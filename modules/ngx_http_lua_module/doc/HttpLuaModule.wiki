= Name =

ngx_http_lua_module - Embed the power of Lua into Nginx HTTP Servers.

This module is a core component of [https://openresty.org OpenResty]. If you are using this module,
then you are essentially using OpenResty.

''This module is not distributed with the Nginx source.'' See
[[#Installation|the installation instructions]].

This is a core component of OpenResty. If you are using this module, then you are essentially using OpenResty :)

= Status =

Production ready.

= Version =

This document describes ngx_lua
[https://github.com/openresty/lua-nginx-module/tags v0.10.19], which was released
on 3 Nov, 2020.

= Videos =

* YouTube video "[Hello World HTTP Example with OpenResty/Lua](https://youtu.be/eSfYLvVQMxw)"

    [![Hello World HTTP Example with OpenResty/Lua](https://img.youtube.com/vi/eSfYLvVQMxw/0.jpg)](https://youtu.be/eSfYLvVQMxw)

* YouTube video "[Write Your Own Lua Modules in OpenResty/Nginx Applications](https://youtu.be/vfYxOMl5LVY)"

    [![Write Your Own Lua Modules in OpenResty/Nginx Applications](https://img.youtube.com/vi/vfYxOMl5LVY/0.jpg)](https://youtu.be/vfYxOMl5LVY)

* YouTube video "[OpenResty's resty Command-Line Utility Demo](https://youtu.be/L1c7aw4mSOo)"

    [![OpenResty's resty Command-Line Utility Demo](https://img.youtube.com/vi/L1c7aw4mSOo/0.jpg)](https://youtu.be/L1c7aw4mSOo)

* YouTube video "[Measure Execution Time of Lua Code Correctly in OpenResty](https://youtu.be/VkRYW_qLoME)"

    [![Measure Execution Time of Lua Code Correctly in OpenResty](https://img.youtube.com/vi/VkRYW_qLoME/0.jpg)](https://youtu.be/VkRYW_qLoME)

* YouTube video "[Precompile Lua Modules into LuaJIT Bytecode to Speedup OpenResty Startup](https://youtu.be/EP7c0BM2yNo)"

    [![Precompile Lua Modules into LuaJIT Bytecode to Speedup OpenResty Startup](https://img.youtube.com/vi/EP7c0BM2yNo/0.jpg)](https://youtu.be/EP7c0BM2yNo)

You are welcome to subscribe to our [official YouTube channel, OpenResty](https://www.youtube.com/channel/UCXVmwF-UCScv2ftsGoMqxhw).

= Synopsis =
<geshi lang="nginx">
    # set search paths for pure Lua external libraries (';;' is the default path):
    lua_package_path '/foo/bar/?.lua;/blah/?.lua;;';

    # set search paths for Lua external libraries written in C (can also use ';;'):
    lua_package_cpath '/bar/baz/?.so;/blah/blah/?.so;;';

    server {
        location /lua_content {
            # MIME type determined by default_type:
            default_type 'text/plain';

            content_by_lua_block {
                ngx.say('Hello,world!')
            }
        }

        location /nginx_var {
            # MIME type determined by default_type:
            default_type 'text/plain';

            # try access /nginx_var?a=hello,world
            content_by_lua_block {
                ngx.say(ngx.var.arg_a)
            }
        }

        location = /request_body {
            client_max_body_size 50k;
            client_body_buffer_size 50k;

            content_by_lua_block {
                ngx.req.read_body()  -- explicitly read the req body
                local data = ngx.req.get_body_data()
                if data then
                    ngx.say("body data:")
                    ngx.print(data)
                    return
                end

                -- body may get buffered in a temp file:
                local file = ngx.req.get_body_file()
                if file then
                    ngx.say("body is in file ", file)
                else
                    ngx.say("no body found")
                end
            }
        }

        # transparent non-blocking I/O in Lua via subrequests
        # (well, a better way is to use cosockets)
        location = /lua {
            # MIME type determined by default_type:
            default_type 'text/plain';

            content_by_lua_block {
                local res = ngx.location.capture("/some_other_location")
                if res then
                    ngx.say("status: ", res.status)
                    ngx.say("body:")
                    ngx.print(res.body)
                end
            }
        }

        location = /foo {
            rewrite_by_lua_block {
                res = ngx.location.capture("/memc",
                    { args = { cmd = "incr", key = ngx.var.uri } }
                )
            }

            proxy_pass http://blah.blah.com;
        }

        location = /mixed {
            rewrite_by_lua_file /path/to/rewrite.lua;
            access_by_lua_file /path/to/access.lua;
            content_by_lua_file /path/to/content.lua;
        }

        # use nginx var in code path
        # CAUTION: contents in nginx var must be carefully filtered,
        # otherwise there'll be great security risk!
        location ~ ^/app/([-_a-zA-Z0-9/]+) {
            set $path $1;
            content_by_lua_file /path/to/lua/app/root/$path.lua;
        }

        location / {
           client_max_body_size 100k;
           client_body_buffer_size 100k;

           access_by_lua_block {
               -- check the client IP address is in our black list
               if ngx.var.remote_addr == "132.5.72.3" then
                   ngx.exit(ngx.HTTP_FORBIDDEN)
               end

               -- check if the URI contains bad words
               if ngx.var.uri and
                      string.match(ngx.var.request_body, "evil")
               then
                   return ngx.redirect("/terms_of_use.html")
               end

               -- tests passed
           }

           # proxy_pass/fastcgi_pass/etc settings
        }
    }
</geshi>

= Description =

This module embeds [https://luajit.org/luajit.html LuaJIT 2.0/2.1] into Nginx.
It is a core component of [https://openresty.org OpenResty]. If you are using
this module, then you are essentially using OpenResty.

Since version <code>v0.10.16</code> of this module, the standard Lua
interpreter (also known as "PUC-Rio Lua") is not supported anymore. This
document interchangeably uses the terms "Lua" and "LuaJIT" to refer to the
LuaJIT interpreter.

By leveraging Nginx's subrequests, this module allows the integration of the
powerful Lua threads (known as Lua "coroutines") into the Nginx event model.

Unlike [https://httpd.apache.org/docs/trunk/mod/mod_lua.html Apache's mod_lua]
and [http://redmine.lighttpd.net/wiki/1/Docs:ModMagnet Lighttpd's mod_magnet],
Lua code executed using this module can be ''100% non-blocking'' on network
traffic as long as the [[#Nginx API for Lua|Nginx API for Lua]] provided by
this module is used to handle requests to upstream services such as MySQL,
PostgreSQL, Memcached, Redis, or upstream HTTP web services.

At least the following Lua libraries and Nginx modules can be used with this
module:

* [https://github.com/openresty/lua-resty-memcached lua-resty-memcached]
* [https://github.com/openresty/lua-resty-mysql lua-resty-mysql]
* [https://github.com/openresty/lua-resty-redis lua-resty-redis]
* [https://github.com/openresty/lua-resty-dns lua-resty-dns]
* [https://github.com/openresty/lua-resty-upload lua-resty-upload]
* [https://github.com/openresty/lua-resty-websocket lua-resty-websocket]
* [https://github.com/openresty/lua-resty-lock lua-resty-lock]
* [https://github.com/cloudflare/lua-resty-logger-socket lua-resty-logger-socket]
* [https://github.com/openresty/lua-resty-lrucache lua-resty-lrucache]
* [https://github.com/openresty/lua-resty-string lua-resty-string]
* [[HttpMemcModule|ngx_memc]]
* [https://github.com/FRiCKLE/ngx_postgres ngx_postgres]
* [[HttpRedis2Module|ngx_redis2]]
* [[HttpRedisModule|ngx_redis]]
* [[HttpProxyModule|ngx_proxy]]
* [[HttpFastcgiModule|ngx_fastcgi]]

Almost any Nginx modules can be used with this ngx_lua module by means of
[[#ngx.location.capture|ngx.location.capture]] or
[[#ngx.location.capture_multi|ngx.location.capture_multi]] but it is
recommended to use those <code>lua-resty-*</code> libraries instead of creating
subrequests to access the Nginx upstream modules because the former is usually
much more flexible and memory-efficient.

The Lua interpreter (also known as "Lua State" or "LuaJIT VM instance") is
shared across all the requests in a single Nginx worker process to minimize
memory use. Request contexts are segregated using lightweight Lua coroutines.

Loaded Lua modules persist in the Nginx worker process level resulting in a
small memory footprint in Lua even when under heavy loads.

This module is plugged into Nginx's "http" subsystem so it can only speaks
downstream communication protocols in the HTTP family (HTTP 0.9/1.0/1.1/2.0,
WebSockets, etc...).  If you want to do generic TCP communications with the
downstream clients, then you should use the
[https://github.com/openresty/stream-lua-nginx-module#readme ngx_stream_lua]
module instead, which offers a compatible Lua API.

= Typical Uses =

Just to name a few:

* Mashup'ing and processing outputs of various Nginx upstream outputs (proxy, drizzle, postgres, redis, memcached, and etc) in Lua,
* doing arbitrarily complex access control and security checks in Lua before requests actually reach the upstream backends,
* manipulating response headers in an arbitrary way (by Lua)
* fetching backend information from external storage backends (like redis, memcached, mysql, postgresql) and use that information to choose which upstream backend to access on-the-fly,
* coding up arbitrarily complex web applications in a content handler using synchronous but still non-blocking access to the database backends and other storage,
* doing very complex URL dispatch in Lua at rewrite phase,
* using Lua to implement advanced caching mechanism for Nginx's subrequests and arbitrary locations.

The possibilities are unlimited as the module allows bringing together various
elements within Nginx as well as exposing the power of the Lua language to the
user. The module provides the full flexibility of scripting while offering
performance levels comparable with native C language programs both in terms of
CPU time as well as memory footprint thanks to LuaJIT 2.x.

Other scripting language implementations typically struggle to match this
performance level.

= Nginx Compatibility =

The latest version of this module is compatible with the following versions of Nginx:

* 1.19.x  (last tested: 1.19.3)
* 1.17.x  (last tested: 1.17.8)
* 1.15.x  (last tested: 1.15.8)
* 1.14.x
* 1.13.x  (last tested: 1.13.6)
* 1.12.x
* 1.11.x  (last tested: 1.11.2)
* 1.10.x
* 1.9.x (last tested: 1.9.15)
* 1.8.x
* 1.7.x (last tested: 1.7.10)
* 1.6.x

Nginx cores older than 1.6.0 (exclusive) are *not* supported.

= Installation =

It is *highly* recommended to use [https://openresty.org OpenResty releases]
which bundle Nginx, ngx_lua (this module), LuaJIT, as well as other powerful
companion Nginx modules and Lua libraries.

It is discouraged to build this module with Nginx yourself since it is tricky
to set up exactly right.

Note that Nginx, LuaJIT, and OpenSSL official releases have various limitations
and long standing bugs that can cause some of this module's features to be
disabled, not work properly, or run slower. Official OpenResty releases are
recommended because they bundle [https://github.com/openresty/luajit2
OpenResty's optimized LuaJIT 2.1 fork] and
[https://github.com/openresty/openresty/tree/master/patches Nginx/OpenSSL
patches].

Alternatively, ngx_lua can be manually compiled into Nginx:

# LuaJIT can be downloaded from the [https://github.com/openresty/luajit2/releases latest release of OpenResty's LuaJIT fork]. The official LuaJIT 2.x releases are also supported, although performance will be significantly lower for reasons elaborated above
# Download the latest version of the ngx_devel_kit (NDK) module [https://github.com/simplresty/ngx_devel_kit/tags HERE]
# Download the latest version of ngx_lua [https://github.com/openresty/lua-nginx-module/tags HERE]
# Download the latest supported version of Nginx [https://nginx.org/ HERE] (See [[#Nginx Compatibility|Nginx Compatibility]])
# Download the latest version of the lua-resty-core [HERE](https://github.com/openresty/lua-resty-core)
# Download the latest version of the lua-resty-lrucache [HERE](https://github.com/openresty/lua-resty-lrucache)

Build the source with this module:

<geshi lang="bash">
    wget 'https://openresty.org/download/nginx-1.19.3.tar.gz'
    tar -xzvf nginx-1.19.3.tar.gz
    cd nginx-1.19.3/

    # tell nginx's build system where to find LuaJIT 2.0:
    export LUAJIT_LIB=/path/to/luajit/lib
    export LUAJIT_INC=/path/to/luajit/include/luajit-2.0

    # tell nginx's build system where to find LuaJIT 2.1:
    export LUAJIT_LIB=/path/to/luajit/lib
    export LUAJIT_INC=/path/to/luajit/include/luajit-2.1

    # Here we assume Nginx is to be installed under /opt/nginx/.
    ./configure --prefix=/opt/nginx \
            --with-ld-opt="-Wl,-rpath,/path/to/luajit/lib" \
            --add-module=/path/to/ngx_devel_kit \
            --add-module=/path/to/lua-nginx-module

    # Note that you may also want to add `./configure` options which are used in your
    # current nginx build.
    # You can get usually those options using command nginx -V

    # you can change the parallelism number 2 below to fit the number of spare CPU cores in your
    # machine.
    make -j2
    make install

    # Note that this version of lug-nginx-module not allow to set `lua_load_resty_core off;` any more.
    # So, you have to install `lua-resty-core` and `lua-resty-lrucache` manually as below.

    cd lua-resty-core
    make install PREFIX=/opt/nginx
    cd lua-resty-lrucache
    make install PREFIX=/opt/nginx

    # add necessary `lua_package_path` directive to `nginx.conf`, in the http context

    lua_package_path "/opt/nginx/lib/lua/?.lua;;";
</geshi>

== Building as a dynamic module ==

Starting from NGINX 1.9.11, you can also compile this module as a dynamic module, by using the <code>--add-dynamic-module=PATH</code> option instead of <code>--add-module=PATH</code> on the
<code>./configure</code> command line above. And then you can explicitly load the module in your <code>nginx.conf</code> via the [load_module](https://nginx.org/en/docs/ngx_core_module.html#load_module)
directive, for example,

<geshi lang="nginx">
load_module /path/to/modules/ndk_http_module.so;  # assuming NDK is built as a dynamic module too
load_module /path/to/modules/ngx_http_lua_module.so;
</geshi>

== C Macro Configurations ==

While building this module either via OpenResty or with the Nginx core, you can define the following C macros via the C compiler options:

* <code>NGX_LUA_USE_ASSERT</code>
: When defined, will enable assertions in the ngx_lua C code base. Recommended for debugging or testing builds. It can introduce some (small) runtime overhead when enabled. This macro was first introduced in the <code>v0.9.10</code> release.
* <code>NGX_LUA_ABORT_AT_PANIC</code>
: When the LuaJIT VM panics, ngx_lua will instruct the current nginx worker process to quit gracefully by default. By specifying this C macro, ngx_lua will abort the current nginx worker process (which usually result in a core dump file) immediately. This option is useful for debugging VM panics. This option was first introduced in the <code>v0.9.8</code> release.

To enable one or more of these macros, just pass extra C compiler options to the <code>./configure</code> script of either Nginx or OpenResty. For instance,

<geshi>
    ./configure --with-cc-opt="-DNGX_LUA_USE_ASSERT -DNGX_LUA_ABORT_AT_PANIC"
</geshi>

= Community =

== English Mailing List ==

The [https://groups.google.com/group/openresty-en openresty-en] mailing list is for English speakers.

== Chinese Mailing List ==

The [https://groups.google.com/group/openresty openresty] mailing list is for Chinese speakers.

= Code Repository =

The code repository of this project is hosted on GitHub at
[https://github.com/openresty/lua-nginx-module openresty/lua-nginx-module].

= Bugs and Patches =

Please submit bug reports, wishlists, or patches by

# creating a ticket on the [https://github.com/openresty/lua-nginx-module/issues GitHub Issue Tracker],
# or posting to the [[#Community|OpenResty community]].

= LuaJIT bytecode support =

Watch YouTube video "[Measure Execution Time of Lua Code Correctly in OpenResty](https://youtu.be/VkRYW_qLoME)"

[![Precompile Lua Modules into LuaJIT Bytecode to Speedup OpenResty Startup](https://img.youtube.com/vi/EP7c0BM2yNo/0.jpg)](https://youtu.be/EP7c0BM2yNo)

As from the <code>v0.5.0rc32</code> release, all <code>*_by_lua_file</code> configure directives (such as [[#content_by_lua_file|content_by_lua_file]]) support loading LuaJIT 2.0/2.1 raw bytecode files directly:

<geshi lang="bash">
    /path/to/luajit/bin/luajit -b /path/to/input_file.lua /path/to/output_file.ljbc
</geshi>

The <code>-bg</code> option can be used to include debug information in the LuaJIT bytecode file:

<geshi lang="bash">
    /path/to/luajit/bin/luajit -bg /path/to/input_file.lua /path/to/output_file.ljbc
</geshi>

Please refer to the official LuaJIT documentation on the <code>-b</code> option for more details:

https://luajit.org/running.html#opt_b

Note that the bytecode files generated by LuaJIT 2.1 is ''not'' compatible with
LuaJIT 2.0, and vice versa. The support for LuaJIT 2.1 bytecode was first added
in ngx_lua v0.9.3.

Attempts to load standard Lua 5.1 bytecode files into ngx_lua instances linked
to LuaJIT 2.0/2.1 (or vice versa) will result in an Nginx error message such as
the one below:

<geshi lang="text">
    [error] 13909#0: *1 failed to load Lua inlined code: bad byte-code header in /path/to/test_file.luac
</geshi>

Loading bytecode files via the Lua primitives like <code>require</code> and
<code>dofile</code> should always work as expected.

= System Environment Variable Support =

If you want to access the system environment variable, say, <code>foo</code>, in Lua via the standard Lua API [https://www.lua.org/manual/5.1/manual.html#pdf-os.getenv os.getenv], then you should also list this environment variable name in your <code>nginx.conf</code> file via the [https://nginx.org/en/docs/ngx_core_module.html#env env directive]. For example,

<geshi lang="nginx">
    env foo;
</geshi>

= HTTP 1.0 support =

The HTTP 1.0 protocol does not support chunked output and requires an explicit <code>Content-Length</code> header when the response body is not empty in order to support the HTTP 1.0 keep-alive.
So when a HTTP 1.0 request is made and the [[#lua_http10_buffering|lua_http10_buffering]] directive is turned <code>on</code>, ngx_lua will buffer the
output of [[#ngx.say|ngx.say]] and [[#ngx.print|ngx.print]] calls and also postpone sending response headers until all the response body output is received.
At that time ngx_lua can calculate the total length of the body and construct a proper <code>Content-Length</code> header to return to the HTTP 1.0 client.
If the <code>Content-Length</code> response header is set in the running Lua code, however, this buffering will be disabled even if the [[#lua_http10_buffering|lua_http10_buffering]] directive is turned <code>on</code>.

For large streaming output responses, it is important to disable the [[#lua_http10_buffering|lua_http10_buffering]] directive to minimise memory usage.

Note that common HTTP benchmark tools such as <code>ab</code> and <code>http_load</code> issue HTTP 1.0 requests by default.
To force <code>curl</code> to send HTTP 1.0 requests, use the <code>-0</code> option.

= Statically Linking Pure Lua Modules =

With LuaJIT 2.x, it is possible to statically link the bytecode of pure Lua
modules into the Nginx executable.

You can use the <code>luajit</code> executable to compile <code>.lua</code> Lua
module files to <code>.o</code> object files containing the exported bytecode
data, and then link the <code>.o</code> files directly in your Nginx build.

Below is a trivial example to demonstrate this. Consider that we have the following <code>.lua</code> file named <code>foo.lua</code>:

<geshi lang="lua">
    -- foo.lua
    local _M = {}

    function _M.go()
        print("Hello from foo")
    end

    return _M
</geshi>

And then we compile this <code>.lua</code> file to <code>foo.o</code> file:

<geshi lang="bash">
    /path/to/luajit/bin/luajit -bg foo.lua foo.o
</geshi>

What matters here is the name of the <code>.lua</code> file, which determines how you use this module later on the Lua land. The file name <code>foo.o</code> does not matter at all except the <code>.o</code> file extension (which tells <code>luajit</code> what output format is used). If you want to strip the Lua debug information from the resulting bytecode, you can just specify the <code>-b</code> option above instead of <code>-bg</code>.

Then when building Nginx or OpenResty, pass the <code>--with-ld-opt="foo.o"</code> option to the <code>./configure</code> script:

<geshi lang="bash">
    ./configure --with-ld-opt="/path/to/foo.o" ...
</geshi>

Finally, you can just do the following in any Lua code run by ngx_lua:

<geshi lang="lua">
    local foo = require "foo"
    foo.go()
</geshi>

And this piece of code no longer depends on the external <code>foo.lua</code> file any more because it has already been compiled into the <code>nginx</code> executable.

If you want to use dot in the Lua module name when calling <code>require</code>, as in

<geshi lang="lua">
    local foo = require "resty.foo"
</geshi>

then you need to rename the <code>foo.lua</code> file to <code>resty_foo.lua</code> before compiling it down to a <code>.o</code> file with the <code>luajit</code> command-line utility.

It is important to use exactly the same version of LuaJIT when compiling <code>.lua</code> files to <code>.o</code> files as building nginx + ngx_lua. This is because the LuaJIT bytecode format may be incompatible between different LuaJIT versions. When the bytecode format is incompatible, you will see a Lua runtime error saying that the Lua module is not found.

When you have multiple <code>.lua</code> files to compile and link, then just specify their <code>.o</code> files at the same time in the value of the <code>--with-ld-opt</code> option. For instance,

<geshi lang="bash">
    ./configure --with-ld-opt="/path/to/foo.o /path/to/bar.o" ...
</geshi>

If you have too many <code>.o</code> files, then it might not be feasible to name them all in a single command. In this case, you can build a static library (or archive) for your <code>.o</code> files, as in

<geshi lang="bash">
    ar rcus libmyluafiles.a *.o
</geshi>

then you can link the <code>myluafiles</code> archive as a whole to your nginx executable:

<geshi lang="bash">
    ./configure \
        --with-ld-opt="-L/path/to/lib -Wl,--whole-archive -lmyluafiles -Wl,--no-whole-archive"
</geshi>

where <code>/path/to/lib</code> is the path of the directory containing the <code>libmyluafiles.a</code> file. It should be noted that the linker option <code>--whole-archive</code> is required here because otherwise our archive will be skipped because no symbols in our archive are mentioned in the main parts of the nginx executable.

= Data Sharing within an Nginx Worker =

To globally share data among all the requests handled by the same Nginx worker
process, encapsulate the shared data into a Lua module, use the Lua
<code>require</code> builtin to import the module, and then manipulate the
shared data in Lua. This works because required Lua modules are loaded only
once and all coroutines will share the same copy of the module (both its code
and data).

Note that the use of global Lua variables is *strongly discouraged*, as it may
lead to unexpected race conditions between concurrent requests.

Here is a small example on sharing data within an Nginx worker via a Lua module:

<geshi lang="lua">
    -- mydata.lua
    local _M = {}

    local data = {
        dog = 3,
        cat = 4,
        pig = 5,
    }

    function _M.get_age(name)
        return data[name]
    end

    return _M
</geshi>

and then accessing it from <code>nginx.conf</code>:

<geshi lang="nginx">
    location /lua {
        content_by_lua_block {
            local mydata = require "mydata"
            ngx.say(mydata.get_age("dog"))
        }
    }
</geshi>

The <code>mydata</code> module in this example will only be loaded and run on the first request to the location <code>/lua</code>,
and all subsequent requests to the same Nginx worker process will use the reloaded instance of the
module as well as the same copy of the data in it, until a <code>HUP</code> signal is sent to the Nginx master process to force a reload.
This data sharing technique is essential for high performance Lua applications based on this module.

Note that this data sharing is on a ''per-worker'' basis and not on a ''per-server'' basis. That is, when there are multiple Nginx worker processes under an Nginx master, data sharing cannot cross the process boundary between these workers.

It is usually recommended to share read-only data this way. You can also share changeable data among all the concurrent requests of each Nginx worker process as
long as there is ''no'' nonblocking I/O operations (including [[#ngx.sleep|ngx.sleep]])
in the middle of your calculations. As long as you do not give the
control back to the Nginx event loop and ngx_lua's light thread
scheduler (even implicitly), there can never be any race conditions in
between. For this reason, always be very careful when you want to share changeable data on the
worker level. Buggy optimizations can easily lead to hard-to-debug
race conditions under load.

If server-wide data sharing is required, then use one or more of the following approaches:

# Use the [[#ngx.shared.DICT|ngx.shared.DICT]] API provided by this module.
# Use only a single Nginx worker and a single server (this is however not recommended when there is a multi core CPU or multiple CPUs in a single machine).
# Use data storage mechanisms such as <code>memcached</code>, <code>redis</code>, <code>MySQL</code> or <code>PostgreSQL</code>. [https://openresty.org The OpenResty official releases] come with a set of companion Nginx modules and Lua libraries that provide interfaces with these data storage mechanisms.

= Known Issues =

== TCP socket connect operation issues ==

The [[#tcpsock:connect|tcpsock:connect]] method may indicate <code>success</code> despite connection failures such as with <code>Connection Refused</code> errors.

However, later attempts to manipulate the cosocket object will fail and return the actual error status message generated by the failed connect operation.

This issue is due to limitations in the Nginx event model and only appears to affect Mac OS X.

== Lua Coroutine Yielding/Resuming ==

* Because Lua's <code>dofile</code> and <code>require</code> builtins are currently implemented as C functions in LuaJIT 2.0/2.1, if the Lua file being loaded by <code>dofile</code> or <code>require</code> invokes [[#ngx.location.capture|ngx.location.capture*]], [[#ngx.exec|ngx.exec]], [[#ngx.exit|ngx.exit]], or other API functions requiring yielding in the *top-level* scope of the Lua file, then the Lua error "attempt to yield across C-call boundary" will be raised. To avoid this, put these calls requiring yielding into your own Lua functions in the Lua file instead of the top-level scope of the file.

== Lua Variable Scope ==

Care must be taken when importing modules, and this form should be used:

<geshi lang="lua">
    local xxx = require('xxx')
</geshi>

instead of the old deprecated form:

<geshi lang="lua">
    require('xxx')
</geshi>

Here is the reason: by design, the global environment has exactly the same lifetime as the Nginx request handler associated with it. Each request handler has its own set of Lua global variables and that is the idea of request isolation. The Lua module is actually loaded by the first Nginx request handler and is cached by the <code>require()</code> built-in in the <code>package.loaded</code> table for later reference, and the <code>module()</code> builtin used by some Lua modules has the side effect of setting a global variable to the loaded module table. But this global variable will be cleared at the end of the request handler,  and every subsequent request handler all has its own (clean) global environment. So one will get Lua exception for accessing the <code>nil</code> value.

The use of Lua global variables is a generally inadvisable in the ngx_lua context as:

# the misuse of Lua globals has detrimental side effects on concurrent requests when such variables should instead be local in scope,
# Lua global variables require Lua table look-ups in the global environment which is computationally expensive, and
# some Lua global variable references may include typing errors which make such difficult to debug.

It is therefore *highly* recommended to always declare such within an appropriate local scope instead.

<geshi lang="lua">
    -- Avoid
    foo = 123
    -- Recommended
    local foo = 123

    -- Avoid
    function foo() return 123 end
    -- Recommended
    local function foo() return 123 end
</geshi>

To find all instances of Lua global variables in your Lua code, run the [https://github.com/openresty/nginx-devel-utils/blob/master/lua-releng lua-releng tool] across all <code>.lua</code> source files:
<geshi lang="text">
$ lua-releng
Checking use of Lua global variables in file lib/foo/bar.lua ...
        1       [1489]  SETGLOBAL       7 -1    ; contains
        55      [1506]  GETGLOBAL       7 -3    ; setvar
        3       [1545]  GETGLOBAL       3 -4    ; varexpand
</geshi>
The output says that the line 1489 of file <code>lib/foo/bar.lua</code> writes to a global variable named <code>contains</code>, the line 1506 reads from the global variable <code>setvar</code>, and line 1545 reads the global <code>varexpand</code>.

This tool will guarantee that local variables in the Lua module functions are all declared with the <code>local</code> keyword, otherwise a runtime exception will be thrown. It prevents undesirable race conditions while accessing such variables. See [[#Data_Sharing_within_an_Nginx_Worker|Data Sharing within an Nginx Worker]] for the reasons behind this.

== Locations Configured by Subrequest Directives of Other Modules ==

The [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]] directives cannot capture locations that include the [[HttpAdditionModule#add_before_body|add_before_body]], [[HttpAdditionModule#add_after_body|add_after_body]], [https://nginx.org/en/docs/http/ngx_http_auth_request_module.html#auth_request auth_request], [[HttpEchoModule#echo_location|echo_location]], [[HttpEchoModule#echo_location_async|echo_location_async]], [[HttpEchoModule#echo_subrequest|echo_subrequest]], or [[HttpEchoModule#echo_subrequest_async|echo_subrequest_async]] directives.

<geshi lang="nginx">
    location /foo {
        content_by_lua_block {
            res = ngx.location.capture("/bar")
        }
    }
    location /bar {
        echo_location /blah;
    }
    location /blah {
        echo "Success!";
    }
</geshi>

<geshi lang="nginx">
    $ curl -i http://example.com/foo
</geshi>

will not work as expected.

== Cosockets Not Available Everywhere ==

Due to internal limitations in the Nginx core, the cosocket API is disabled in the following contexts: [[#set_by_lua|set_by_lua*]], [[#log_by_lua|log_by_lua*]], [[#header_filter_by_lua|header_filter_by_lua*]], and [[#body_filter_by_lua|body_filter_by_lua]].

The cosockets are currently also disabled in the [[#init_by_lua|init_by_lua*]] and [[#init_worker_by_lua|init_worker_by_lua*]] directive contexts but we may add support for these contexts in the future because there is no limitation in the Nginx core (or the limitation might be worked around).

There exists a workaround, however, when the original context does *not* need to wait for the cosocket results. That is, creating a zero-delay timer via the [[#ngx.timer.at|ngx.timer.at]] API and do the cosocket results in the timer handler, which runs asynchronously as to the original context creating the timer.

== Special Escaping Sequences ==

'''NOTE''' Following the <code>v0.9.17</code> release, this pitfall can be avoided by using the <code>*_by_lua_block {}</code> configuration directives.

PCRE sequences such as <code>\d</code>, <code>\s</code>, or <code>\w</code>, require special attention because in string literals, the backslash character, <code>\</code>, is stripped out by both the Lua language parser and by the Nginx config file parser before processing if not within a <code>*_by_lua_block {}</code> directive. So the following snippet will not work as expected:

<geshi lang="nginx">
    # nginx.conf
    ? location /test {
    ?     content_by_lua '
    ?         local regex = "\d+"  -- THIS IS WRONG OUTSIDE OF A *_by_lua_block DIRECTIVE
    ?         local m = ngx.re.match("hello, 1234", regex)
    ?         if m then ngx.say(m[0]) else ngx.say("not matched!") end
    ?     ';
    ? }
    # evaluates to "not matched!"
</geshi>

To avoid this, ''double'' escape the backslash:

<geshi lang="nginx">
    # nginx.conf
    location /test {
        content_by_lua '
            local regex = "\\\\d+"
            local m = ngx.re.match("hello, 1234", regex)
            if m then ngx.say(m[0]) else ngx.say("not matched!") end
        ';
    }
    # evaluates to "1234"
</geshi>

Here, <code>\\\\d+</code> is stripped down to <code>\\d+</code> by the Nginx config file parser and this is further stripped down to <code>\d+</code> by the Lua language parser before running.

Alternatively, the regex pattern can be presented as a long-bracketed Lua string literal by encasing it in "long brackets", <code>&#91;[...]]</code>, in which case backslashes have to only be escaped once for the Nginx config file parser.

<geshi lang="nginx">
    # nginx.conf
    location /test {
        content_by_lua '
            local regex = [[\\d+]]
            local m = ngx.re.match("hello, 1234", regex)
            if m then ngx.say(m[0]) else ngx.say("not matched!") end
        ';
    }
    # evaluates to "1234"
</geshi>

Here, <code>&#91;[\\d+]]</code> is stripped down to <code>&#91;[\d+]]</code> by the Nginx config file parser and this is processed correctly.

Note that a longer from of the long bracket, <code>[=[...]=]</code>, may be required if the regex pattern contains <code>&#91;...]</code> sequences.
The <code>[=[...]=]</code> form may be used as the default form if desired.

<geshi lang="nginx">
    # nginx.conf
    location /test {
        content_by_lua '
            local regex = [=[[0-9]+]=]
            local m = ngx.re.match("hello, 1234", regex)
            if m then ngx.say(m[0]) else ngx.say("not matched!") end
        ';
    }
    # evaluates to "1234"
</geshi>

An alternative approach to escaping PCRE sequences is to ensure that Lua code is placed in external script files and executed using the various <code>*_by_lua_file</code> directives.
With this approach, the backslashes are only stripped by the Lua language parser and therefore only need to be escaped once each.

<geshi lang="lua">
    -- test.lua
    local regex = "\\d+"
    local m = ngx.re.match("hello, 1234", regex)
    if m then ngx.say(m[0]) else ngx.say("not matched!") end
    -- evaluates to "1234"
</geshi>

Within external script files, PCRE sequences presented as long-bracketed Lua string literals do not require modification.

<geshi lang="lua">
    -- test.lua
    local regex = [[\d+]]
    local m = ngx.re.match("hello, 1234", regex)
    if m then ngx.say(m[0]) else ngx.say("not matched!") end
    -- evaluates to "1234"
</geshi>

As noted earlier, PCRE sequences presented within <code>*_by_lua_block {}</code> directives (available following the <code>v0.9.17</code> release) do not require modification.

<geshi lang="nginx">
    # nginx.conf
    location /test {
        content_by_lua_block {
            local regex = [[\d+]]
            local m = ngx.re.match("hello, 1234", regex)
            if m then ngx.say(m[0]) else ngx.say("not matched!") end
        }
    }
    # evaluates to "1234"
</geshi>

'''NOTE''' You are recommended to use `by_lua_file` when the Lua code is very long.

== Mixing with SSI Not Supported ==

Mixing SSI with ngx_lua in the same Nginx request is not supported at all. Just use ngx_lua exclusively. Everything you can do with SSI can be done atop ngx_lua anyway and it can be more efficient when using ngx_lua.

== SPDY Mode Not Fully Supported ==

Certain Lua APIs provided by ngx_lua do not work in Nginx's SPDY mode yet: [[#ngx.location.capture|ngx.location.capture]], [[#ngx.location.capture_multi|ngx.location.capture_multi]], and [[#ngx.req.socket|ngx.req.socket]].

== Missing data on short circuited requests ==

Nginx may terminate a request early with (at least):

* 400 (Bad Request)
* 405 (Not Allowed)
* 408 (Request Timeout)
* 413 (Request Entity Too Large)
* 414 (Request URI Too Large)
* 494 (Request Headers Too Large)
* 499 (Client Closed Request)
* 500 (Internal Server Error)
* 501 (Not Implemented)

This means that phases that normally run are skipped, such as the rewrite or
access phase. This also means that later phases that are run regardless, e.g.
[[#log_by_lua|log_by_lua]], will not have access to information that is normally set in those
phases.

= TODO =

* cosocket: implement LuaSocket's unconnected UDP API.
* cosocket: add support in the context of [[#init_by_lua|init_by_lua*]].
* cosocket: implement the <code>bind()</code> method for stream-typed cosockets.
* cosocket: review and merge aviramc's [https://github.com/openresty/lua-nginx-module/pull/290 patch] for adding the <code>bsdrecv</code> method.
* cosocket: add configure options for different strategies of handling the cosocket connection exceeding in the pools.
* review and apply vadim-pavlov's patch for [[#ngx.location.capture|ngx.location.capture]]'s <code>extra_headers</code> option
* use <code>ngx_hash_t</code> to optimize the built-in header look-up process for [[#ngx.req.set_header|ngx.req.set_header]], and etc.
* add <code>ignore_resp_headers</code>, <code>ignore_resp_body</code>, and <code>ignore_resp</code> options to [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]] methods, to allow micro performance tuning on the user side.
* add automatic Lua code time slicing support by yielding and resuming the Lua VM actively via Lua's debug hooks.
* add <code>stat</code> mode similar to [https://httpd.apache.org/docs/trunk/mod/mod_lua.html mod_lua].

= Changes =

The changes made in every release of this module are listed in the change logs of the OpenResty bundle:

https://openresty.org/#Changes

= Test Suite =

The following dependencies are required to run the test suite:

* Nginx version >= 1.4.2

* Perl modules:
** Test::Nginx: https://github.com/openresty/test-nginx

* Nginx modules:
** [https://github.com/simplresty/ngx_devel_kit ngx_devel_kit]
** [https://github.com/openresty/set-misc-nginx-module ngx_set_misc]
** [http://mdounin.ru/files/ngx_http_auth_request_module-0.2.tar.gz ngx_auth_request] (this is not needed if you're using Nginx 1.5.4+.
** [https://github.com/openresty/echo-nginx-module ngx_echo]
** [https://github.com/openresty/memc-nginx-module ngx_memc]
** [https://github.com/openresty/srcache-nginx-module ngx_srcache]
** ngx_lua (i.e., this module)
** [https://github.com/openresty/lua-upstream-nginx-module ngx_lua_upstream]
** [https://github.com/openresty/headers-more-nginx-module ngx_headers_more]
** [https://github.com/openresty/drizzle-nginx-module ngx_drizzle]
** [https://github.com/openresty/rds-json-nginx-module ngx_rds_json]
** [https://github.com/FRiCKLE/ngx_coolkit ngx_coolkit]
** [https://github.com/openresty/redis2-nginx-module ngx_redis2]

The order in which these modules are added during configuration is important because the position of any filter module in the
filtering chain determines the final output, for example. The correct adding order is shown above.

* 3rd-party Lua libraries:
** [http://www.kyne.com.au/~mark/software/lua-cjson.php lua-cjson]

* Applications:
** mysql: create database 'ngx_test', grant all privileges to user 'ngx_test', password is 'ngx_test'
** memcached: listening on the default port, 11211.
** redis: listening on the default port, 6379.

See also the [https://github.com/openresty/lua-nginx-module/blob/master/util/build.sh developer build script] for more details on setting up the testing environment.

To run the whole test suite in the default testing mode:
<geshi lang="text">
    cd /path/to/lua-nginx-module
    export PATH=/path/to/your/nginx/sbin:$PATH
    prove -I/path/to/test-nginx/lib -r t
</geshi>

To run specific test files:
<geshi lang="text">
    cd /path/to/lua-nginx-module
    export PATH=/path/to/your/nginx/sbin:$PATH
    prove -I/path/to/test-nginx/lib t/002-content.t t/003-errors.t
</geshi>

To run a specific test block in a particular test file, add the line <code>--- ONLY</code> to the test block you want to run, and then use the <code>prove</code> utility to run that <code>.t</code> file.

There are also various testing modes based on mockeagain, valgrind, and etc. Refer to the [https://search.cpan.org/perldoc?Test::Nginx Test::Nginx documentation] for more details for various advanced testing modes. See also the test reports for the Nginx test cluster running on Amazon EC2: https://qa.openresty.org.

= Copyright and License =

This module is licensed under the BSD license.

Copyright (C) 2009-2017, by Xiaozhe Wang (chaoslawful) <chaoslawful@gmail.com>.

Copyright (C) 2009-2019, by Yichun "agentzh" Zhang (章亦春) <agentzh@gmail.com>, OpenResty Inc.

All rights reserved.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

= See Also =

Blog posts:

* [Introduction to Lua-Land CPU Flame Graphs](https://blog.openresty.com/en/lua-cpu-flame-graph/?src=gh_ngxlua)
* [How OpenResty and Nginx Allocate and Manage Memory](https://blog.openresty.com/en//how-or-alloc-mem?src=gh_ngxlua)
* [How OpenResty and Nginx Shared Memory Zones Consume RAM](https://blog.openresty.com/en/how-nginx-shm-consume-ram/?src=gh_ngxlua)
* [Memory Fragmentation in OpenResty and Nginx's Shared Memory Zones](https://blog.openresty.com/en/nginx-shm-frag/?src=gh_ngxlua)

Other related modules and libraries:

* [https://github.com/openresty/stream-lua-nginx-module#readme ngx_stream_lua_module] for an official port of this module for the Nginx "stream" subsystem (doing generic downstream TCP communications).
* [https://github.com/openresty/lua-resty-memcached lua-resty-memcached] library based on ngx_lua cosocket.
* [https://github.com/openresty/lua-resty-redis lua-resty-redis] library based on ngx_lua cosocket.
* [https://github.com/openresty/lua-resty-mysql lua-resty-mysql] library based on ngx_lua cosocket.
* [https://github.com/openresty/lua-resty-upload lua-resty-upload] library based on ngx_lua cosocket.
* [https://github.com/openresty/lua-resty-dns lua-resty-dns] library based on ngx_lua cosocket.
* [https://github.com/openresty/lua-resty-websocket lua-resty-websocket] library for both WebSocket server and client, based on ngx_lua cosocket.
* [https://github.com/openresty/lua-resty-string lua-resty-string] library based on [https://luajit.org/ext_ffi.html LuaJIT FFI].
* [https://github.com/openresty/lua-resty-lock lua-resty-lock] library for a nonblocking simple lock API.
* [https://github.com/cloudflare/lua-resty-cookie lua-resty-cookie] library for HTTP cookie manipulation.
* [https://openresty.org/#RoutingMySQLQueriesBasedOnURIArgs Routing requests to different MySQL queries based on URI arguments]
* [https://openresty.org/#DynamicRoutingBasedOnRedis Dynamic Routing Based on Redis and Lua]
* [https://openresty.org/#UsingLuaRocks Using LuaRocks with ngx_lua]
* [https://github.com/openresty/lua-nginx-module/wiki/Introduction Introduction to ngx_lua]
* [https://github.com/simplresty/ngx_devel_kit ngx_devel_kit]
* [[HttpEchoModule]]
* [[HttpDrizzleModule]]
* [https://github.com/FRiCKLE/ngx_postgres postgres-nginx-module]
* [[HttpMemcModule]]
* [https://openresty.org The OpenResty bundle]
* [https://github.com/openresty/nginx-systemtap-toolkit Nginx Systemtap Toolkit]

= Directives =

<!-- inline-toc -->

The basic building blocks of scripting Nginx with Lua are directives. Directives are used to specify when the user Lua code is run and
how the result will be used. Below is a diagram showing the order in which directives are executed.

![Lua Nginx Modules Directives](https://cloud.githubusercontent.com/assets/2137369/15272097/77d1c09e-1a37-11e6-97ef-d9767035fc3e.png)

== lua_load_resty_core ==

'''syntax:''' ''lua_load_resty_core on|off''

'''default:''' ''lua_load_resty_core on''

'''context:''' ''http''

This directive is deprecated since the <code>v0.10.16</code> release of this
module. The <code>resty.core</code> module from
[https://github.com/openresty/lua-resty-core lua-resty-core] is now mandatorily
loaded during the Lua VM initialization. Specifying this directive will have no
effect.

This directive was first introduced in the <code>v0.10.15</code> release and
used to optionally load the <code>resty.core</code> module.

== lua_capture_error_log ==

'''syntax:''' ''lua_capture_error_log size''

'''default:''' ''none''

'''context:''' ''http''

Enables a buffer of the specified <code>size</code> for capturing all the Nginx error log message data (not just those produced
by this module or the Nginx http subsystem, but everything) without touching files or disks.

You can use units like `k` and `m` in the <code>size</code> value, as in

<geshi lang="nginx">
    lua_capture_error_log 100k;
</geshi>

As a rule of thumb, a 4KB buffer can usually hold about 20 typical error log messages. So do the maths!

This buffer never grows. If it is full, new error log messages will replace the oldest ones in the buffer.

The size of the buffer must be bigger than the maximum length of a single error log message (which is 4K in OpenResty and 2K in stock NGINX).

You can read the messages in the buffer on the Lua land via the
[https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/errlog.md#get_logs get_logs()]
function of the
[https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/errlog.md#readme ngx.errlog]
module of the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/errlog.md#readme lua-resty-core]
library. This Lua API function will return the captured error log messages and
also remove these already read from the global capturing buffer, making room
for any new error log data. For this reason, the user should not configure this
buffer to be too big if the user read the buffered error log data fast enough.

Note that the log level specified in the standard [https://nginx.org/r/error_log error_log] directive
''does'' have effect on this capturing facility. It only captures log
messages of a level no lower than the specified log level in the [https://nginx.org/r/error_log error_log] directive.
The user can still choose to set an even higher filtering log level on the fly via the Lua API function
[https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/errlog.md#set_filter_level errlog.set_filter_level].
So it is more flexible than the static [https://nginx.org/r/error_log error_log] directive.

It is worth noting that there is no way to capture the debugging logs
without building OpenResty or Nginx with the <code>./configure</code>
option <code>--with-debug</code>. And enabling debugging logs is
strongly discouraged in production builds due to high overhead.

This directive was first introduced in the <code>v0.10.9</code> release.

== lua_use_default_type ==

'''syntax:''' ''lua_use_default_type on | off''

'''default:''' ''lua_use_default_type on''

'''context:''' ''http, server, location, location if''

Specifies whether to use the MIME type specified by the [https://nginx.org/en/docs/http/ngx_http_core_module.html#default_type default_type] directive for the default value of the <code>Content-Type</code> response header. Deactivate this directive if a default <code>Content-Type</code> response header for Lua request handlers is not desired.

This directive is turned on by default.

This directive was first introduced in the <code>v0.9.1</code> release.

== lua_malloc_trim ==

'''syntax:''' ''lua_malloc_trim <request-count>''

'''default:''' ''lua_malloc_trim 1000''

'''context:''' ''http''

Asks the underlying <code>libc</code> runtime library to release its cached free memory back to the operating system every
<code>N</code> requests processed by the Nginx core. By default, <code>N</code> is 1000. You can configure the request count
by using your own numbers. Smaller numbers mean more frequent releases, which may introduce higher CPU time consumption and
smaller memory footprint while larger numbers usually lead to less CPU time overhead and relatively larger memory footprint.
Just tune the number for your own use cases.

Configuring the argument to <code>0</code> essentially turns off the periodical memory trimming altogether.

<geshi lang="nginx">
    lua_malloc_trim 0;  # turn off trimming completely
</geshi>

The current implementation uses an Nginx log phase handler to do the request counting. So the appearance of the
[https://nginx.org/en/docs/http/ngx_http_core_module.html#log_subrequest log_subrequest on] directives in <code>nginx.conf</code>
may make the counting faster when subrequests are involved. By default, only "main requests" count.

Note that this directive does *not* affect the memory allocated by LuaJIT's own allocator based on the <code>mmap</code>
system call.

This directive was first introduced in the <code>v0.10.7</code> release.

== lua_code_cache ==
'''syntax:''' ''lua_code_cache on | off''

'''default:''' ''lua_code_cache on''

'''context:''' ''http, server, location, location if''

Enables or disables the Lua code cache for Lua code in <code>*_by_lua_file</code> directives (like [[#set_by_lua_file|set_by_lua_file]] and
[[#content_by_lua_file|content_by_lua_file]]) and Lua modules.

When turning off, every request served by ngx_lua will run in a separate Lua VM instance, starting from the <code>0.9.3</code> release. So the Lua files referenced in [[#set_by_lua_file|set_by_lua_file]],
[[#content_by_lua_file|content_by_lua_file]], [[#access_by_lua_file|access_by_lua_file]],
and etc will not be cached
and all Lua modules used will be loaded from scratch. With this in place, developers can adopt an edit-and-refresh approach.

Please note however, that Lua code written inlined within nginx.conf
such as those specified by [[#set_by_lua|set_by_lua]], [[#content_by_lua|content_by_lua]],
[[#access_by_lua|access_by_lua]], and [[#rewrite_by_lua|rewrite_by_lua]] will not be updated when you edit the inlined Lua code in your <code>nginx.conf</code> file because only the Nginx config file parser can correctly parse the <code>nginx.conf</code>
file and the only way is to reload the config file
by sending a <code>HUP</code> signal or just to restart Nginx.

Even when the code cache is enabled, Lua files which are loaded by <code>dofile</code> or <code>loadfile</code>
in *_by_lua_file cannot be cached (unless you cache the results yourself). Usually you can either use the [[#init_by_lua|init_by_lua]]
or [[#init-by_lua_file|init_by_lua_file]] directives to load all such files or just make these Lua files true Lua modules
and load them via <code>require</code>.

The ngx_lua module does not support the <code>stat</code> mode available with the
Apache <code>mod_lua</code> module (yet).

Disabling the Lua code cache is strongly
discouraged for production use and should only be used during
development as it has a significant negative impact on overall performance. For example, the performance of a "hello world" Lua example can drop by an order of magnitude after disabling the Lua code cache.

== lua_thread_cache_max_entries ==

'''syntax:''' ''lua_thread_cache_max_entries <num>''

'''default:''' ''lua_thread_cache_max_entries 1024''

'''context:''' ''http''

Specifies the maximum number of entries allowed in the worker process level lua thread object cache.

This cache recycles the lua thread GC objects among all our "light threads".

A zero value of `<num>` disables the cache.

Note that this feature requires OpenResty's LuaJIT with the new C API `lua_resetthread`.

This feature was first introduced in verson `v0.10.9`.

== lua_regex_cache_max_entries ==

'''syntax:''' ''lua_regex_cache_max_entries <num>''

'''default:''' ''lua_regex_cache_max_entries 1024''

'''context:''' ''http''

Specifies the maximum number of entries allowed in the worker process level compiled regex cache.

The regular expressions used in [[#ngx.re.match|ngx.re.match]], [[#ngx.re.gmatch|ngx.re.gmatch]], [[#ngx.re.sub|ngx.re.sub]], and [[#ngx.re.gsub|ngx.re.gsub]] will be cached within this cache if the regex option <code>o</code> (i.e., compile-once flag) is specified.

The default number of entries allowed is 1024 and when this limit is reached, new regular expressions will not be cached (as if the <code>o</code> option was not specified) and there will be one, and only one, warning in the <code>error.log</code> file:

<geshi lang="text">
    2011/08/27 23:18:26 [warn] 31997#0: *1 lua exceeding regex cache max entries (1024), ...
</geshi>

If you are using the <code>ngx.re.*</code> implementation of [lua-resty-core](https://github.com/openresty/lua-resty-core) by loading the <code>resty.core.regex</code> module (or just the <code>resty.core</code> module), then an LRU cache is used for the regex cache being used here.

Do not activate the <code>o</code> option for regular expressions (and/or <code>replace</code> string arguments for [[#ngx.re.sub|ngx.re.sub]] and [[#ngx.re.gsub|ngx.re.gsub]]) that are generated ''on the fly'' and give rise to infinite variations to avoid hitting the specified limit.

== lua_regex_match_limit ==

'''syntax:''' ''lua_regex_match_limit <num>''

'''default:''' ''lua_regex_match_limit 0''

'''context:''' ''http''

Specifies the "match limit" used by the PCRE library when executing the [[#ngx.re.match|ngx.re API]]. To quote the PCRE manpage, "the limit ... has the effect of limiting the amount of backtracking that can take place."

When the limit is hit, the error string "pcre_exec() failed: -8" will be returned by the [[#ngx.re.match|ngx.re API]] functions on the Lua land.

When setting the limit to 0, the default "match limit" when compiling the PCRE library is used. And this is the default value of this directive.

This directive was first introduced in the <code>v0.8.5</code> release.

== lua_package_path ==

'''syntax:''' ''lua_package_path <lua-style-path-str>''

'''default:''' ''The content of LUA_PATH environment variable or Lua's compiled-in defaults.''

'''context:''' ''http''

Sets the Lua module search path used by scripts specified by [[#set_by_lua|set_by_lua]],
[[#content_by_lua|content_by_lua]] and others. The path string is in standard Lua path form, and <code>;;</code>
can be used to stand for the original search paths.

As from the <code>v0.5.0rc29</code> release, the special notation <code>$prefix</code> or <code>${prefix}</code> can be used in the search path string to indicate the path of the <code>server prefix</code> usually determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

== lua_package_cpath ==

'''syntax:''' ''lua_package_cpath <lua-style-cpath-str>''

'''default:''' ''The content of LUA_CPATH environment variable or Lua's compiled-in defaults.''

'''context:''' ''http''

Sets the Lua C-module search path used by scripts specified by [[#set_by_lua|set_by_lua]],
[[#content_by_lua|content_by_lua]] and others. The cpath string is in standard Lua cpath form, and <code>;;</code>
can be used to stand for the original cpath.

As from the <code>v0.5.0rc29</code> release, the special notation <code>$prefix</code> or <code>${prefix}</code> can be used in the search path string to indicate the path of the <code>server prefix</code> usually determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

== init_by_lua ==

'''syntax:''' ''init_by_lua <lua-script-str>''

'''context:''' ''http''

'''phase:''' ''loading-config''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#init_by_lua_block|init_by_lua_block]] directive instead.

Similar to the [[#init_by_lua_block|init_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    init_by_lua '
        print("I need no extra escaping here, for example: \r\nblah")
    '
</geshi>

This directive was first introduced in the <code>v0.5.5</code> release.

== init_by_lua_block ==

'''syntax:''' ''init_by_lua_block { lua-script }''

'''context:''' ''http''

'''phase:''' ''loading-config''


When Nginx receives the <code>HUP</code> signal and starts reloading the config file, the Lua VM will also be re-created and <code>init_by_lua_block</code> will run again on the new Lua VM. In case that the [[#lua_code_cache|lua_code_cache]] directive is turned off (default on), the <code>init_by_lua_block</code> handler will run upon every request because in this special mode a standalone Lua VM is always created for each request.

Usually you can pre-load Lua modules at server start-up by means of this hook and take advantage of modern operating systems' copy-on-write (COW) optimization. Here is an example for pre-loading Lua modules:

<geshi lang="nginx">
    # this runs before forking out nginx worker processes:
    init_by_lua_block { require "cjson" }

    server {
        location = /api {
            content_by_lua_block {
                -- the following require() will just  return
                -- the already loaded module from package.loaded:
                ngx.say(require "cjson".encode{dog = 5, cat = 6})
            }
        }
    }
</geshi>

You can also initialize the [[#lua_shared_dict|lua_shared_dict]] shm storage at this phase. Here is an example for this:

<geshi lang="nginx">
    lua_shared_dict dogs 1m;

    init_by_lua_block {
        local dogs = ngx.shared.dogs
        dogs:set("Tom", 56)
    }

    server {
        location = /api {
            content_by_lua_block {
                local dogs = ngx.shared.dogs
                ngx.say(dogs:get("Tom"))
            }
        }
    }
</geshi>

But note that, the [[#lua_shared_dict|lua_shared_dict]]'s shm storage will not be cleared through a config reload (via the <code>HUP</code> signal, for example). So if you do ''not'' want to re-initialize the shm storage in your <code>init_by_lua_block</code> code in this case, then you just need to set a custom flag in the shm storage and always check the flag in your <code>init_by_lua_block</code> code.

Because the Lua code in this context runs before Nginx forks its worker processes (if any), data or code loaded here will enjoy the [https://en.wikipedia.org/wiki/Copy-on-write Copy-on-write (COW)] feature provided by many operating systems among all the worker processes, thus saving a lot of memory.

Do *not* initialize your own Lua global variables in this context because use of Lua global variables have performance penalties and can lead to global namespace pollution (see the [[#Lua_Variable_Scope|Lua Variable Scope]] section for more details). The recommended way is to use proper [https://www.lua.org/manual/5.1/manual.html#5.3 Lua module] files (but do not use the standard Lua function [https://www.lua.org/manual/5.1/manual.html#pdf-module module()] to define Lua modules because it pollutes the global namespace as well) and call [https://www.lua.org/manual/5.1/manual.html#pdf-require require()] to load your own module files in <code>init_by_lua_block</code> or other contexts ([https://www.lua.org/manual/5.1/manual.html#pdf-require require()] does cache the loaded Lua modules in the global <code>package.loaded</code> table in the Lua registry so your modules will only loaded once for the whole Lua VM instance).

Only a small set of the [[#Nginx API for Lua|Nginx API for Lua]] is supported in this context:

* Logging APIs: [[#ngx.log|ngx.log]] and [[#print|print]],
* Shared Dictionary API: [[#ngx.shared.DICT|ngx.shared.DICT]].

More Nginx APIs for Lua may be supported in this context upon future user requests.

Basically you can safely use Lua libraries that do blocking I/O in this very context because blocking the master process during server start-up is completely okay. Even the Nginx core does blocking I/O (at least on resolving upstream's host names) at the configure-loading phase.

You should be very careful about potential security vulnerabilities in your Lua code registered in this context because the Nginx master process is often run under the <code>root</code> account.

This directive was first introduced in the <code>v0.9.17</code> release.

See also the following blog posts for more details on OpenResty and Nginx's shared memory zones:

* [How OpenResty and Nginx Shared Memory Zones Consume RAM](https://blog.openresty.com/en/how-nginx-shm-consume-ram/?src=gh_ngxlua)
* [Memory Fragmentation in OpenResty and Nginx's Shared Memory Zones](https://blog.openresty.com/en/nginx-shm-frag/?src=gh_ngxlua)

== init_by_lua_file ==

'''syntax:''' ''init_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http''

'''phase:''' ''loading-config''

Equivalent to [[#init_by_lua_block|init_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code or [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.5.5</code> release.

== init_worker_by_lua ==

'''syntax:''' ''init_worker_by_lua <lua-script-str>''

'''context:''' ''http''

'''phase:''' ''starting-worker''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#init_worker_by_lua_block|init_worker_by_lua_block]] directive instead.

Similar to the [[#init_worker_by_lua_block|init_worker_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    init_worker_by_lua '
        print("I need no extra escaping here, for example: \r\nblah")
    ';
</geshi>

This directive was first introduced in the <code>v0.9.5</code> release.

This hook no longer runs in the cache manager and cache loader processes since the <code>v0.10.12</code> release.

== init_worker_by_lua_block ==

'''syntax:''' ''init_worker_by_lua_block { lua-script }''

'''context:''' ''http''

'''phase:''' ''starting-worker''

Runs the specified Lua code upon every Nginx worker process's startup when the master process is enabled. When the master process is disabled, this hook will just run after [[#init_by_lua_block|init_by_lua*]].

This hook is often used to create per-worker reoccurring timers (via the [[#ngx.timer.at|ngx.timer.at]] Lua API), either for backend health-check or other timed routine work. Below is an example,

<geshi lang="nginx">
    init_worker_by_lua_block {
        local delay = 3  -- in seconds
        local new_timer = ngx.timer.at
        local log = ngx.log
        local ERR = ngx.ERR
        local check

        check = function(premature)
            if not premature then
                -- do the health check or other routine work
                local ok, err = new_timer(delay, check)
                if not ok then
                    log(ERR, "failed to create timer: ", err)
                    return
                end
            end

            -- do something in timer
        end

        local hdl, err = new_timer(delay, check)
        if not hdl then
            log(ERR, "failed to create timer: ", err)
            return
        end

        -- other job in init_worker_by_lua
    }
</geshi>

This directive was first introduced in the <code>v0.9.17</code> release.

This hook no longer runs in the cache manager and cache loader processes since the <code>v0.10.12</code> release.

== init_worker_by_lua_file ==

'''syntax:''' ''init_worker_by_lua_file <lua-file-path>''

'''context:''' ''http''

'''phase:''' ''starting-worker''

Similar to [[#init_worker_by_lua_block|init_worker_by_lua_block]], but accepts the file path to a Lua source file or Lua bytecode file.

This directive was first introduced in the <code>v0.9.5</code> release.

This hook no longer runs in the cache manager and cache loader processes since the <code>v0.10.12</code> release.

== exit_worker_by_lua_block ==

'''syntax:''' ''exit_worker_by_lua_block { lua-script }''

'''context:''' ''http''

'''phase:''' ''exiting-worker''

Runs the specified Lua code upon every Nginx worker process's exit when the master process is enabled. When the master process is disabled, this hook will run before the Nginx process exits.

This hook is often used to release resources allocated by each worker (e.g. resources allocated by [[#init_worker_by_lua_block|init_worker_by_lua*]]), or to prevent workers from exiting abnormally.

For example,

<geshi lang="nginx">
    exit_worker_by_lua_block {
        print("log from exit_worker_by_lua_block")
    }
</geshi>

It's not allowed to create a timer (even a 0-delay timer) here since it runs after all timers have been processed.

This directive was first introduced in the <code>v0.10.18</code> release.

== exit_worker_by_lua_file ==

'''syntax:''' ''exit_worker_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http''

'''phase:''' ''exiting-worker''

Similar to [[#exit_worker_by_lua_block|exit_worker_by_lua_block]], but accepts the file path to a Lua source file or Lua bytecode file.

This directive was first introduced in the <code>v0.10.18</code> release.

== set_by_lua ==

'''syntax:''' ''set_by_lua $res <lua-script-str> [$arg1 $arg2 ...]''

'''context:''' ''server, server if, location, location if''

'''phase:''' ''rewrite''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#set_by_lua_block|set_by_lua_block]] directive instead.

Similar to the [[#set_by_lua_block|set_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping), and
# this directive support extra arguments after the Lua script.

For example,

<geshi lang="nginx">
    set_by_lua $res ' return 32 + math.cos(32) ';
    # $res now has the value "32.834223360507" or alike.
</geshi>

As from the <code>v0.5.0rc29</code> release, Nginx variable interpolation is disabled in the <code><lua-script-str></code> argument of this directive and therefore, the dollar sign character (<code>$</code>) can be used directly.

This directive requires the [https://github.com/simplresty/ngx_devel_kit ngx_devel_kit] module.

== set_by_lua_block ==

'''syntax:''' ''set_by_lua_block $res { lua-script }''

'''context:''' ''server, server if, location, location if''

'''phase:''' ''rewrite''

Executes code specified inside a pair of curly braces (<code>{}</code>), and returns string output to <code>$res</code>.
The code inside a pair of curly braces (<code>{}</code>) can make [[#Nginx API for Lua|API calls]] and can retrieve input arguments from the <code>ngx.arg</code> table (index starts from <code>1</code> and increases sequentially).

This directive is designed to execute short, fast running code blocks as the Nginx event loop is blocked during code execution. Time consuming code sequences should therefore be avoided.

This directive is implemented by injecting custom commands into the standard [[HttpRewriteModule]]'s command list. Because [[HttpRewriteModule]] does not support nonblocking I/O in its commands, Lua APIs requiring yielding the current Lua "light thread" cannot work in this directive.

At least the following API functions are currently disabled within the context of <code>set_by_lua_block</code>:

* Output API functions (e.g., [[#ngx.say|ngx.say]] and [[#ngx.send_headers|ngx.send_headers]])
* Control API functions (e.g., [[#ngx.exit|ngx.exit]])
* Subrequest API functions (e.g., [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]])
* Cosocket API functions (e.g., [[#ngx.socket.tcp|ngx.socket.tcp]] and [[#ngx.req.socket|ngx.req.socket]]).
* Sleeping API function [[#ngx.sleep|ngx.sleep]].

In addition, note that this directive can only write out a value to a single Nginx variable at
a time. However, a workaround is possible using the [[#ngx.var.VARIABLE|ngx.var.VARIABLE]] interface.

<geshi lang="nginx">
    location /foo {
        set $diff ''; # we have to predefine the $diff variable here

        set_by_lua_block $sum {
            local a = 32
            local b = 56

            ngx.var.diff = a - b  -- write to $diff directly
            return a + b          -- return the $sum value normally
        }

        echo "sum = $sum, diff = $diff";
    }
</geshi>

This directive can be freely mixed with all directives of the [[HttpRewriteModule]], [[HttpSetMiscModule]], and [[HttpArrayVarModule]] modules. All of these directives will run in the same order as they appear in the config file.

<geshi lang="nginx">
    set $foo 32;
    set_by_lua_block $bar { return tonumber(ngx.var.foo) + 1 }
    set $baz "bar: $bar";  # $baz == "bar: 33"
</geshi>

No special escaping is required in the Lua code block.

This directive requires the [https://github.com/simplresty/ngx_devel_kit ngx_devel_kit] module.

This directive was first introduced in the <code>v0.9.17</code> release.

== set_by_lua_file ==

'''syntax:''' ''set_by_lua_file $res <path-to-lua-script-file> [$arg1 $arg2 ...]''

'''context:''' ''server, server if, location, location if''

'''phase:''' ''rewrite''

Equivalent to [[#set_by_lua_block|set_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

Nginx variable interpolation is supported in the <code><path-to-lua-script-file></code> argument string of this directive. But special care must be taken for injection attacks.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached
and the Nginx config must be reloaded each time the Lua source file is modified.
The Lua code cache can be temporarily disabled during development by
switching [[#lua_code_cache|lua_code_cache]] <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.

This directive requires the [https://github.com/simplresty/ngx_devel_kit ngx_devel_kit] module.

== content_by_lua ==

'''syntax:''' ''content_by_lua <lua-script-str>''

'''context:''' ''location, location if''

'''phase:''' ''content''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#content_by_lua_block|content_by_lua_block]] directive instead.

Similar to the [[#content_by_lua_block|content_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    content_by_lua '
        ngx.say("I need no extra escaping here, for example: \r\nblah")
    ';
</geshi>

== content_by_lua_block ==

'''syntax:''' ''content_by_lua_block { lua-script }''

'''context:''' ''location, location if''

'''phase:''' ''content''

For instance,

<geshi lang="nginx">
    content_by_lua_block {
        ngx.say("I need no extra escaping here, for example: \r\nblah")
    }
</geshi>

Acts as a "content handler" and executes Lua code string specified in <code>{ lua-script }</code> for every request.
The Lua code may make [[#Nginx API for Lua|API calls]] and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).

Do not use this directive and other content handler directives in the same location. For example, this directive and the [[HttpProxyModule#proxy_pass|proxy_pass]] directive should not be used in the same location.

This directive was first introduced in the <code>v0.9.17</code> release.

== content_by_lua_file ==

'''syntax:''' ''content_by_lua_file <path-to-lua-script-file>''

'''context:''' ''location, location if''

'''phase:''' ''content''

Equivalent to [[#content_by_lua_block|content_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

Nginx variables can be used in the <code><path-to-lua-script-file></code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached
and the Nginx config must be reloaded each time the Lua source file is modified.
The Lua code cache can be temporarily disabled during development by
switching [[#lua_code_cache|lua_code_cache]] <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.

Nginx variables are supported in the file path for dynamic dispatch, for example:

<geshi lang="nginx">
    # CAUTION: contents in nginx var must be carefully filtered,
    # otherwise there'll be great security risk!
    location ~ ^/app/([-_a-zA-Z0-9/]+) {
        set $path $1;
        content_by_lua_file /path/to/lua/app/root/$path.lua;
    }
</geshi>

But be very careful about malicious user inputs and always carefully validate or filter out the user-supplied path components.

== server_rewrite_by_lua_block ==

'''syntax:''' ''server_rewrite_by_lua_block { lua-script }''

'''context:''' ''http, server''

'''phase:''' ''server rewrite''

Acts as a server rewrite phase handler and executes Lua code string specified in <code>{ lua-script }</code> for every request.
The Lua code may make [[#Nginx API for Lua|API calls]] and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).

<geshi lang="nginx">
server {
    ...

    server_rewrite_by_lua_block {
        ngx.ctx.a = "server_rewrite_by_lua_block in http"
    }

    location /lua {
        content_by_lua_block {
            ngx.say(ngx.ctx.a)
            ngx.log(ngx.INFO, ngx.ctx.a)
       	}
    }
}
</geshi>

Just as any other rewrite phase handlers, [[#server_rewrite_by_lua_block|server_rewrite_by_lua_block]] also runs in subrequests.

<geshi lang="nginx">
server {
    server_rewrite_by_lua_block {
        ngx.log(ngx.INFO, "is_subrequest:", ngx.is_subrequest)
    }

    location /lua {
        content_by_lua_block {
            local res = ngx.location.capture("/sub")
            ngx.print(res.body)
        }
    }

    location /sub {
        content_by_lua_block {
            ngx.say("OK")
        }
    }
}
</geshi>

Note that when calling <code>ngx.exit(ngx.OK)</code> within a [[#server_rewrite_by_lua_block|server_rewrite_by_lua_block]] handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a [[#server_rewrite_by_lua_block|server_rewrite_by_lua_block]] handler, call [[#ngx.exit|ngx.exit]] with status >= 200 (<code>ngx.HTTP_OK</code>) and status < 300 (<code>ngx.HTTP_SPECIAL_RESPONSE</code>) for successful quits and <code>ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)</code> (or its friends) for failures.


<geshi lang="nginx">
    server_rewrite_by_lua_block {
        ngx.exit(503)
    }

    location /bar {
        ...
        # never exec
    }
</geshi>


== server_rewrite_by_lua_file ==

'''syntax:''' ''server_rewrite_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server''

'''phase:''' ''server rewrite''

Equivalent to [[#server_rewrite_by_lua_block|server_rewrite_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.10.22</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

Nginx variables can be used in the <code><path-to-lua-script-file></code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching [[#lua_code_cache|lua_code_cache]] <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.

== rewrite_by_lua ==

'''syntax:''' ''rewrite_by_lua <lua-script-str>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''rewrite tail''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#rewrite_by_lua_block|rewrite_by_lua_block]] directive instead.

Similar to the [[#rewrite_by_lua_block|rewrite_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    rewrite_by_lua '
        do_something("hello, world!\nhiya\n")
    ';
</geshi>

== rewrite_by_lua_block ==

'''syntax:''' ''rewrite_by_lua_block { lua-script }''

'''context:''' ''http, server, location, location if''

'''phase:''' ''rewrite tail''

Acts as a rewrite phase handler and executes Lua code string specified in <code>{ lua-script }</code> for every request.
The Lua code may make [[#Nginx API for Lua|API calls]] and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).

Note that this handler always runs ''after'' the standard [[HttpRewriteModule]]. So the following will work as expected:

<geshi lang="nginx">
    location /foo {
        set $a 12; # create and initialize $a
        set $b ""; # create and initialize $b
        rewrite_by_lua_block {
            ngx.var.b = tonumber(ngx.var.a) + 1
        }
        echo "res = $b";
    }
</geshi>

because <code>set $a 12</code> and <code>set $b ""</code> run ''before'' [[#rewrite_by_lua_block|rewrite_by_lua_block]].

On the other hand, the following will not work as expected:

<geshi lang="nginx">
    ?  location /foo {
    ?      set $a 12; # create and initialize $a
    ?      set $b ''; # create and initialize $b
    ?      rewrite_by_lua_block {
    ?          ngx.var.b = tonumber(ngx.var.a) + 1
    ?      }
    ?      if ($b = '13') {
    ?         rewrite ^ /bar redirect;
    ?         break;
    ?      }
    ?
    ?      echo "res = $b";
    ?  }
</geshi>

because <code>if</code> runs ''before'' [[#rewrite_by_lua_block|rewrite_by_lua_block]] even if it is placed after [[#rewrite_by_lua_block|rewrite_by_lua_block]] in the config.

The right way of doing this is as follows:

<geshi lang="nginx">
    location /foo {
        set $a 12; # create and initialize $a
        set $b ''; # create and initialize $b
        rewrite_by_lua_block {
            ngx.var.b = tonumber(ngx.var.a) + 1
            if tonumber(ngx.var.b) == 13 then
                return ngx.redirect("/bar")
            end
        }

        echo "res = $b";
    }
</geshi>

Note that the [http://www.grid.net.ru/nginx/eval.en.html ngx_eval] module can be approximated by using [[#rewrite_by_lua_block|rewrite_by_lua_block]]. For example,

<geshi lang="nginx">
    location / {
        eval $res {
            proxy_pass http://foo.com/check-spam;
        }

        if ($res = 'spam') {
            rewrite ^ /terms-of-use.html redirect;
        }

        fastcgi_pass ...;
    }
</geshi>

can be implemented in ngx_lua as:

<geshi lang="nginx">
    location = /check-spam {
        internal;
        proxy_pass http://foo.com/check-spam;
    }

    location / {
        rewrite_by_lua_block {
            local res = ngx.location.capture("/check-spam")
            if res.body == "spam" then
                return ngx.redirect("/terms-of-use.html")
            end
        }

        fastcgi_pass ...;
    }
</geshi>

Just as any other rewrite phase handlers, [[#rewrite_by_lua_block|rewrite_by_lua_block]] also runs in subrequests.

Note that when calling <code>ngx.exit(ngx.OK)</code> within a [[#rewrite_by_lua_block|rewrite_by_lua_block]] handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a [[#rewrite_by_lua_block|rewrite_by_lua_block]] handler, call [[#ngx.exit|ngx.exit]] with status >= 200 (<code>ngx.HTTP_OK</code>) and status < 300 (<code>ngx.HTTP_SPECIAL_RESPONSE</code>) for successful quits and <code>ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)</code> (or its friends) for failures.

If the [[HttpRewriteModule]]'s [[HttpRewriteModule#rewrite|rewrite]] directive is used to change the URI and initiate location re-lookups (internal redirections), then any [[#rewrite_by_lua_block|rewrite_by_lua_block]] or [[#rewrite_by_lua_file_block|rewrite_by_lua_file_block]] code sequences within the current location will not be executed. For example,

<geshi lang="nginx">
    location /foo {
        rewrite ^ /bar;
        rewrite_by_lua_block {
            ngx.exit(503)
        }
    }
    location /bar {
        ...
    }
</geshi>

Here the Lua code <code>ngx.exit(503)</code> will never run. This will be the case if <code>rewrite ^ /bar last</code> is used as this will similarly initiate an internal redirection. If the <code>break</code> modifier is used instead, there will be no internal redirection and the <code>rewrite_by_lua_block</code> code will be executed.

The <code>rewrite_by_lua_block</code> code will always run at the end of the <code>rewrite</code> request-processing phase unless [[#rewrite_by_lua_no_postpone|rewrite_by_lua_no_postpone]] is turned on.

This directive was first introduced in the <code>v0.9.17</code> release.

== rewrite_by_lua_file ==

'''syntax:''' ''rewrite_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''rewrite tail''

Equivalent to [[#rewrite_by_lua_block|rewrite_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

Nginx variables can be used in the <code><path-to-lua-script-file></code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached and the Nginx config must be reloaded each time the Lua source file is modified. The Lua code cache can be temporarily disabled during development by switching [[#lua_code_cache|lua_code_cache]] <code>off</code> in <code>nginx.conf</code> to avoid reloading Nginx.

The <code>rewrite_by_lua_file</code> code will always run at the end of the <code>rewrite</code> request-processing phase unless [[#rewrite_by_lua_no_postpone|rewrite_by_lua_no_postpone]] is turned on.

Nginx variables are supported in the file path for dynamic dispatch just as in [[#content_by_lua_file|content_by_lua_file]].

== access_by_lua ==

'''syntax:''' ''access_by_lua <lua-script-str>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''access tail''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#access_by_lua_block|access_by_lua_block]] directive instead.

Similar to the [[#access_by_lua_block|access_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    access_by_lua '
        do_something("hello, world!\nhiya\n")
    ';
</geshi>

== access_by_lua_block ==

'''syntax:''' ''access_by_lua_block { lua-script }''

'''context:''' ''http, server, location, location if''

'''phase:''' ''access tail''

Acts as an access phase handler and executes Lua code string specified in <code>{ <lua-script }</code> for every request.
The Lua code may make [[#Nginx API for Lua|API calls]] and is executed as a new spawned coroutine in an independent global environment (i.e. a sandbox).

Note that this handler always runs ''after'' the standard [[HttpAccessModule]]. So the following will work as expected:

<geshi lang="nginx">
    location / {
        deny    192.168.1.1;
        allow   192.168.1.0/24;
        allow   10.1.1.0/16;
        deny    all;

        access_by_lua_block {
            local res = ngx.location.capture("/mysql", { ... })
            ...
        }

        # proxy_pass/fastcgi_pass/...
    }
</geshi>

That is, if a client IP address is in the blacklist, it will be denied before the MySQL query for more complex authentication is executed by [[#access_by_lua_block|access_by_lua_block]].

Note that the [http://mdounin.ru/hg/ngx_http_auth_request_module/ ngx_auth_request] module can be approximated by using [[#access_by_lua_block|access_by_lua_block]]:

<geshi lang="nginx">
    location / {
        auth_request /auth;

        # proxy_pass/fastcgi_pass/postgres_pass/...
    }
</geshi>

can be implemented in ngx_lua as:

<geshi lang="nginx">
    location / {
        access_by_lua_block {
            local res = ngx.location.capture("/auth")

            if res.status == ngx.HTTP_OK then
                return
            end

            if res.status == ngx.HTTP_FORBIDDEN then
                ngx.exit(res.status)
            end

            ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)
        }

        # proxy_pass/fastcgi_pass/postgres_pass/...
    }
</geshi>

As with other access phase handlers, [[#access_by_lua_block|access_by_lua_block]] will ''not'' run in subrequests.

Note that when calling <code>ngx.exit(ngx.OK)</code> within a [[#access_by_lua_block|access_by_lua_block]] handler, the Nginx request processing control flow will still continue to the content handler. To terminate the current request from within a [[#access_by_lua_block|access_by_lua_block]] handler, call [[#ngx.exit|ngx.exit]] with status >= 200 (<code>ngx.HTTP_OK</code>) and status < 300 (<code>ngx.HTTP_SPECIAL_RESPONSE</code>) for successful quits and <code>ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)</code> (or its friends) for failures.

Starting from the <code>v0.9.20</code> release, you can use the [[#access_by_lua_no_postpone|access_by_lua_no_postpone]]
directive to control when to run this handler inside the "access" request-processing phase
of Nginx.

This directive was first introduced in the <code>v0.9.17</code> release.

== access_by_lua_file ==

'''syntax:''' ''access_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''access tail''

Equivalent to [[#access_by_lua_block|access_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

Nginx variables can be used in the <code><path-to-lua-script-file></code> string to provide flexibility. This however carries some risks and is not ordinarily recommended.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

When the Lua code cache is turned on (by default), the user code is loaded once at the first request and cached
and the Nginx config must be reloaded each time the Lua source file is modified.
The Lua code cache can be temporarily disabled during development by switching [[#lua_code_cache|lua_code_cache]] <code>off</code> in <code>nginx.conf</code> to avoid repeatedly reloading Nginx.

Nginx variables are supported in the file path for dynamic dispatch just as in [[#content_by_lua_file|content_by_lua_file]].

== header_filter_by_lua ==

'''syntax:''' ''header_filter_by_lua <lua-script-str>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''output-header-filter''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#header_filter_by_lua_block|header_filter_by_lua_block]] directive instead.

Similar to the [[#header_filter_by_lua_block|header_filter_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    header_filter_by_lua '
        ngx.header["content-length"] = nil
    ';
</geshi>

This directive was first introduced in the <code>v0.2.1rc20</code> release.

== header_filter_by_lua_block ==

'''syntax:''' ''header_filter_by_lua_block { lua-script }''

'''context:''' ''http, server, location, location if''

'''phase:''' ''output-header-filter''

Uses Lua code specified in <code>{ lua-script }</code> to define an output header filter.

Note that the following API functions are currently disabled within this context:

* Output API functions (e.g., [[#ngx.say|ngx.say]] and [[#ngx.send_headers|ngx.send_headers]])
* Control API functions (e.g., [[#ngx.redirect|ngx.redirect]] and [[#ngx.exec|ngx.exec]])
* Subrequest API functions (e.g., [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]])
* Cosocket API functions (e.g., [[#ngx.socket.tcp|ngx.socket.tcp]] and [[#ngx.req.socket|ngx.req.socket]]).

Here is an example of overriding a response header (or adding one if absent) in our Lua header filter:

<geshi lang="nginx">
    location / {
        proxy_pass http://mybackend;
        header_filter_by_lua_block {
            ngx.header.Foo = "blah"
        }
    }
</geshi>

This directive was first introduced in the <code>v0.9.17</code> release.

== header_filter_by_lua_file ==

'''syntax:''' ''header_filter_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''output-header-filter''

Equivalent to [[#header_filter_by_lua_block|header_filter_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.2.1rc20</code> release.

== body_filter_by_lua ==

'''syntax:''' ''body_filter_by_lua <lua-script-str>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''output-body-filter''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#body_filter_by_lua_block|body_filter_by_lua_block]] directive instead.

Similar to the [[#body_filter_by_lua_block|body_filter_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    body_filter_by_lua '
        local data, eof = ngx.arg[1], ngx.arg[2]
    ';
</geshi>

This directive was first introduced in the <code>v0.5.0rc32</code> release.

== body_filter_by_lua_block ==

'''syntax:''' ''body_filter_by_lua_block { lua-script-str }''

'''context:''' ''http, server, location, location if''

'''phase:''' ''output-body-filter''

Uses Lua code specified in <code>{ lua-script }</code> to define an output body filter.

The input data chunk is passed via [[#ngx.arg|ngx.arg]][1] (as a Lua string value) and the "eof" flag indicating the end of the response body data stream is passed via [[#ngx.arg|ngx.arg]][2] (as a Lua boolean value).

Behind the scene, the "eof" flag is just the <code>last_buf</code> (for main requests) or <code>last_in_chain</code> (for subrequests) flag of the Nginx chain link buffers. (Before the <code>v0.7.14</code> release, the "eof" flag does not work at all in subrequests.)

The output data stream can be aborted immediately by running the following Lua statement:

<geshi lang="lua">
    return ngx.ERROR
</geshi>

This will truncate the response body and usually result in incomplete and also invalid responses.

The Lua code can pass its own modified version of the input data chunk to the downstream Nginx output body filters by overriding [[#ngx.arg|ngx.arg]][1] with a Lua string or a Lua table of strings. For example, to transform all the lowercase letters in the response body, we can just write:

<geshi lang="nginx">
    location / {
        proxy_pass http://mybackend;
        body_filter_by_lua_block {
            ngx.arg[1] = string.upper(ngx.arg[1])
        }
    }
</geshi>

When setting <code>nil</code> or an empty Lua string value to <code>ngx.arg[1]</code>, no data chunk will be passed to the downstream Nginx output filters at all.

Likewise, new "eof" flag can also be specified by setting a boolean value to [[#ngx.arg|ngx.arg]][2]. For example,

<geshi lang="nginx">
    location /t {
        echo hello world;
        echo hiya globe;

        body_filter_by_lua_block {
            local chunk = ngx.arg[1]
            if string.match(chunk, "hello") then
                ngx.arg[2] = true  -- new eof
                return
            end

            -- just throw away any remaining chunk data
            ngx.arg[1] = nil
        }
    }
</geshi>

Then <code>GET /t</code> will just return the output

<geshi lang="text">
    hello world
</geshi>

That is, when the body filter sees a chunk containing the word "hello", then it will set the "eof" flag to true immediately, resulting in truncated but still valid responses.

When the Lua code may change the length of the response body, then it is required to always clear out the <code>Content-Length</code> response header (if any) in a header filter to enforce streaming output, as in

<geshi lang="nginx">
    location /foo {
        # fastcgi_pass/proxy_pass/...

        header_filter_by_lua_block {
            ngx.header.content_length = nil
        }
        body_filter_by_lua_block {
            ngx.arg[1] = string.len(ngx.arg[1]) .. "\n"
        }
    }
</geshi>

Note that the following API functions are currently disabled within this context due to the limitations in Nginx output filter's current implementation:

* Output API functions (e.g., [[#ngx.say|ngx.say]] and [[#ngx.send_headers|ngx.send_headers]])
* Control API functions (e.g., [[#ngx.exit|ngx.exit]] and [[#ngx.exec|ngx.exec]])
* Subrequest API functions (e.g., [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]])
* Cosocket API functions (e.g., [[#ngx.socket.tcp|ngx.socket.tcp]] and [[#ngx.req.socket|ngx.req.socket]]).

Nginx output filters may be called multiple times for a single request because response body may be delivered in chunks. Thus, the Lua code specified by in this directive may also run multiple times in the lifetime of a single HTTP request.

This directive was first introduced in the <code>v0.9.17</code> release.

== body_filter_by_lua_file ==

'''syntax:''' ''body_filter_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''output-body-filter''

Equivalent to [[#body_filter_by_lua_block|body_filter_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.5.0rc32</code> release.

== log_by_lua ==

'''syntax:''' ''log_by_lua <lua-script-str>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''log''

'''NOTE''' Use of this directive is ''discouraged'' following the <code>v0.9.17</code> release. Use the [[#log_by_lua_block|log_by_lua_block]] directive instead.

Similar to the [[#log_by_lua_block|log_by_lua_block]] directive, but accepts the Lua source directly in an Nginx string literal (which requires
special character escaping).

For instance,

<geshi lang="nginx">
    log_by_lua '
        print("I need no extra escaping here, for example: \r\nblah")
    ';
</geshi>

This directive was first introduced in the <code>v0.5.0rc31</code> release.

== log_by_lua_block ==

'''syntax:''' ''log_by_lua_block { lua-script }''

'''context:''' ''http, server, location, location if''

'''phase:''' ''log''

Runs the Lua source code inlined as the <code>{ lua-script }</code> at the <code>log</code> request processing phase. This does not replace the current access logs, but runs before.

Note that the following API functions are currently disabled within this context:

* Output API functions (e.g., [[#ngx.say|ngx.say]] and [[#ngx.send_headers|ngx.send_headers]])
* Control API functions (e.g., [[#ngx.exit|ngx.exit]])
* Subrequest API functions (e.g., [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]])
* Cosocket API functions (e.g., [[#ngx.socket.tcp|ngx.socket.tcp]] and [[#ngx.req.socket|ngx.req.socket]]).

Here is an example of gathering average data for [[HttpUpstreamModule#$upstream_response_time|$upstream_response_time]]:

<geshi lang="nginx">
    lua_shared_dict log_dict 5M;

    server {
        location / {
            proxy_pass http://mybackend;

            log_by_lua_block {
                local log_dict = ngx.shared.log_dict
                local upstream_time = tonumber(ngx.var.upstream_response_time)

                local sum = log_dict:get("upstream_time-sum") or 0
                sum = sum + upstream_time
                log_dict:set("upstream_time-sum", sum)

                local newval, err = log_dict:incr("upstream_time-nb", 1)
                if not newval and err == "not found" then
                    log_dict:add("upstream_time-nb", 0)
                    log_dict:incr("upstream_time-nb", 1)
                end
            }
        }

        location = /status {
            content_by_lua_block {
                local log_dict = ngx.shared.log_dict
                local sum = log_dict:get("upstream_time-sum")
                local nb = log_dict:get("upstream_time-nb")

                if nb and sum then
                    ngx.say("average upstream response time: ", sum / nb,
                            " (", nb, " reqs)")
                else
                    ngx.say("no data yet")
                end
            }
        }
    }
</geshi>

This directive was first introduced in the <code>v0.9.17</code> release.

== log_by_lua_file ==

'''syntax:''' ''log_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server, location, location if''

'''phase:''' ''log''

Equivalent to [[#log_by_lua_block|log_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.5.0rc31</code> release.

== balancer_by_lua_block ==

'''syntax:''' ''balancer_by_lua_block { lua-script }''

'''context:''' ''upstream''

'''phase:''' ''content''

This directive runs Lua code as an upstream balancer for any upstream entities defined
by the <code>upstream {}</code> configuration block.

For instance,

<geshi lang="nginx">
    upstream foo {
        server 127.0.0.1;
        balancer_by_lua_block {
            -- use Lua to do something interesting here
            -- as a dynamic balancer
        }
    }

    server {
        location / {
            proxy_pass http://foo;
        }
    }
</geshi>

The resulting Lua load balancer can work with any existing Nginx upstream modules
like [https://nginx.org/en/docs/http/ngx_http_proxy_module.html ngx_proxy] and
[https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html ngx_fastcgi].

Also, the Lua load balancer can work with the standard upstream connection pool mechanism,
i.e., the standard [https://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive keepalive] directive.
Just ensure that the [https://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive keepalive] directive
is used *after* this <code>balancer_by_lua_block</code> directive in a single <code>upstream {}</code> configuration block.

The Lua load balancer can totally ignore the list of servers defined in the <code>upstream {}</code> block
and select peer from a completely dynamic server list (even changing per request) via the
[https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/balancer.md ngx.balancer] module
from the [https://github.com/openresty/lua-resty-core lua-resty-core] library.

The Lua code handler registered by this directive might get called more than once in a single
downstream request when the Nginx upstream mechanism retries the request on conditions
specified by directives like the [https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream proxy_next_upstream]
directive.

This Lua code execution context does not support yielding, so Lua APIs that may yield
(like cosockets and "light threads") are disabled in this context. One can usually work
around this limitation by doing such operations in an earlier phase handler (like
[[#access_by_lua|access_by_lua*]]) and passing along the result into this context
via the [[#ngx.ctx|ngx.ctx]] table.

This directive was first introduced in the <code>v0.10.0</code> release.

== balancer_by_lua_file ==

'''syntax:''' ''balancer_by_lua_file <path-to-lua-script-file>''

'''context:''' ''upstream''

'''phase:''' ''content''

Equivalent to [[#balancer_by_lua_block|balancer_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.10.0</code> release.

== lua_need_request_body ==

'''syntax:''' ''lua_need_request_body <on|off>''

'''default:''' ''off''

'''context:''' ''http, server, location, location if''

'''phase:''' ''depends on usage''

Determines whether to force the request body data to be read before running rewrite/access/content_by_lua* or not. The Nginx core does not read the client request body by default and if request body data is required, then this directive should be turned <code>on</code> or the [[#ngx.req.read_body|ngx.req.read_body]] function should be called within the Lua code.

To read the request body data within the [[HttpCoreModule#$request_body|$request_body]] variable,
[[HttpCoreModule#client_body_buffer_size|client_body_buffer_size]] must have the same value as [[HttpCoreModule#client_max_body_size|client_max_body_size]]. Because when the content length exceeds [[HttpCoreModule#client_body_buffer_size|client_body_buffer_size]] but less than [[HttpCoreModule#client_max_body_size|client_max_body_size]], Nginx will buffer the data into a temporary file on the disk, which will lead to empty value in the [[HttpCoreModule#$request_body|$request_body]] variable.

If the current location includes [[#rewrite_by_lua|rewrite_by_lua*]] directives,
then the request body will be read just before the [[#rewrite_by_lua|rewrite_by_lua*]] code is run (and also at the
<code>rewrite</code> phase). Similarly, if only [[#content_by_lua|content_by_lua]] is specified,
the request body will not be read until the content handler's Lua code is
about to run (i.e., the request body will be read during the content phase).

It is recommended however, to use the [[#ngx.req.read_body|ngx.req.read_body]] and [[#ngx.req.discard_body|ngx.req.discard_body]] functions for finer control over the request body reading process instead.

This also applies to [[#access_by_lua|access_by_lua*]].

== ssl_client_hello_by_lua_block ==

'''syntax:''' ''ssl_client_hello_by_lua_block { lua-script }''

'''context:''' ''http, server''

'''phase:''' ''right-after-client-hello-message-was-processed''

This directive runs user Lua code when Nginx is about to post-process the SSL client hello message for the downstream
SSL (https) connections.

It is particularly useful for dynamically setting the SSL protocols according to the SNI.

It is also useful to do some custom operations according to the per-connection information in the client hello message.

For example, one can parse custom client hello extension and do the corresponding handling in pure Lua.

This Lua handler will always run whether the SSL session is resumed (via SSL session IDs or TLS session tickets) or not.
While the <code>ssl_certificate_by_lua*</code> Lua handler will only runs when initiating a full SSL handshake.

The [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl/clienthello.md ngx.ssl.clienthello] Lua modules
provided by the [https://github.com/openresty/lua-resty-core/#readme lua-resty-core]
library are particularly useful in this context.

Note that this handler runs in extremely early stage of SSL handshake, before the SSL client hello extensions are parsed.
So you can not use some Lua API like <code>ssl.server_name()</code> which is dependent on the later stage's processing.

Also note that only the directive in default server is valid for several virtual servers with the same IP address and port.

Below is a trivial example using the
[https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl/clienthello.md ngx.ssl.clienthello] module
at the same time:

<geshi lang="nginx">
server {
    listen 443 ssl;
    server_name   test.com;
    ssl_certificate /path/to/cert.crt;
    ssl_certificate_key /path/to/key.key;
    ssl_client_hello_by_lua_block {
        local ssl_clt = require "ngx.ssl.clienthello"
        local host, err = ssl_clt.get_client_hello_server_name()
        if host == "test.com" then
            ssl_clt.set_protocols({"TLSv1", "TLSv1.1"})
        elseif host == "test2.com" then
            ssl_clt.set_protocols({"TLSv1.2", "TLSv1.3"})
        elseif not host then
            ngx.log(ngx.ERR, "failed to get the SNI name: ", err)
            ngx.exit(ngx.ERROR)
        else
            ngx.log(ngx.ERR, "unknown SNI name: ", host)
            ngx.exit(ngx.ERROR)
        end
    }
    ...
}
server {
    listen 443 ssl;
    server_name   test2.com;
    ssl_certificate /path/to/cert.crt;
    ssl_certificate_key /path/to/key.key;
    ...
}
</geshi>

See more information in the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl/clienthello.md ngx.ssl.clienthello]
Lua modules' official documentation.

Uncaught Lua exceptions in the user Lua code immediately abort the current SSL session, so does the
[[#ngx.exit|ngx.exit]] call with an error code like <code>ngx.ERROR</code>.

This Lua code execution context *does* support yielding, so Lua APIs that may yield
(like cosockets, sleeping, and "light threads")
are enabled in this context

Note, you need to configure the [https://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_certificate ssl_certificate]
and [https://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_certificate_key ssl_certificate_key]
to avoid the following error while starting NGINX:

<geshi>
    nginx: [emerg] no ssl configured for the server
</geshi>

This directive requires OpenSSL 1.1.1 or greater.

If you are using the [official pre-built
packages](https://openresty.org/en/linux-packages.html) for
[OpenResty](https://openresty.org/) 1.21.4.1 or later, then everything should
work out of the box.

If you are not using the Nginx core shipped with
[OpenResty](https://openresty.org) 1.21.4.1 or later, you will need to apply
patches to the standard Nginx core:

https://openresty.org/en/nginx-ssl-patches.html

This directive was first introduced in the <code>v0.10.21</code> release.

== ssl_client_hello_by_lua_file ==

'''syntax:''' ''ssl_client_hello_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http, server''

'''phase:''' ''right-after-client-hello-message-was-processed''

Equivalent to [[#ssl_client_hello_by_lua_block|ssl_client_hello_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.10.21</code> release.

== ssl_certificate_by_lua_block ==

'''syntax:''' ''ssl_certificate_by_lua_block { lua-script }''

'''context:''' ''server''

'''phase:''' ''right-before-SSL-handshake''

This directive runs user Lua code when Nginx is about to start the SSL handshake for the downstream
SSL (https) connections.

It is particularly useful for setting the SSL certificate chain and the corresponding private key on a per-request
basis. It is also useful to load such handshake configurations nonblockingly from the remote (for example,
with the [[#ngx.socket.tcp|cosocket]] API). And one can also do per-request OCSP stapling handling in pure
Lua here as well.

Another typical use case is to do SSL handshake traffic control nonblockingly in this context,
with the help of the [https://github.com/openresty/lua-resty-limit-traffic lua-resty-limit-traffic#readme]
library, for example.

One can also do interesting things with the SSL handshake requests from the client side, like
rejecting old SSL clients using the SSLv3 protocol or even below selectively.

The [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md ngx.ssl]
and [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ocsp.md ngx.ocsp] Lua modules
provided by the [https://github.com/openresty/lua-resty-core/#readme lua-resty-core]
library are particularly useful in this context. You can use the Lua API offered by these two Lua modules
to manipulate the SSL certificate chain and private key for the current SSL connection
being initiated.

This Lua handler does not run at all, however, when Nginx/OpenSSL successfully resumes
the SSL session via SSL session IDs or TLS session tickets for the current SSL connection. In
other words, this Lua handler only runs when Nginx has to initiate a full SSL handshake.

Below is a trivial example using the
[https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md ngx.ssl] module
at the same time:

<geshi lang="nginx">
    server {
        listen 443 ssl;
        server_name   test.com;

        ssl_certificate_by_lua_block {
            print("About to initiate a new SSL handshake!")
        }

        location / {
            root html;
        }
    }
</geshi>

See more complicated examples in the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md ngx.ssl]
and [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ocsp.md ngx.ocsp]
Lua modules' official documentation.

Uncaught Lua exceptions in the user Lua code immediately abort the current SSL session, so does the
[[#ngx.exit|ngx.exit]] call with an error code like <code>ngx.ERROR</code>.

This Lua code execution context *does* support yielding, so Lua APIs that may yield
(like cosockets, sleeping, and "light threads")
are enabled in this context.

Note, however, you still need to configure the [https://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_certificate ssl_certificate] and
[https://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_certificate_key ssl_certificate_key]
directives even though you will not use this static certificate and private key at all. This is
because the NGINX core requires their appearance otherwise you are seeing the following error
while starting NGINX:

<geshi>
    nginx: [emerg] no ssl configured for the server
</geshi>

This directive requires OpenSSL 1.0.2e or greater.

If you are using the [official pre-built
packages](https://openresty.org/en/linux-packages.html) for
[OpenResty](https://openresty.org/) 1.9.7.2 or later, then everything should
work out of the box.

If you are not using the Nginx core shipped with
[OpenResty](https://openresty.org) 1.9.7.2 or later, you will need to apply
patches to the standard Nginx core:

https://openresty.org/en/nginx-ssl-patches.html

This directive was first introduced in the <code>v0.10.0</code> release.

== ssl_certificate_by_lua_file ==

'''syntax:''' ''ssl_certificate_by_lua_file <path-to-lua-script-file>''

'''context:''' ''server''

'''phase:''' ''right-before-SSL-handshake''

Equivalent to [[#ssl_certificate_by_lua_block|ssl_certificate_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or, as from the <code>v0.5.0rc32</code> release, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.10.0</code> release.

== ssl_session_fetch_by_lua_block ==

'''syntax:''' ''ssl_session_fetch_by_lua_block { lua-script }''

'''context:''' ''http''

'''phase:''' ''right-before-SSL-handshake''

This directive runs Lua code to look up and load the SSL session (if any) according to the session ID
provided by the current SSL handshake request for the downstream.

The Lua API for obtaining the current session ID and loading a cached SSL session data
is provided in the [ngx.ssl.session](https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl/session.md)
Lua module shipped with the [lua-resty-core](https://github.com/openresty/lua-resty-core#readme)
library.

Lua APIs that may yield, like [[#ngx.sleep|ngx.sleep]] and [[#ngx.socket.tcp|cosockets]],
are enabled in this context.

This hook, together with the [[#ssl_session_store_by_lua_block|ssl_session_store_by_lua*]] hook,
can be used to implement distributed caching mechanisms in pure Lua (based
on the [[#ngx.socket.tcp|cosocket]] API, for example). If a cached SSL session is found
and loaded into the current SSL connection context,
SSL session resumption can then get immediately initiated and bypass the full SSL handshake process which is very expensive in terms of CPU time.

Please note that TLS session tickets are very different and it is the clients' responsibility
to cache the SSL session state when session tickets are used. SSL session resumptions based on
TLS session tickets would happen automatically without going through this hook (nor the
[[#ssl_session_store_by_lua_block|ssl_session_store_by_lua*]] hook). This hook is mainly
for older or less capable SSL clients that can only do SSL sessions by session IDs.

When [[#ssl_certificate_by_lua_block|ssl_certificate_by_lua*]] is specified at the same time,
this hook usually runs before [[#ssl_certificate_by_lua_block|ssl_certificate_by_lua*]].
When the SSL session is found and successfully loaded for the current SSL connection,
SSL session resumption will happen and thus bypass the [[#ssl_certificate_by_lua_block|ssl_certificate_by_lua*]]
hook completely. In this case, Nginx also bypasses the [[#ssl_session_store_by_lua_block|ssl_session_store_by_lua*]]
hook, for obvious reasons.

To easily test this hook locally with a modern web browser, you can temporarily put the following line
in your https server block to disable the TLS session ticket support:

    ssl_session_tickets off;

But do not forget to comment this line out before publishing your site to the world.

If you are using the [official pre-built packages](https://openresty.org/en/linux-packages.html) for [OpenResty](https://openresty.org/)
1.11.2.1 or later, then everything should work out of the box.

If you are not using one of the [OpenSSL
packages](https://openresty.org/en/linux-packages.html) provided by
[OpenResty](https://openresty.org), you will need to apply patches to OpenSSL
in order to use this directive:

https://openresty.org/en/openssl-patches.html

Similarly, if you are not using the Nginx core shipped with
[OpenResty](https://openresty.org) 1.11.2.1 or later, you will need to apply
patches to the standard Nginx core:

https://openresty.org/en/nginx-ssl-patches.html

This directive was first introduced in the <code>v0.10.6</code> release.

Note that this directive can only be used in the '''http context''' starting
with the <code>v0.10.7</code> release since SSL session resumption happens
before server name dispatch.

== ssl_session_fetch_by_lua_file ==

'''syntax:''' ''ssl_session_fetch_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http''

'''phase:''' ''right-before-SSL-handshake''

Equivalent to [[#ssl_session_fetch_by_lua_block|ssl_session_fetch_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or rather, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.10.6</code> release.

Note that: this directive is only allowed to used in '''http context''' from the <code>v0.10.7</code> release
(because SSL session resumption happens before server name dispatch).

== ssl_session_store_by_lua_block ==

'''syntax:''' ''ssl_session_store_by_lua_block { lua-script }''

'''context:''' ''http''

'''phase:''' ''right-after-SSL-handshake''

This directive runs Lua code to fetch and save the SSL session (if any) according to the session ID
provided by the current SSL handshake request for the downstream. The saved or cached SSL
session data can be used for future SSL connections to resume SSL sessions without going
through the full SSL handshake process (which is very expensive in terms of CPU time).

Lua APIs that may yield, like [[#ngx.sleep|ngx.sleep]] and [[#ngx.socket.tcp|cosockets]],
are *disabled* in this context. You can still, however, use the [[#ngx.timer.at|ngx.timer.at]] API
to create 0-delay timers to save the SSL session data asynchronously to external services (like <code>redis</code> or <code>memcached</code>).

The Lua API for obtaining the current session ID and the associated session state data
is provided in the [ngx.ssl.session](https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl/session.md#readme)
Lua module shipped with the [lua-resty-core](https://github.com/openresty/lua-resty-core#readme)
library.

To easily test this hook locally with a modern web browser, you can temporarily put the following line
in your https server block to disable the TLS session ticket support:

    ssl_session_tickets off;

But do not forget to comment this line out before publishing your site to the world.

This directive was first introduced in the <code>v0.10.6</code> release.

Note that: this directive is only allowed to used in '''http context''' from the <code>v0.10.7</code> release
(because SSL session resumption happens before server name dispatch).

== ssl_session_store_by_lua_file ==

'''syntax:''' ''ssl_session_store_by_lua_file <path-to-lua-script-file>''

'''context:''' ''http''

'''phase:''' ''right-after-SSL-handshake''

Equivalent to [[#ssl_session_store_by_lua_block|ssl_session_store_by_lua_block]], except that the file specified by <code><path-to-lua-script-file></code> contains the Lua code, or rather, the [[#LuaJIT bytecode support|LuaJIT bytecode]] to be executed.

When a relative path like <code>foo/bar.lua</code> is given, they will be turned into the absolute path relative to the <code>server prefix</code> path determined by the <code>-p PATH</code> command-line option while starting the Nginx server.

This directive was first introduced in the <code>v0.10.6</code> release.

Note that: this directive is only allowed to used in '''http context''' from the <code>v0.10.7</code> release
(because SSL session resumption happens before server name dispatch).

== lua_shared_dict ==

'''syntax:''' ''lua_shared_dict <name> <size>''

'''default:''' ''no''

'''context:''' ''http''

'''phase:''' ''depends on usage''

Declares a shared memory zone, <code><name></code>, to serve as storage for the shm based Lua dictionary <code>ngx.shared.<name></code>.

Shared memory zones are always shared by all the Nginx worker processes in the current Nginx server instance.

The <code><size></code> argument accepts size units such as <code>k</code> and <code>m</code>:

<geshi lang="nginx">
    http {
        lua_shared_dict dogs 10m;
        ...
    }
</geshi>

The hard-coded minimum size is 8KB while the practical minimum size depends
on actual user data set (some people start with 12KB).

See [[#ngx.shared.DICT|ngx.shared.DICT]] for details.

This directive was first introduced in the <code>v0.3.1rc22</code> release.

== lua_socket_connect_timeout ==

'''syntax:''' ''lua_socket_connect_timeout <time>''

'''default:''' ''lua_socket_connect_timeout 60s''

'''context:''' ''http, server, location''

This directive controls the default timeout value used in TCP/unix-domain socket object's [[#tcpsock:connect|connect]] method and can be overridden by the [[#tcpsock:settimeout|settimeout]] or [[#tcpsock:settimeouts|settimeouts]] methods.

The <code><time></code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., "second". The default setting is <code>60s</code>.

This directive was first introduced in the <code>v0.5.0rc1</code> release.

== lua_socket_send_timeout ==

'''syntax:''' ''lua_socket_send_timeout <time>''

'''default:''' ''lua_socket_send_timeout 60s''

'''context:''' ''http, server, location''

Controls the default timeout value used in TCP/unix-domain socket object's [[#tcpsock:send|send]] method and can be overridden by the [[#tcpsock:settimeout|settimeout]] or [[#tcpsock:settimeouts|settimeouts]] methods.

The <code><time></code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., "second". The default setting is <code>60s</code>.

This directive was first introduced in the <code>v0.5.0rc1</code> release.

== lua_socket_send_lowat ==

'''syntax:''' ''lua_socket_send_lowat <size>''

'''default:''' ''lua_socket_send_lowat 0''

'''context:''' ''http, server, location''

Controls the <code>lowat</code> (low water) value for the cosocket send buffer.

== lua_socket_read_timeout ==

'''syntax:''' ''lua_socket_read_timeout <time>''

'''default:''' ''lua_socket_read_timeout 60s''

'''context:''' ''http, server, location''

'''phase:''' ''depends on usage''

This directive controls the default timeout value used in TCP/unix-domain socket object's [[#tcpsock:receive|receive]] method and iterator functions returned by the [[#tcpsock:receiveuntil|receiveuntil]] method. This setting can be overridden by the [[#tcpsock:settimeout|settimeout]] or [[#tcpsock:settimeouts|settimeouts]] methods.

The <code><time></code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., "second". The default setting is <code>60s</code>.

This directive was first introduced in the <code>v0.5.0rc1</code> release.

== lua_socket_buffer_size ==

'''syntax:''' ''lua_socket_buffer_size <size>''

'''default:''' ''lua_socket_buffer_size 4k/8k''

'''context:''' ''http, server, location''

Specifies the buffer size used by cosocket reading operations.

This buffer does not have to be that big to hold everything at the same time because cosocket supports 100% non-buffered reading and parsing. So even <code>1</code> byte buffer size should still work everywhere but the performance could be terrible.

This directive was first introduced in the <code>v0.5.0rc1</code> release.

== lua_socket_pool_size ==

'''syntax:''' ''lua_socket_pool_size <size>''

'''default:''' ''lua_socket_pool_size 30''

'''context:''' ''http, server, location''

Specifies the size limit (in terms of connection count) for every cosocket connection pool associated with every remote server (i.e., identified by either the host-port pair or the unix domain socket file path).

Default to 30 connections for every pool.

When the connection pool exceeds the available size limit, the least recently used (idle) connection already in the pool will be closed to make room for the current connection.

Note that the cosocket connection pool is per Nginx worker process rather than per Nginx server instance, so size limit specified here also applies to every single Nginx worker process.

This directive was first introduced in the <code>v0.5.0rc1</code> release.

== lua_socket_keepalive_timeout ==

'''syntax:''' ''lua_socket_keepalive_timeout <time>''

'''default:''' ''lua_socket_keepalive_timeout 60s''

'''context:''' ''http, server, location''

This directive controls the default maximal idle time of the connections in the cosocket built-in connection pool. When this timeout reaches, idle connections will be closed and removed from the pool. This setting can be overridden by cosocket objects' [[#tcpsock:setkeepalive|setkeepalive]] method.

The <code><time></code> argument can be an integer, with an optional time unit, like <code>s</code> (second), <code>ms</code> (millisecond), <code>m</code> (minute). The default time unit is <code>s</code>, i.e., "second". The default setting is <code>60s</code>.

This directive was first introduced in the <code>v0.5.0rc1</code> release.

== lua_socket_log_errors ==

'''syntax:''' ''lua_socket_log_errors on|off''

'''default:''' ''lua_socket_log_errors on''

'''context:''' ''http, server, location''

This directive can be used to toggle error logging when a failure occurs for the TCP or UDP cosockets. If you are already doing proper error handling and logging in your Lua code, then it is recommended to turn this directive off to prevent data flushing in your Nginx error log files (which is usually rather expensive).

This directive was first introduced in the <code>v0.5.13</code> release.

== lua_ssl_ciphers ==

'''syntax:''' ''lua_ssl_ciphers <ciphers>''

'''default:''' ''lua_ssl_ciphers DEFAULT''

'''context:''' ''http, server, location''

Specifies the enabled ciphers for requests to a SSL/TLS server in the [[#tcpsock:sslhandshake|tcpsock:sslhandshake]] method. The ciphers are specified in the format understood by the OpenSSL library.

The full list can be viewed using the “openssl ciphers” command.

This directive was first introduced in the <code>v0.9.11</code> release.

== lua_ssl_crl ==

'''syntax:''' ''lua_ssl_crl <file>''

'''default:''' ''no''

'''context:''' ''http, server, location''

Specifies a file with revoked certificates (CRL) in the PEM format used to verify the certificate of the SSL/TLS server in the [[#tcpsock:sslhandshake|tcpsock:sslhandshake]] method.

This directive was first introduced in the <code>v0.9.11</code> release.

== lua_ssl_protocols ==

'''syntax:''' ''lua_ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3]''

'''default:''' ''lua_ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2''

'''context:''' ''http, server, location''

Enables the specified protocols for requests to a SSL/TLS server in the [[#tcpsock:sslhandshake|tcpsock:sslhandshake]] method.

The support for the <code>TLSv1.3</code> parameter requires version <code>v0.10.12</code> *and* OpenSSL 1.1.1.

This directive was first introduced in the <code>v0.9.11</code> release.

== lua_ssl_trusted_certificate ==

'''syntax:''' ''lua_ssl_trusted_certificate <file>''

'''default:''' ''no''

'''context:''' ''http, server, location''

Specifies a file path with trusted CA certificates in the PEM format used to verify the certificate of the SSL/TLS server in the [[#tcpsock:sslhandshake|tcpsock:sslhandshake]] method.

This directive was first introduced in the <code>v0.9.11</code> release.

See also [[#lua_ssl_verify_depth|lua_ssl_verify_depth]].

== lua_ssl_verify_depth ==

'''syntax:''' ''lua_ssl_verify_depth <number>''

'''default:''' ''lua_ssl_verify_depth 1''

'''context:''' ''http, server, location''

Sets the verification depth in the server certificates chain.

This directive was first introduced in the <code>v0.9.11</code> release.

See also [[#lua_ssl_trusted_certificate|lua_ssl_trusted_certificate]].

== lua_ssl_conf_command ==

'''syntax:''' ''lua_ssl_conf_command <command>''

'''default:''' ''no''

'''context:''' ''http, server, location''

Sets arbitrary OpenSSL configuration [https://www.openssl.org/docs/man1.1.1/man3/SSL_CONF_cmd.html commands].

The directive is supported when using OpenSSL 1.0.2 or higher and nginx 1.19.4 or higher. According to the specify command, higher OpenSSL version may be needed.

Several <code>lua_ssl_conf_command</code> directives can be specified on the same level:

<geshi lang="nginx">
lua_ssl_conf_command Options PrioritizeChaCha;
lua_ssl_conf_command Ciphersuites TLS_CHACHA20_POLY1305_SHA256;
</geshi>

Configuration commands are applied after OpenResty own configuration for SSL, so they can be used to override anything set by OpenResty.

Note though that configuring OpenSSL directly with <code>lua_ssl_conf_command</code> might result in a behaviour OpenResty does not expect, and should be done with care.

This directive was first introduced in the <code>v0.10.21</code> release.



== lua_http10_buffering ==

'''syntax:''' ''lua_http10_buffering on|off''

'''default:''' ''lua_http10_buffering on''

'''context:''' ''http, server, location, location-if''

Enables or disables automatic response buffering for HTTP 1.0 (or older) requests. This buffering mechanism is mainly used for HTTP 1.0 keep-alive which relies on a proper <code>Content-Length</code> response header.

If the Lua code explicitly sets a <code>Content-Length</code> response header before sending the headers (either explicitly via [[#ngx.send_headers|ngx.send_headers]] or implicitly via the first [[#ngx.say|ngx.say]] or [[#ngx.print|ngx.print]] call), then the HTTP 1.0 response buffering will be disabled even when this directive is turned on.

To output very large response data in a streaming fashion (via the [[#ngx.flush|ngx.flush]] call, for example), this directive MUST be turned off to minimize memory usage.

This directive is turned <code>on</code> by default.

This directive was first introduced in the <code>v0.5.0rc19</code> release.

== rewrite_by_lua_no_postpone ==

'''syntax:''' ''rewrite_by_lua_no_postpone on|off''

'''default:''' ''rewrite_by_lua_no_postpone off''

'''context:''' ''http''

Controls whether or not to disable postponing [[#rewrite_by_lua|rewrite_by_lua*]] directives to run at the end of the <code>rewrite</code> request-processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the <code>rewrite</code> phase.

This directive was first introduced in the <code>v0.5.0rc29</code> release.

== access_by_lua_no_postpone ==

'''syntax:''' ''access_by_lua_no_postpone on|off''

'''default:''' ''access_by_lua_no_postpone off''

'''context:''' ''http''

Controls whether or not to disable postponing [[#access_by_lua|access_by_lua*]] directives to run at the end of the <code>access</code> request-processing phase. By default, this directive is turned off and the Lua code is postponed to run at the end of the <code>access</code> phase.

This directive was first introduced in the <code>v0.9.20</code> release.

== lua_transform_underscores_in_response_headers ==

'''syntax:''' ''lua_transform_underscores_in_response_headers on|off''

'''default:''' ''lua_transform_underscores_in_response_headers on''

'''context:''' ''http, server, location, location-if''

Controls whether to transform underscores (<code>_</code>) in the response header names specified in the [[#ngx.header.HEADER|ngx.header.HEADER]] API to hyphens (<code>-</code>).

This directive was first introduced in the <code>v0.5.0rc32</code> release.

== lua_check_client_abort ==

'''syntax:''' ''lua_check_client_abort on|off''

'''default:''' ''lua_check_client_abort off''

'''context:''' ''http, server, location, location-if''

This directive controls whether to check for premature client connection abortion.

When this directive is on, the ngx_lua module will monitor the premature connection close event on the downstream connections and when there is such an event, it will call the user Lua function callback (registered by [[#ngx.on_abort|ngx.on_abort]]) or just stop and clean up all the Lua "light threads" running in the current request's request handler when there is no user callback function registered.

According to the current implementation, however, if the client closes the connection before the Lua code finishes reading the request body data via [[#ngx.req.socket|ngx.req.socket]], then ngx_lua will neither stop all the running "light threads" nor call the user callback (if [[#ngx.on_abort|ngx.on_abort]] has been called). Instead, the reading operation on [[#ngx.req.socket|ngx.req.socket]] will just return the error message "client aborted" as the second return value (the first return value is surely <code>nil</code>).

When TCP keepalive is disabled, it is relying on the client side to close the socket gracefully (by sending a <code>FIN</code> packet or something like that). For (soft) real-time web applications, it is highly recommended to configure the [http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/overview.html TCP keepalive] support in your system's TCP stack implementation in order to detect "half-open" TCP connections in time.

For example, on Linux, you can configure the standard [[HttpCoreModule#listen|listen]] directive in your <code>nginx.conf</code> file like this:

<geshi lang="nginx">
    listen 80 so_keepalive=2s:2s:8;
</geshi>

On FreeBSD, you can only tune the system-wide configuration for TCP keepalive, for example:

    # sysctl net.inet.tcp.keepintvl=2000
    # sysctl net.inet.tcp.keepidle=2000

This directive was first introduced in the <code>v0.7.4</code> release.

See also [[#ngx.on_abort|ngx.on_abort]].

== lua_max_pending_timers ==

'''syntax:''' ''lua_max_pending_timers <count>''

'''default:''' ''lua_max_pending_timers 1024''

'''context:''' ''http''

Controls the maximum number of pending timers allowed.

Pending timers are those timers that have not expired yet.

When exceeding this limit, the [[#ngx.timer.at|ngx.timer.at]] call will immediately return <code>nil</code> and the error string "too many pending timers".

This directive was first introduced in the <code>v0.8.0</code> release.

== lua_max_running_timers ==

'''syntax:''' ''lua_max_running_timers <count>''

'''default:''' ''lua_max_running_timers 256''

'''context:''' ''http''

Controls the maximum number of "running timers" allowed.

Running timers are those timers whose user callback functions are still running.

When exceeding this limit, Nginx will stop running the callbacks of newly expired timers and log an error message "N lua_max_running_timers are not enough" where "N" is the current value of this directive.

This directive was first introduced in the <code>v0.8.0</code> release.

== lua_sa_restart ==

'''syntax:''' ''lua_sa_restart on|off''

'''default:''' ''lua_sa_restart on''

'''context:''' ''http''

When enabled, this module will set the `SA_RESTART` flag on Nginx workers signal dispositions.

This allows Lua I/O primitives to not be interrupted by Nginx's handling of various signals.

This directive was first introduced in the <code>v0.10.14</code> release.

== lua_worker_thread_vm_pool_size ==

'''syntax:''' ''lua_worker_thread_vm_pool_size <size>''

'''default:''' ''lua_worker_thread_vm_pool_size 100''

'''context:''' ''http''

Specifies the size limit of the Lua VM pool (default 100) that will be used in the [ngx.run_worker_thread](#ngxrun_worker_thread) API.

Also, it is not allowed to create Lua VMs that exceeds the pool size limit.

The Lua VM in the VM pool is used to execute Lua code in separate thread.

The pool is global at Nginx worker level. And it is used to reuse Lua VMs between requests.

= Nginx API for Lua =

<!-- inline-toc -->

== Introduction ==

The various <code>*_by_lua</code>, <code>*_by_lua_block</code> and <code>*_by_lua_file</code> configuration directives serve as gateways to the Lua API within the <code>nginx.conf</code> file. The Nginx Lua API described below can only be called within the user Lua code run in the context of these configuration directives.

The API is exposed to Lua in the form of two standard packages <code>ngx</code> and <code>ndk</code>. These packages are in the default global scope within ngx_lua and are always available within ngx_lua directives.

The packages can be introduced into external Lua modules like this:

<geshi lang="lua">
    local say = ngx.say

    local _M = {}

    function _M.foo(a)
        say(a)
    end

    return _M
</geshi>

Use of the [https://www.lua.org/manual/5.1/manual.html#pdf-package.seeall package.seeall] flag is strongly discouraged due to its various bad side-effects.

It is also possible to directly require the packages in external Lua modules:

<geshi lang="lua">
    local ngx = require "ngx"
    local ndk = require "ndk"
</geshi>

The ability to require these packages was introduced in the <code>v0.2.1rc19</code> release.

Network I/O operations in user code should only be done through the Nginx Lua API calls as the Nginx event loop may be blocked and performance drop off dramatically otherwise. Disk operations with relatively small amount of data can be done using the standard Lua <code>io</code> library but huge file reading and writing should be avoided wherever possible as they may block the Nginx process significantly. Delegating all network and disk I/O operations to Nginx's subrequests (via the [[#ngx.location.capture|ngx.location.capture]] method and similar) is strongly recommended for maximum performance.

== ngx.arg ==

'''syntax:''' ''val = ngx.arg[index]''

'''context:''' ''set_by_lua*, body_filter_by_lua*''

When this is used in the context of the [[#set_by_lua|set_by_lua*]] directives, this table is read-only and holds the input arguments to the config directives:

<geshi lang="lua">
    value = ngx.arg[n]
</geshi>

Here is an example

<geshi lang="nginx">
    location /foo {
        set $a 32;
        set $b 56;

        set_by_lua $sum
            'return tonumber(ngx.arg[1]) + tonumber(ngx.arg[2])'
            $a $b;

        echo $sum;
    }
</geshi>

that writes out <code>88</code>, the sum of <code>32</code> and <code>56</code>.

When this table is used in the context of [[#body_filter_by_lua|body_filter_by_lua*]], the first element holds the input data chunk to the output filter code and the second element holds the boolean flag for the "eof" flag indicating the end of the whole output data stream.

The data chunk and "eof" flag passed to the downstream Nginx output filters can also be overridden by assigning values directly to the corresponding table elements. When setting <code>nil</code> or an empty Lua string value to <code>ngx.arg[1]</code>, no data chunk will be passed to the downstream Nginx output filters at all.

== ngx.var.VARIABLE ==

'''syntax:''' ''ngx.var.VAR_NAME''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*''

Read and write Nginx variable values.

<geshi lang="nginx">
    value = ngx.var.some_nginx_variable_name
    ngx.var.some_nginx_variable_name = value
</geshi>

Note that only already defined Nginx variables can be written to.
For example:

<geshi lang="nginx">
    location /foo {
        set $my_var ''; # this line is required to create $my_var at config time
        content_by_lua_block {
            ngx.var.my_var = 123
            ...
        }
    }
</geshi>

That is, Nginx variables cannot be created on-the-fly.

Some special Nginx variables like <code>$args</code> and <code>$limit_rate</code> can be assigned a value,
many others are not, like <code>$query_string</code>, <code>$arg_PARAMETER</code>, and <code>$http_NAME</code>.

Nginx regex group capturing variables <code>$1</code>, <code>$2</code>, <code>$3</code>, and etc, can be read by this
interface as well, by writing <code>ngx.var[1]</code>, <code>ngx.var[2]</code>, <code>ngx.var[3]</code>, and etc.

Setting <code>ngx.var.Foo</code> to a <code>nil</code> value will unset the <code>$Foo</code> Nginx variable.

<geshi lang="lua">
    ngx.var.args = nil
</geshi>

'''CAUTION''' When reading from an Nginx variable, Nginx will allocate memory in the per-request memory pool which is freed only at request termination. So when you need to read from an Nginx variable repeatedly in your Lua code, cache the Nginx variable value to your own Lua variable, for example,

<geshi lang="lua">
    local val = ngx.var.some_var
    --- use the val repeatedly later
</geshi>

to prevent (temporary) memory leaking within the current request's lifetime. Another way of caching the result is to use the [[#ngx.ctx|ngx.ctx]] table.

Undefined Nginx variables are evaluated to <code>nil</code> while uninitialized (but defined) Nginx variables are evaluated to an empty Lua string.

This API requires a relatively expensive metamethod call and it is recommended to avoid using it on hot code paths.

== Core constants ==

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, *log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

<geshi lang="lua">
  ngx.OK (0)
  ngx.ERROR (-1)
  ngx.AGAIN (-2)
  ngx.DONE (-4)
  ngx.DECLINED (-5)
</geshi>

Note that only three of these constants are utilized by the [[#Nginx API for Lua|Nginx API for Lua]] (i.e., [[#ngx.exit|ngx.exit]] accepts <code>ngx.OK</code>, <code>ngx.ERROR</code>, and <code>ngx.DECLINED</code> as input).

<geshi lang="lua">
  ngx.null
</geshi>

The <code>ngx.null</code> constant is a <code>NULL</code> light userdata usually used to represent nil values in Lua tables etc and is similar to the [http://www.kyne.com.au/~mark/software/lua-cjson.php lua-cjson] library's <code>cjson.null</code> constant. This constant was first introduced in the <code>v0.5.0rc5</code> release.

The <code>ngx.DECLINED</code> constant was first introduced in the <code>v0.5.0rc19</code> release.

== HTTP method constants ==

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

<geshi lang="text">
  ngx.HTTP_GET
  ngx.HTTP_HEAD
  ngx.HTTP_PUT
  ngx.HTTP_POST
  ngx.HTTP_DELETE
  ngx.HTTP_OPTIONS   (added in the v0.5.0rc24 release)
  ngx.HTTP_MKCOL     (added in the v0.8.2 release)
  ngx.HTTP_COPY      (added in the v0.8.2 release)
  ngx.HTTP_MOVE      (added in the v0.8.2 release)
  ngx.HTTP_PROPFIND  (added in the v0.8.2 release)
  ngx.HTTP_PROPPATCH (added in the v0.8.2 release)
  ngx.HTTP_LOCK      (added in the v0.8.2 release)
  ngx.HTTP_UNLOCK    (added in the v0.8.2 release)
  ngx.HTTP_PATCH     (added in the v0.8.2 release)
  ngx.HTTP_TRACE     (added in the v0.8.2 release)
</geshi>

These constants are usually used in [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]] method calls.

== HTTP status constants ==

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

<geshi lang="nginx">
  value = ngx.HTTP_CONTINUE (100) (first added in the v0.9.20 release)
  value = ngx.HTTP_SWITCHING_PROTOCOLS (101) (first added in the v0.9.20 release)
  value = ngx.HTTP_OK (200)
  value = ngx.HTTP_CREATED (201)
  value = ngx.HTTP_ACCEPTED (202) (first added in the v0.9.20 release)
  value = ngx.HTTP_NO_CONTENT (204) (first added in the v0.9.20 release)
  value = ngx.HTTP_PARTIAL_CONTENT (206) (first added in the v0.9.20 release)
  value = ngx.HTTP_SPECIAL_RESPONSE (300)
  value = ngx.HTTP_MOVED_PERMANENTLY (301)
  value = ngx.HTTP_MOVED_TEMPORARILY (302)
  value = ngx.HTTP_SEE_OTHER (303)
  value = ngx.HTTP_NOT_MODIFIED (304)
  value = ngx.HTTP_TEMPORARY_REDIRECT (307) (first added in the v0.9.20 release)
  value = ngx.HTTP_PERMANENT_REDIRECT (308)
  value = ngx.HTTP_BAD_REQUEST (400)
  value = ngx.HTTP_UNAUTHORIZED (401)
  value = ngx.HTTP_PAYMENT_REQUIRED (402) (first added in the v0.9.20 release)
  value = ngx.HTTP_FORBIDDEN (403)
  value = ngx.HTTP_NOT_FOUND (404)
  value = ngx.HTTP_NOT_ALLOWED (405)
  value = ngx.HTTP_NOT_ACCEPTABLE (406) (first added in the v0.9.20 release)
  value = ngx.HTTP_REQUEST_TIMEOUT (408) (first added in the v0.9.20 release)
  value = ngx.HTTP_CONFLICT (409) (first added in the v0.9.20 release)
  value = ngx.HTTP_GONE (410)
  value = ngx.HTTP_UPGRADE_REQUIRED (426) (first added in the v0.9.20 release)
  value = ngx.HTTP_TOO_MANY_REQUESTS (429) (first added in the v0.9.20 release)
  value = ngx.HTTP_CLOSE (444) (first added in the v0.9.20 release)
  value = ngx.HTTP_ILLEGAL (451) (first added in the v0.9.20 release)
  value = ngx.HTTP_INTERNAL_SERVER_ERROR (500)
  value = ngx.HTTP_NOT_IMPLEMENTED (501)
  value = ngx.HTTP_METHOD_NOT_IMPLEMENTED (501) (kept for compatibility)
  value = ngx.HTTP_BAD_GATEWAY (502) (first added in the v0.9.20 release)
  value = ngx.HTTP_SERVICE_UNAVAILABLE (503)
  value = ngx.HTTP_GATEWAY_TIMEOUT (504) (first added in the v0.3.1rc38 release)
  value = ngx.HTTP_VERSION_NOT_SUPPORTED (505) (first added in the v0.9.20 release)
  value = ngx.HTTP_INSUFFICIENT_STORAGE (507) (first added in the v0.9.20 release)
</geshi>

== Nginx log level constants ==

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

<geshi lang="lua">
  ngx.STDERR
  ngx.EMERG
  ngx.ALERT
  ngx.CRIT
  ngx.ERR
  ngx.WARN
  ngx.NOTICE
  ngx.INFO
  ngx.DEBUG
</geshi>

These constants are usually used by the [[#ngx.log|ngx.log]] method.

== print ==

'''syntax:''' ''print(...)''

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Writes argument values into the Nginx <code>error.log</code> file with the <code>ngx.NOTICE</code> log level.

It is equivalent to

<geshi lang="lua">
    ngx.log(ngx.NOTICE, ...)
</geshi>

Lua <code>nil</code> arguments are accepted and result in literal <code>"nil"</code> strings while Lua booleans result in literal <code>"true"</code> or <code>"false"</code> strings. And the <code>ngx.null</code> constant will yield the <code>"null"</code> string output.

There is a hard coded <code>2048</code> byte limitation on error message lengths in the Nginx core. This limit includes trailing newlines and leading time stamps. If the message size exceeds this limit, Nginx will truncate the message text accordingly. This limit can be manually modified by editing the <code>NGX_MAX_ERROR_STR</code> macro definition in the <code>src/core/ngx_log.h</code> file in the Nginx source tree.

== ngx.ctx ==

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, exit_worker_by_lua*''

This table can be used to store per-request Lua context data and has a life time identical to the current request (as with the Nginx variables).

Consider the following example,

<geshi lang="nginx">
    location /test {
        rewrite_by_lua_block {
            ngx.ctx.foo = 76
        }
        access_by_lua_block {
            ngx.ctx.foo = ngx.ctx.foo + 3
        }
        content_by_lua_block {
            ngx.say(ngx.ctx.foo)
        }
    }
</geshi>

Then <code>GET /test</code> will yield the output

<geshi lang="bash">
    79
</geshi>

That is, the <code>ngx.ctx.foo</code> entry persists across the rewrite, access, and content phases of a request.

Every request, including subrequests, has its own copy of the table. For example:

<geshi lang="nginx">
    location /sub {
        content_by_lua_block {
            ngx.say("sub pre: ", ngx.ctx.blah)
            ngx.ctx.blah = 32
            ngx.say("sub post: ", ngx.ctx.blah)
        }
    }

    location /main {
        content_by_lua_block {
            ngx.ctx.blah = 73
            ngx.say("main pre: ", ngx.ctx.blah)
            local res = ngx.location.capture("/sub")
            ngx.print(res.body)
            ngx.say("main post: ", ngx.ctx.blah)
        }
    }
</geshi>

Then <code>GET /main</code> will give the output

<geshi lang="bash">
    main pre: 73
    sub pre: nil
    sub post: 32
    main post: 73
</geshi>

Here, modification of the <code>ngx.ctx.blah</code> entry in the subrequest does not affect the one in the parent request. This is because they have two separate versions of <code>ngx.ctx.blah</code>.

Internal redirects (triggered by nginx configuration directives like `error_page`, `try_files`, `index` and etc) will destroy the original request <code>ngx.ctx</code> data (if any) and the new request will have an empty <code>ngx.ctx</code> table. For instance,

<geshi lang="nginx">
    location /new {
        content_by_lua_block {
            ngx.say(ngx.ctx.foo)
        }
    }

    location /orig {
        content_by_lua_block {
            ngx.ctx.foo = "hello"
            ngx.exec("/new")
        }
    }
</geshi>

Then <code>GET /orig</code> will give

<geshi lang="bash">
    nil
</geshi>

rather than the original <code>"hello"</code> value.

Because HTTP request is created after SSL handshake, the <code>ngx.ctx</code> created
in [[#ssl_certificate_by_lua|ssl_certificate_by_lua*]], [[#ssl_session_store_by_lua|ssl_session_store_by_lua*]], [[#ssl_session_fetch_by_lua|ssl_session_fetch_by_lua*]] and [[#ssl_client_hello_by_lua|ssl_client_hello_by_lua*]]
is not available in the following phases like [[#rewrite_by_lua|rewrite_by_lua*]].

Since <code>v0.10.18</code>, the <code>ngx.ctx</code> created during a SSL handshake
will be inherited by the requests which share the same TCP connection established by the handshake.
Note that overwrite values in <code>ngx.ctx</code> in the http request phases (like `rewrite_by_lua*`) will only take affect in the current http request.

Arbitrary data values, including Lua closures and nested tables, can be inserted into this "magic" table. It also allows the registration of custom meta methods.

Overriding <code>ngx.ctx</code> with a new Lua table is also supported, for example,

<geshi lang="lua">
    ngx.ctx = { foo = 32, bar = 54 }
</geshi>

When being used in the context of [[#init_worker_by_lua|init_worker_by_lua*]], this table just has the same lifetime of the current Lua handler.

The <code>ngx.ctx</code> lookup requires relatively expensive metamethod calls and it is much slower than explicitly passing per-request data along by your own function arguments. So do not abuse this API for saving your own function arguments because it usually has quite some performance impact.

Because of the metamethod magic, never "local" the <code>ngx.ctx</code> table outside your Lua function scope on the Lua module level due to [[#Data_Sharing_within_an_Nginx_Worker|worker-level data sharing]]. For example, the following is bad:

<geshi lang="lua">
-- mymodule.lua
local _M = {}

-- the following line is bad since ngx.ctx is a per-request
-- data while this <code>ctx</code> variable is on the Lua module level
-- and thus is per-nginx-worker.
local ctx = ngx.ctx

function _M.main()
    ctx.foo = "bar"
end

return _M
</geshi>

Use the following instead:

<geshi lang="lua">
-- mymodule.lua
local _M = {}

function _M.main(ctx)
    ctx.foo = "bar"
end

return _M
</geshi>

That is, let the caller pass the <code>ctx</code> table explicitly via a function argument.

== ngx.location.capture ==

'''syntax:''' ''res = ngx.location.capture(uri, options?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Issues a synchronous but still non-blocking ''Nginx Subrequest'' using <code>uri</code>.

Nginx's subrequests provide a powerful way to make non-blocking internal requests to other locations configured with disk file directory or ''any'' other Nginx C modules like <code>ngx_proxy</code>, <code>ngx_fastcgi</code>, <code>ngx_memc</code>,
<code>ngx_postgres</code>, <code>ngx_drizzle</code>, and even ngx_lua itself and etc etc etc.

Also note that subrequests just mimic the HTTP interface but there is ''no'' extra HTTP/TCP traffic ''nor'' IPC involved. Everything works internally, efficiently, on the C level.

Subrequests are completely different from HTTP 301/302 redirection (via [[#ngx.redirect|ngx.redirect]]) and internal redirection (via [[#ngx.exec|ngx.exec]]).

You should always read the request body (by either calling [[#ngx.req.read_body|ngx.req.read_body]] or configuring [[#lua_need_request_body|lua_need_request_body]] on) before initiating a subrequest.

This API function (as well as [[#ngx.location.capture_multi|ngx.location.capture_multi]]) always buffers the whole response body of the subrequest in memory. Thus, you should use [[#ngx.socket.tcp|cosockets]]
and streaming processing instead if you have to handle large subrequest responses.

Here is a basic example:

<geshi lang="lua">
    res = ngx.location.capture(uri)
</geshi>

Returns a Lua table with 4 slots: <code>res.status</code>, <code>res.header</code>, <code>res.body</code>, and <code>res.truncated</code>.

<code>res.status</code> holds the response status code for the subrequest response.

<code>res.header</code> holds all the response headers of the
subrequest and it is a normal Lua table. For multi-value response headers,
the value is a Lua (array) table that holds all the values in the order that
they appear. For instance, if the subrequest response headers contain the following
lines:

<geshi lang="bash">
    Set-Cookie: a=3
    Set-Cookie: foo=bar
    Set-Cookie: baz=blah
</geshi>

Then <code>res.header["Set-Cookie"]</code> will be evaluated to the table value
<code>{"a=3", "foo=bar", "baz=blah"}</code>.

<code>res.body</code> holds the subrequest's response body data, which might be truncated. You always need to check the <code>res.truncated</code> boolean flag to see if <code>res.body</code> contains truncated data. The data truncation here can only be caused by those unrecoverable errors in your subrequests like the cases that the remote end aborts the connection prematurely in the middle of the response body data stream or a read timeout happens when your subrequest is receiving the response body data from the remote.

URI query strings can be concatenated to URI itself, for instance,

<geshi lang="lua">
    res = ngx.location.capture('/foo/bar?a=3&b=4')
</geshi>

Named locations like <code>@foo</code> are not allowed due to a limitation in
the Nginx core. Use normal locations combined with the <code>internal</code> directive to
prepare internal-only locations.

An optional option table can be fed as the second
argument, which supports the options:

* <code>method</code>
: specify the subrequest's request method, which only accepts constants like <code>ngx.HTTP_POST</code>.
* <code>body</code>
: specify the subrequest's request body (string value only).
* <code>args</code>
: specify the subrequest's URI query arguments (both string value and Lua tables are accepted)
* <code>ctx</code>
: specify a Lua table to be the [[#ngx.ctx|ngx.ctx]] table for the subrequest. It can be the current request's [[#ngx.ctx|ngx.ctx]] table, which effectively makes the parent and its subrequest to share exactly the same context table. This option was first introduced in the <code>v0.3.1rc25</code> release.
* <code>vars</code>
: take a Lua table which holds the values to set the specified Nginx variables in the subrequest as this option's value. This option was first introduced in the <code>v0.3.1rc31</code> release.
* <code>copy_all_vars</code>
: specify whether to copy over all the Nginx variable values of the current request to the subrequest in question. modifications of the Nginx variables in the subrequest will not affect the current (parent) request. This option was first introduced in the <code>v0.3.1rc31</code> release.
* <code>share_all_vars</code>
: specify whether to share all the Nginx variables of the subrequest with the current (parent) request. modifications of the Nginx variables in the subrequest will affect the current (parent) request. Enabling this option may lead to hard-to-debug issues due to bad side-effects and is considered bad and harmful. Only enable this option when you completely know what you are doing.
* <code>always_forward_body</code>
: when set to true, the current (parent) request's request body will always be forwarded to the subrequest being created if the <code>body</code> option is not specified. The request body read by either [[#ngx.req.read_body|ngx.req.read_body()]] or [[#lua_need_request_body|lua_need_request_body on]] will be directly forwarded to the subrequest without copying the whole request body data when creating the subrequest (no matter the request body data is buffered in memory buffers or temporary files). By default, this option is <code>false</code> and when the <code>body</code> option is not specified, the request body of the current (parent) request is only forwarded when the subrequest takes the <code>PUT</code> or <code>POST</code> request method.

Issuing a POST subrequest, for example, can be done as follows

<geshi lang="lua">
    res = ngx.location.capture(
        '/foo/bar',
        { method = ngx.HTTP_POST, body = 'hello, world' }
    )
</geshi>

See HTTP method constants methods other than POST.
The <code>method</code> option is <code>ngx.HTTP_GET</code> by default.

The <code>args</code> option can specify extra URI arguments, for instance,

<geshi lang="lua">
    ngx.location.capture('/foo?a=1',
        { args = { b = 3, c = ':' } }
    )
</geshi>

is equivalent to

<geshi lang="lua">
    ngx.location.capture('/foo?a=1&b=3&c=%3a')
</geshi>

that is, this method will escape argument keys and values according to URI rules and
concatenate them together into a complete query string. The format for the Lua table passed as the <code>args</code> argument is identical to the format used in the [[#ngx.encode_args|ngx.encode_args]] method.

The <code>args</code> option can also take plain query strings:

<geshi lang="lua">
    ngx.location.capture('/foo?a=1',
        { args = 'b=3&c=%3a' }
    )
</geshi>

This is functionally identical to the previous examples.

The <code>share_all_vars</code> option controls whether to share Nginx variables among the current request and its subrequests.
If this option is set to <code>true</code>, then the current request and associated subrequests will share the same Nginx variable scope. Hence, changes to Nginx variables made by a subrequest will affect the current request.

Care should be taken in using this option as variable scope sharing can have unexpected side effects. The <code>args</code>, <code>vars</code>, or <code>copy_all_vars</code> options are generally preferable instead.

This option is set to <code>false</code> by default

<geshi lang="nginx">
    location /other {
        set $dog "$dog world";
        echo "$uri dog: $dog";
    }

    location /lua {
        set $dog 'hello';
        content_by_lua_block {
            res = ngx.location.capture("/other",
                { share_all_vars = true })

            ngx.print(res.body)
            ngx.say(ngx.var.uri, ": ", ngx.var.dog)
        }
    }
</geshi>

Accessing location <code>/lua</code> gives

<geshi lang="text">
    /other dog: hello world
    /lua: hello world
</geshi>

The <code>copy_all_vars</code> option provides a copy of the parent request's Nginx variables to subrequests when such subrequests are issued. Changes made to these variables by such subrequests will not affect the parent request or any other subrequests sharing the parent request's variables.

<geshi lang="nginx">
    location /other {
        set $dog "$dog world";
        echo "$uri dog: $dog";
    }

    location /lua {
        set $dog 'hello';
        content_by_lua_block {
            res = ngx.location.capture("/other",
                { copy_all_vars = true })

            ngx.print(res.body)
            ngx.say(ngx.var.uri, ": ", ngx.var.dog)
        }
    }
</geshi>

Request <code>GET /lua</code> will give the output

<geshi lang="text">
    /other dog: hello world
    /lua: hello
</geshi>

Note that if both <code>share_all_vars</code> and <code>copy_all_vars</code> are set to true, then <code>share_all_vars</code> takes precedence.

In addition to the two settings above, it is possible to specify
values for variables in the subrequest using the <code>vars</code> option. These
variables are set after the sharing or copying of variables has been
evaluated, and provides a more efficient method of passing specific
values to a subrequest over encoding them as URL arguments and
unescaping them in the Nginx config file.

<geshi lang="nginx">
    location /other {
        content_by_lua_block {
            ngx.say("dog = ", ngx.var.dog)
            ngx.say("cat = ", ngx.var.cat)
        }
    }

    location /lua {
        set $dog '';
        set $cat '';
        content_by_lua_block {
            res = ngx.location.capture("/other",
                { vars = { dog = "hello", cat = 32 }})

            ngx.print(res.body)
        }
    }
</geshi>

Accessing <code>/lua</code> will yield the output

<geshi lang="text">
    dog = hello
    cat = 32
</geshi>

The <code>ctx</code> option can be used to specify a custom Lua table to serve as the [[#ngx.ctx|ngx.ctx]] table for the subrequest.

<geshi lang="nginx">
    location /sub {
        content_by_lua_block {
            ngx.ctx.foo = "bar";
        }
    }
    location /lua {
        content_by_lua_block {
            local ctx = {}
            res = ngx.location.capture("/sub", { ctx = ctx })

            ngx.say(ctx.foo)
            ngx.say(ngx.ctx.foo)
        }
    }
</geshi>

Then request <code>GET /lua</code> gives

<geshi lang="text">
    bar
    nil
</geshi>

It is also possible to use this <code>ctx</code> option to share the same [[#ngx.ctx|ngx.ctx]] table between the current (parent) request and the subrequest:

<geshi lang="nginx">
    location /sub {
        content_by_lua_block {
            ngx.ctx.foo = "bar"
        }
    }
    location /lua {
        content_by_lua_block {
            res = ngx.location.capture("/sub", { ctx = ngx.ctx })
            ngx.say(ngx.ctx.foo)
        }
    }
</geshi>

Request <code>GET /lua</code> yields the output

<geshi lang="text">
    bar
</geshi>

Note that subrequests issued by [[#ngx.location.capture|ngx.location.capture]] inherit all the
request headers of the current request by default and that this may have unexpected side effects on the
subrequest responses. For example, when using the standard <code>ngx_proxy</code> module to serve
subrequests, an "Accept-Encoding: gzip" header in the main request may result
in gzipped responses that cannot be handled properly in Lua code. Original request headers should be ignored by setting
[[HttpProxyModule#proxy_pass_request_headers|proxy_pass_request_headers]] to <code>off</code> in subrequest locations.

When the <code>body</code> option is not specified and the <code>always_forward_body</code> option is false (the default value), the <code>POST</code> and <code>PUT</code> subrequests will inherit the request bodies of the parent request (if any).

There is a hard-coded upper limit on the number of subrequests possible for every main request. In older versions of Nginx, the limit was <code>50</code> concurrent subrequests and in more recent versions, Nginx <code>1.9.5</code> onwards, the same limit is changed to limit the depth of recursive subrequests. When this limit is exceeded, the following error message is added to the <code>error.log</code> file:

<geshi lang="text">
    [error] 13983#0: *1 subrequests cycle while processing "/uri"
</geshi>

The limit can be manually modified if required by editing the definition of the <code>NGX_HTTP_MAX_SUBREQUESTS</code> macro in the <code>nginx/src/http/ngx_http_request.h</code> file in the Nginx source tree.

Please also refer to restrictions on capturing locations configured by [[#Locations_Configured_by_Subrequest_Directives_of_Other_Modules|subrequest directives of other modules]].

== ngx.location.capture_multi ==

'''syntax:''' ''res1, res2, ... = ngx.location.capture_multi({ {uri, options?}, {uri, options?}, ... })''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Just like [[#ngx.location.capture|ngx.location.capture]], but supports multiple subrequests running in parallel.

This function issues several parallel subrequests specified by the input table and returns their results in the same order. For example,

<geshi lang="lua">
    res1, res2, res3 = ngx.location.capture_multi{
        { "/foo", { args = "a=3&b=4" } },
        { "/bar" },
        { "/baz", { method = ngx.HTTP_POST, body = "hello" } },
    }

    if res1.status == ngx.HTTP_OK then
        ...
    end

    if res2.body == "BLAH" then
        ...
    end
</geshi>

This function will not return until all the subrequests terminate.
The total latency is the longest latency of the individual subrequests rather than the sum.

Lua tables can be used for both requests and responses when the number of subrequests to be issued is not known in advance:

<geshi lang="lua">
    -- construct the requests table
    local reqs = {}
    table.insert(reqs, { "/mysql" })
    table.insert(reqs, { "/postgres" })
    table.insert(reqs, { "/redis" })
    table.insert(reqs, { "/memcached" })

    -- issue all the requests at once and wait until they all return
    local resps = {
        ngx.location.capture_multi(reqs)
    }

    -- loop over the responses table
    for i, resp in ipairs(resps) do
        -- process the response table "resp"
    end
</geshi>

The [[#ngx.location.capture|ngx.location.capture]] function is just a special form
of this function. Logically speaking, the [[#ngx.location.capture|ngx.location.capture]] can be implemented like this

<geshi lang="lua">
    ngx.location.capture =
        function (uri, args)
            return ngx.location.capture_multi({ {uri, args} })
        end
</geshi>

Please also refer to restrictions on capturing locations configured by [[#Locations_Configured_by_Subrequest_Directives_of_Other_Modules|subrequest directives of other modules]].

== ngx.status ==

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Read and write the current request's response status. This should be called
before sending out the response headers.

<geshi lang="lua">
    ngx.status = ngx.HTTP_CREATED
    status = ngx.status
</geshi>

Setting <code>ngx.status</code> after the response header is sent out has no effect but leaving an error message in your Nginx's error log file:

<geshi lang="text">
    attempt to set ngx.status after sending out response headers
</geshi>

== ngx.header.HEADER ==

'''syntax:''' ''ngx.header.HEADER = VALUE''

'''syntax:''' ''value = ngx.header.HEADER''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Set, add to, or clear the current request's <code>HEADER</code> response header that is to be sent.

Underscores (<code>_</code>) in the header names will be replaced by hyphens (<code>-</code>) by default. This transformation can be turned off via the [[#lua_transform_underscores_in_response_headers|lua_transform_underscores_in_response_headers]] directive.

The header names are matched case-insensitively.

<geshi lang="lua">
    -- equivalent to ngx.header["Content-Type"] = 'text/plain'
    ngx.header.content_type = 'text/plain'

    ngx.header["X-My-Header"] = 'blah blah'
</geshi>

Multi-value headers can be set this way:

<geshi lang="lua">
    ngx.header['Set-Cookie'] = {'a=32; path=/', 'b=4; path=/'}
</geshi>

will yield

<geshi lang="bash">
    Set-Cookie: a=32; path=/
    Set-Cookie: b=4; path=/
</geshi>

in the response headers.

Only Lua tables are accepted (Only the last element in the table will take effect for standard headers such as <code>Content-Type</code> that only accept a single value).

<geshi lang="lua">
    ngx.header.content_type = {'a', 'b'}
</geshi>

is equivalent to

<geshi lang="lua">
    ngx.header.content_type = 'b'
</geshi>

Setting a slot to <code>nil</code> effectively removes it from the response headers:

<geshi lang="lua">
    ngx.header["X-My-Header"] = nil
</geshi>

The same applies to assigning an empty table:

<geshi lang="lua">
    ngx.header["X-My-Header"] = {}
</geshi>

Setting <code>ngx.header.HEADER</code> after sending out response headers (either explicitly with [[#ngx.send_headers|ngx.send_headers]] or implicitly with [[#ngx.print|ngx.print]] and similar) will log an error message.

Reading <code>ngx.header.HEADER</code> will return the value of the response header named <code>HEADER</code>.

Underscores (<code>_</code>) in the header names will also be replaced by dashes (<code>-</code>) and the header names will be matched case-insensitively. If the response header is not present at all, <code>nil</code> will be returned.

This is particularly useful in the context of [[#header_filter_by_lua|header_filter_by_lua*]], for example,

<geshi lang="nginx">
    location /test {
        set $footer '';

        proxy_pass http://some-backend;

        header_filter_by_lua_block {
            if ngx.header["X-My-Header"] == "blah" then
                ngx.var.footer = "some value"
            end
        }

        echo_after_body $footer;
    }
</geshi>

For multi-value headers, all of the values of header will be collected in order and returned as a Lua table. For example, response headers

<geshi lang="text">
    Foo: bar
    Foo: baz
</geshi>

will result in

<geshi lang="lua">
    {"bar", "baz"}
</geshi>

to be returned when reading <code>ngx.header.Foo</code>.

Note that <code>ngx.header</code> is not a normal Lua table and as such, it is not possible to iterate through it using the Lua <code>ipairs</code> function.

Note: this function throws a Lua error if <code>HEADER</code> or
<code>VALUE</code> contain unsafe characters (control characters).

For reading ''request'' headers, use the [[#ngx.req.get_headers|ngx.req.get_headers]] function instead.

== ngx.resp.get_headers ==

'''syntax:''' ''headers, err = ngx.resp.get_headers(max_headers?, raw?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*''

Returns a Lua table holding all the current response headers for the current request.

<geshi lang="lua">
local h, err = ngx.resp.get_headers()

if err == "truncated" then
    -- one can choose to ignore or reject the current response here
end

for k, v in pairs(h) do
    ...
end
</geshi>

This function has the same signature as [[#ngx.req.get_headers|ngx.req.get_headers]] except getting response headers instead of request headers.

Note that a maximum of 100 response headers are parsed by default (including those with the same name) and that additional response headers are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string `"truncated"`.

This API was first introduced in the <code>v0.9.5</code> release.

== ngx.req.is_internal ==

'''syntax:''' ''is_internal = ngx.req.is_internal()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Returns a boolean indicating whether the current request is an "internal request", i.e.,
a request initiated from inside the current Nginx server instead of from the client side.

Subrequests are all internal requests and so are requests after internal redirects.

This API was first introduced in the <code>v0.9.20</code> release.

== ngx.req.start_time ==

'''syntax:''' ''secs = ngx.req.start_time()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Returns a floating-point number representing the timestamp (including milliseconds as the decimal part) when the current request was created.

The following example emulates the <code>$request_time</code> variable value (provided by [[HttpLogModule]]) in pure Lua:

<geshi lang="lua">
    local request_time = ngx.now() - ngx.req.start_time()
</geshi>

This function was first introduced in the <code>v0.7.7</code> release.

See also [[#ngx.now|ngx.now]] and [[#ngx.update_time|ngx.update_time]].

== ngx.req.http_version ==

'''syntax:''' ''num = ngx.req.http_version()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*''

Returns the HTTP version number for the current request as a Lua number.

Current possible values are 2.0, 1.0, 1.1, and 0.9. Returns <code>nil</code> for unrecognized values.

This method was first introduced in the <code>v0.7.17</code> release.

== ngx.req.raw_header ==

'''syntax:''' ''str = ngx.req.raw_header(no_request_line?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*''

Returns the original raw HTTP protocol header received by the Nginx server.

By default, the request line and trailing <code>CR LF</code> terminator will also be included. For example,

<geshi lang="lua">
    ngx.print(ngx.req.raw_header())
</geshi>

gives something like this:

<geshi lang="text">
    GET /t HTTP/1.1
    Host: localhost
    Connection: close
    Foo: bar

</geshi>

You can specify the optional
<code>no_request_line</code> argument as a <code>true</code> value to exclude the request line from the result. For example,

<geshi lang="lua">
    ngx.print(ngx.req.raw_header(true))
</geshi>

outputs something like this:

<geshi lang="text">
    Host: localhost
    Connection: close
    Foo: bar

</geshi>

This method was first introduced in the <code>v0.7.17</code> release.

This method does not work in HTTP/2 requests yet.

== ngx.req.get_method ==

'''syntax:''' ''method_name = ngx.req.get_method()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, balancer_by_lua*, log_by_lua*''

Retrieves the current request's request method name. Strings like <code>"GET"</code> and <code>"POST"</code> are returned instead of numerical [[#HTTP method constants|method constants]].

If the current request is an Nginx subrequest, then the subrequest's method name will be returned.

This method was first introduced in the <code>v0.5.6</code> release.

See also [[#ngx.req.set_method|ngx.req.set_method]].

== ngx.req.set_method ==

'''syntax:''' ''ngx.req.set_method(method_id)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*''

Overrides the current request's request method with the <code>method_id</code> argument. Currently only numerical [[#HTTP method constants|method constants]] are supported, like <code>ngx.HTTP_POST</code> and <code>ngx.HTTP_GET</code>.

If the current request is an Nginx subrequest, then the subrequest's method will be overridden.

This method was first introduced in the <code>v0.5.6</code> release.

See also [[#ngx.req.get_method|ngx.req.get_method]].

== ngx.req.set_uri ==

'''syntax:''' ''ngx.req.set_uri(uri, jump?, binary?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*''

Rewrite the current request's (parsed) URI by the <code>uri</code> argument. The <code>uri</code> argument must be a Lua string and cannot be of zero length, or a Lua exception will be thrown.

The optional boolean <code>jump</code> argument can trigger location rematch (or location jump) as [[HttpRewriteModule]]'s [[HttpRewriteModule#rewrite|rewrite]] directive, that is, when <code>jump</code> is <code>true</code> (default to <code>false</code>), this function will never return and it will tell Nginx to try re-searching locations with the new URI value at the later <code>post-rewrite</code> phase and jumping to the new location.

Location jump will not be triggered otherwise, and only the current request's URI will be modified, which is also the default behavior. This function will return but with no returned values when the <code>jump</code> argument is <code>false</code> or absent altogether.

For example, the following Nginx config snippet

<geshi lang="nginx">
    rewrite ^ /foo last;
</geshi>

can be coded in Lua like this:

<geshi lang="lua">
    ngx.req.set_uri("/foo", true)
</geshi>

Similarly, Nginx config

<geshi lang="nginx">
    rewrite ^ /foo break;
</geshi>

can be coded in Lua as

<geshi lang="lua">
    ngx.req.set_uri("/foo", false)
</geshi>

or equivalently,

<geshi lang="lua">
    ngx.req.set_uri("/foo")
</geshi>

The <code>jump</code> argument can only be set to <code>true</code> in [[#rewrite_by_lua|rewrite_by_lua*]]. Use of jump in other contexts is prohibited and will throw out a Lua exception.

A more sophisticated example involving regex substitutions is as follows

<geshi lang="nginx">
    location /test {
        rewrite_by_lua_block {
            local uri = ngx.re.sub(ngx.var.uri, "^/test/(.*)", "/$1", "o")
            ngx.req.set_uri(uri)
        }
        proxy_pass http://my_backend;
    }
</geshi>

which is functionally equivalent to

<geshi lang="nginx">
    location /test {
        rewrite ^/test/(.*) /$1 break;
        proxy_pass http://my_backend;
    }
</geshi>

Note: this function throws a Lua error if the <code>uri</code> argument
contains unsafe characters (control characters).

Note that it is not possible to use this interface to rewrite URI arguments and that [[#ngx.req.set_uri_args|ngx.req.set_uri_args]] should be used for this instead. For instance, Nginx config

<geshi lang="nginx">
    rewrite ^ /foo?a=3? last;
</geshi>

can be coded as

<geshi lang="nginx">
    ngx.req.set_uri_args("a=3")
    ngx.req.set_uri("/foo", true)
</geshi>

or

<geshi lang="nginx">
    ngx.req.set_uri_args({a = 3})
    ngx.req.set_uri("/foo", true)
</geshi>

Starting from <code>0.10.16</code> of this module, this function accepts an
optional boolean <code>binary</code> argument to allow arbitrary binary URI
data. By default, this <code>binary</code> argument is false and this function
will throw out a Lua error such as the one below when the <code>uri</code>
argument contains any control characters (ASCII Code 0 ~ 0x08, 0x0A ~ 0x1F and 0x7F).

<geshi lang="text">
    [error] 23430#23430: *1 lua entry thread aborted: runtime error:
    content_by_lua(nginx.conf:44):3: ngx.req.set_uri unsafe byte "0x00"
    in "\x00foo" (maybe you want to set the 'binary' argument?)
</geshi>

This interface was first introduced in the <code>v0.3.1rc14</code> release.

== ngx.req.set_uri_args ==

'''syntax:''' ''ngx.req.set_uri_args(args)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*''

Rewrite the current request's URI query arguments by the <code>args</code> argument. The <code>args</code> argument can be either a Lua string, as in

<geshi lang="lua">
    ngx.req.set_uri_args("a=3&b=hello%20world")
</geshi>

or a Lua table holding the query arguments' key-value pairs, as in

<geshi lang="lua">
    ngx.req.set_uri_args({ a = 3, b = "hello world" })
</geshi>

In the former case, i.e., when the whole query-string is provided directly,
the input Lua string should already be well-formed with the URI encoding.
For security considerations, this method will automatically escape any control and
whitespace characters (ASCII code 0x00 ~ 0x20 and 0x7F) in the Lua string.

In the latter case, this method will escape argument keys and values according to the URI escaping rule.

Multi-value arguments are also supported:

<geshi lang="lua">
    ngx.req.set_uri_args({ a = 3, b = {5, 6} })
</geshi>

which will result in a query string like <code>a=3&b=5&b=6</code>.

This interface was first introduced in the <code>v0.3.1rc13</code> release.

See also [[#ngx.req.set_uri|ngx.req.set_uri]].

== ngx.req.get_uri_args ==

'''syntax:''' ''args, err = ngx.req.get_uri_args(max_args?, tab?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, balancer_by_lua*''

Returns a Lua table holding all the current request URL query arguments. An optional <code>tab</code> argument
can be used to reuse the table returned by this method.

<geshi lang="nginx">
    location = /test {
        content_by_lua_block {
            local args, err = ngx.req.get_uri_args()

            if err == "truncated" then
                -- one can choose to ignore or reject the current request here
            end

            for key, val in pairs(args) do
                if type(val) == "table" then
                    ngx.say(key, ": ", table.concat(val, ", "))
                else
                    ngx.say(key, ": ", val)
                end
            end
        }
    }
</geshi>

Then <code>GET /test?foo=bar&bar=baz&bar=blah</code> will yield the response body

<geshi lang="bash">
    foo: bar
    bar: baz, blah
</geshi>

Multiple occurrences of an argument key will result in a table value holding all the values for that key in order.

Keys and values are unescaped according to URI escaping rules. In the settings above, <code>GET /test?a%20b=1%61+2</code> will yield:

<geshi lang="bash">
    a b: 1a 2
</geshi>

Arguments without the <code>=<value></code> parts are treated as boolean arguments. <code>GET /test?foo&bar</code> will yield:

<geshi lang="bash">
    foo: true
    bar: true
</geshi>

That is, they will take Lua boolean values <code>true</code>. However, they are different from arguments taking empty string values. <code>GET /test?foo=&bar=</code> will give something like

<geshi lang="bash">
    foo:
    bar:
</geshi>

Empty key arguments are discarded. <code>GET /test?=hello&=world</code> will yield an empty output for instance.

Updating query arguments via the Nginx variable <code>$args</code> (or <code>ngx.var.args</code> in Lua) at runtime is also supported:

<geshi lang="lua">
    ngx.var.args = "a=3&b=42"
    local args, err = ngx.req.get_uri_args()
</geshi>

Here the <code>args</code> table will always look like

<geshi lang="lua">
    {a = 3, b = 42}
</geshi>

regardless of the actual request query string.

Note that a maximum of 100 request arguments are parsed by default (including those with the same name) and that additional request arguments are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string `"truncated"`.

However, the optional <code>max_args</code> function argument can be used to override this limit:

<geshi lang="lua">
    local args, err = ngx.req.get_uri_args(10)
    if err == "truncated" then
        -- one can choose to ignore or reject the current request here
    end
</geshi>

This argument can be set to zero to remove the limit and to process all request arguments received:

<geshi lang="lua">
    local args, err = ngx.req.get_uri_args(0)
</geshi>

Removing the <code>max_args</code> cap is strongly discouraged.

== ngx.req.get_post_args ==

'''syntax:''' ''args, err = ngx.req.get_post_args(max_args?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Returns a Lua table holding all the current request POST query arguments (of the MIME type <code>application/x-www-form-urlencoded</code>). Call [[#ngx.req.read_body|ngx.req.read_body]] to read the request body first or turn on the [[#lua_need_request_body|lua_need_request_body]] directive to avoid errors.

<geshi lang="nginx">
    location = /test {
        content_by_lua_block {
            ngx.req.read_body()
            local args, err = ngx.req.get_post_args()

            if err == "truncated" then
                -- one can choose to ignore or reject the current request here
            end

            if not args then
                ngx.say("failed to get post args: ", err)
                return
            end
            for key, val in pairs(args) do
                if type(val) == "table" then
                    ngx.say(key, ": ", table.concat(val, ", "))
                else
                    ngx.say(key, ": ", val)
                end
            end
        }
    }
</geshi>

Then

<geshi lang="bash">
    # Post request with the body 'foo=bar&bar=baz&bar=blah'
    $ curl --data 'foo=bar&bar=baz&bar=blah' localhost/test
</geshi>

will yield the response body like

<geshi lang="bash">
    foo: bar
    bar: baz, blah
</geshi>

Multiple occurrences of an argument key will result in a table value holding all of the values for that key in order.

Keys and values will be unescaped according to URI escaping rules.

With the settings above,

<geshi lang="bash">
    # POST request with body 'a%20b=1%61+2'
    $ curl -d 'a%20b=1%61+2' localhost/test
</geshi>

will yield:

<geshi lang="bash">
    a b: 1a 2
</geshi>

Arguments without the <code>=<value></code> parts are treated as boolean arguments. <code>POST /test</code> with the request body <code>foo&bar</code> will yield:

<geshi lang="bash">
    foo: true
    bar: true
</geshi>

That is, they will take Lua boolean values <code>true</code>. However, they are different from arguments taking empty string values. <code>POST /test</code> with request body <code>foo=&bar=</code> will return something like

<geshi lang="bash">
    foo:
    bar:
</geshi>

Empty key arguments are discarded. <code>POST /test</code> with body <code>=hello&=world</code> will yield empty outputs for instance.

Note that a maximum of 100 request arguments are parsed by default (including those with the same name) and that additional request arguments are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string `"truncated"`.

However, the optional <code>max_args</code> function argument can be used to override this limit:

<geshi lang="lua">
    local args, err = ngx.req.get_post_args(10)
    if err == "truncated" then
        -- one can choose to ignore or reject the current request here
    end
</geshi>

This argument can be set to zero to remove the limit and to process all request arguments received:

<geshi lang="lua">
    local args, err = ngx.req.get_post_args(0)
</geshi>

Removing the <code>max_args</code> cap is strongly discouraged.

== ngx.req.get_headers ==

'''syntax:''' ''headers, err = ngx.req.get_headers(max_headers?, raw?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Returns a Lua table holding all the current request headers.

<geshi lang="lua">
    local h, err = ngx.req.get_headers()

    if err == "truncated" then
        -- one can choose to ignore or reject the current request here
    end

    for k, v in pairs(h) do
        ...
    end
</geshi>

To read an individual header:

<geshi lang="lua">
    ngx.say("Host: ", ngx.req.get_headers()["Host"])
</geshi>

Note that the [[#ngx.var.VARIABLE|ngx.var.HEADER]] API call, which uses core [[HttpCoreModule#$http_HEADER|$http_HEADER]] variables, may be more preferable for reading individual request headers.

For multiple instances of request headers such as:

<geshi lang="bash">
    Foo: foo
    Foo: bar
    Foo: baz
</geshi>

the value of <code>ngx.req.get_headers()["Foo"]</code> will be a Lua (array) table such as:

<geshi lang="lua">
    {"foo", "bar", "baz"}
</geshi>

Note that a maximum of 100 request headers are parsed by default (including those with the same name) and that additional request headers are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string `"truncated"`.

However, the optional <code>max_headers</code> function argument can be used to override this limit:

<geshi lang="lua">
    local headers, err = ngx.req.get_headers(10)

    if err == "truncated" then
        -- one can choose to ignore or reject the current request here
    end
</geshi>

This argument can be set to zero to remove the limit and to process all request headers received:

<geshi lang="lua">
    local headers, err = ngx.req.get_headers(0)
</geshi>

Removing the <code>max_headers</code> cap is strongly discouraged.

Since the <code>0.6.9</code> release, all the header names in the Lua table returned are converted to the pure lower-case form by default, unless the <code>raw</code> argument is set to <code>true</code> (default to <code>false</code>).

Also, by default, an <code>__index</code> metamethod is added to the resulting Lua table and will normalize the keys to a pure lowercase form with all underscores converted to dashes in case of a lookup miss. For example, if a request header <code>My-Foo-Header</code> is present, then the following invocations will all pick up the value of this header correctly:

<geshi lang="lua">
    ngx.say(headers.my_foo_header)
    ngx.say(headers["My-Foo-Header"])
    ngx.say(headers["my-foo-header"])
</geshi>

The <code>__index</code> metamethod will not be added when the <code>raw</code> argument is set to <code>true</code>.

== ngx.req.set_header ==

'''syntax:''' ''ngx.req.set_header(header_name, header_value)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*''

Set the current request's request header named <code>header_name</code> to value <code>header_value</code>, overriding any existing ones.

The input Lua string `header_name` and `header_value` should already be well-formed with the URI encoding.
For security considerations, this method will automatically escape " ", """, "(", ")", ",", "/", ":", ";", "?",
"<", "=", ">", "?", "@", "[", "]", "\", "{", "}", 0x00-0x1F, 0x7F-0xFF in `header_name` and automatically escape
"0x00-0x08, 0x0A-0x0F, 0x7F in `header_value`.

By default, all the subrequests subsequently initiated by [[#ngx.location.capture|ngx.location.capture]] and [[#ngx.location.capture_multi|ngx.location.capture_multi]] will inherit the new header.

It is not a Lua's equivalent of nginx `proxy_set_header` directive (same is true about [ngx.req.clear_header](#ngxreqclear_header)). `proxy_set_header` only affects the upstream request while `ngx.req.set_header` change the incoming request. Record the http headers in the access log file will show the difference. But you still can use it as an alternative of nginx `proxy_set_header` directive as long as you know the difference.

Here is an example of setting the <code>Content-Type</code> header:

<geshi lang="lua">
    ngx.req.set_header("Content-Type", "text/css")
</geshi>

The <code>header_value</code> can take an array list of values,
for example,

<geshi lang="lua">
    ngx.req.set_header("Foo", {"a", "abc"})
</geshi>

will produce two new request headers:

<geshi lang="bash">
    Foo: a
    Foo: abc
</geshi>

and old <code>Foo</code> headers will be overridden if there is any.

When the <code>header_value</code> argument is <code>nil</code>, the request header will be removed. So

<geshi lang="lua">
    ngx.req.set_header("X-Foo", nil)
</geshi>

is equivalent to

<geshi lang="lua">
    ngx.req.clear_header("X-Foo")
</geshi>

Note: this function throws a Lua error if <code>header_name</code> or
<code>header_value</code> contain unsafe characters (control characters).

== ngx.req.clear_header ==

'''syntax:''' ''ngx.req.clear_header(header_name)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*''

Clears the current request's request header named <code>header_name</code>. None of the current request's existing subrequests will be affected but subsequently initiated subrequests will inherit the change by default.

== ngx.req.read_body ==

'''syntax:''' ''ngx.req.read_body()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Reads the client request body synchronously without blocking the Nginx event loop.

<geshi lang="lua">
    ngx.req.read_body()
    local args = ngx.req.get_post_args()
</geshi>

If the request body is already read previously by turning on [[#lua_need_request_body|lua_need_request_body]] or by using other modules, then this function does not run and returns immediately.

If the request body has already been explicitly discarded, either by the [[#ngx.req.discard_body|ngx.req.discard_body]] function or other modules, this function does not run and returns immediately.

In case of errors, such as connection errors while reading the data, this method will throw out a Lua exception ''or'' terminate the current request with a 500 status code immediately.

The request body data read using this function can be retrieved later via [[#ngx.req.get_body_data|ngx.req.get_body_data]] or, alternatively, the temporary file name for the body data cached to disk using [[#ngx.req.get_body_file|ngx.req.get_body_file]]. This depends on

# whether the current request body is already larger than the [[HttpCoreModule#client_body_buffer_size|client_body_buffer_size]],
# and whether [[HttpCoreModule#client_body_in_file_only|client_body_in_file_only]] has been switched on.

In cases where current request may have a request body and the request body data is not required, The [[#ngx.req.discard_body|ngx.req.discard_body]] function must be used to explicitly discard the request body to avoid breaking things under HTTP 1.1 keepalive or HTTP 1.1 pipelining.

This function was first introduced in the <code>v0.3.1rc17</code> release.

== ngx.req.discard_body ==

'''syntax:''' ''ngx.req.discard_body()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Explicitly discard the request body, i.e., read the data on the connection and throw it away immediately (without using the request body by any means).

This function is an asynchronous call and returns immediately.

If the request body has already been read, this function does nothing and returns immediately.

This function was first introduced in the <code>v0.3.1rc17</code> release.

See also [[#ngx.req.read_body|ngx.req.read_body]].

== ngx.req.get_body_data ==

'''syntax:''' ''data = ngx.req.get_body_data()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, log_by_lua*''

Retrieves in-memory request body data. It returns a Lua string rather than a Lua table holding all the parsed query arguments. Use the [[#ngx.req.get_post_args|ngx.req.get_post_args]] function instead if a Lua table is required.

This function returns <code>nil</code> if

# the request body has not been read,
# the request body has been read into disk temporary files,
# or the request body has zero size.

If the request body has not been read yet, call [[#ngx.req.read_body|ngx.req.read_body]] first (or turn on [[#lua_need_request_body|lua_need_request_body]] to force this module to read the request body. This is not recommended however).

If the request body has been read into disk files, try calling the [[#ngx.req.get_body_file|ngx.req.get_body_file]] function instead.

To force in-memory request bodies, try setting [[HttpCoreModule#client_body_buffer_size|client_body_buffer_size]] to the same size value in [[HttpCoreModule#client_max_body_size|client_max_body_size]].

Note that calling this function instead of using <code>ngx.var.request_body</code> or <code>ngx.var.echo_request_body</code> is more efficient because it can save one dynamic memory allocation and one data copy.

This function was first introduced in the <code>v0.3.1rc17</code> release.

See also [[#ngx.req.get_body_file|ngx.req.get_body_file]].

== ngx.req.get_body_file ==

'''syntax:''' ''file_name = ngx.req.get_body_file()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Retrieves the file name for the in-file request body data. Returns <code>nil</code> if the request body has not been read or has been read into memory.

The returned file is read only and is usually cleaned up by Nginx's memory pool. It should not be manually modified, renamed, or removed in Lua code.

If the request body has not been read yet, call [[#ngx.req.read_body|ngx.req.read_body]] first (or turn on [[#lua_need_request_body|lua_need_request_body]] to force this module to read the request body. This is not recommended however).

If the request body has been read into memory, try calling the [[#ngx.req.get_body_data|ngx.req.get_body_data]] function instead.

To force in-file request bodies, try turning on [[HttpCoreModule#client_body_in_file_only|client_body_in_file_only]].

This function was first introduced in the <code>v0.3.1rc17</code> release.

See also [[#ngx.req.get_body_data|ngx.req.get_body_data]].

== ngx.req.set_body_data ==

'''syntax:''' ''ngx.req.set_body_data(data)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Set the current request's request body using the in-memory data specified by the <code>data</code> argument.

If the request body has not been read yet, call [[#ngx.req.read_body|ngx.req.read_body]] first (or turn on [[#lua_need_request_body|lua_need_request_body]] to force this module to read the request body. This is not recommended however). Additionally, the request body must not have been previously discarded by [[#ngx.req.discard_body|ngx.req.discard_body]].

Whether the previous request body has been read into memory or buffered into a disk file, it will be freed or the disk file will be cleaned up immediately, respectively.

This function was first introduced in the <code>v0.3.1rc18</code> release.

See also [[#ngx.req.set_body_file|ngx.req.set_body_file]].

== ngx.req.set_body_file ==

'''syntax:''' ''ngx.req.set_body_file(file_name, auto_clean?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Set the current request's request body using the in-file data specified by the <code>file_name</code> argument.

If the request body has not been read yet, call [[#ngx.req.read_body|ngx.req.read_body]] first (or turn on [[#lua_need_request_body|lua_need_request_body]] to force this module to read the request body. This is not recommended however). Additionally, the request body must not have been previously discarded by [[#ngx.req.discard_body|ngx.req.discard_body]].

If the optional <code>auto_clean</code> argument is given a <code>true</code> value, then this file will be removed at request completion or the next time this function or [[#ngx.req.set_body_data|ngx.req.set_body_data]] are called in the same request. The <code>auto_clean</code> is default to <code>false</code>.

Please ensure that the file specified by the <code>file_name</code> argument exists and is readable by an Nginx worker process by setting its permission properly to avoid Lua exception errors.

Whether the previous request body has been read into memory or buffered into a disk file, it will be freed or the disk file will be cleaned up immediately, respectively.

This function was first introduced in the <code>v0.3.1rc18</code> release.

See also [[#ngx.req.set_body_data|ngx.req.set_body_data]].

== ngx.req.init_body ==

'''syntax:''' ''ngx.req.init_body(buffer_size?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*''

Creates a new blank request body for the current request and initializes the buffer for later request body data writing via the [[#ngx.req.append_body|ngx.req.append_body]] and [[#ngx.req.finish_body|ngx.req.finish_body]] APIs.

If the <code>buffer_size</code> argument is specified, then its value will be used for the size of the memory buffer for body writing with [[#ngx.req.append_body|ngx.req.append_body]]. If the argument is omitted, then the value specified by the standard [[HttpCoreModule#client_body_buffer_size|client_body_buffer_size]] directive will be used instead.

When the data can no longer be hold in the memory buffer for the request body, then the data will be flushed onto a temporary file just like the standard request body reader in the Nginx core.

It is important to always call the [[#ngx.req.finish_body|ngx.req.finish_body]] after all the data has been appended onto the current request body. Also, when this function is used together with [[#ngx.req.socket|ngx.req.socket]], it is required to call [[#ngx.req.socket|ngx.req.socket]] ''before'' this function, or you will get the "request body already exists" error message.

The usage of this function is often like this:

<geshi lang="lua">
    ngx.req.init_body(128 * 1024)  -- buffer is 128KB
    for chunk in next_data_chunk() do
        ngx.req.append_body(chunk) -- each chunk can be 4KB
    end
    ngx.req.finish_body()
</geshi>

This function can be used with [[#ngx.req.append_body|ngx.req.append_body]], [[#ngx.req.finish_body|ngx.req.finish_body]], and [[#ngx.req.socket|ngx.req.socket]] to implement efficient input filters in pure Lua (in the context of [[#rewrite_by_lua|rewrite_by_lua*]] or [[#access_by_lua|access_by_lua*]]), which can be used with other Nginx content handler or upstream modules like [[HttpProxyModule]] and [[HttpFastcgiModule]].

This function was first introduced in the <code>v0.5.11</code> release.

== ngx.req.append_body ==

'''syntax:''' ''ngx.req.append_body(data_chunk)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*''

Append new data chunk specified by the <code>data_chunk</code> argument onto the existing request body created by the [[#ngx.req.init_body|ngx.req.init_body]] call.

When the data can no longer be hold in the memory buffer for the request body, then the data will be flushed onto a temporary file just like the standard request body reader in the Nginx core.

It is important to always call the [[#ngx.req.finish_body|ngx.req.finish_body]] after all the data has been appended onto the current request body.

This function can be used with [[#ngx.req.init_body|ngx.req.init_body]], [[#ngx.req.finish_body|ngx.req.finish_body]], and [[#ngx.req.socket|ngx.req.socket]] to implement efficient input filters in pure Lua (in the context of [[#rewrite_by_lua|rewrite_by_lua*]] or [[#access_by_lua|access_by_lua*]]), which can be used with other Nginx content handler or upstream modules like [[HttpProxyModule]] and [[HttpFastcgiModule]].

This function was first introduced in the <code>v0.5.11</code> release.

See also [[#ngx.req.init_body|ngx.req.init_body]].

== ngx.req.finish_body ==

'''syntax:''' ''ngx.req.finish_body()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*''

Completes the construction process of the new request body created by the [[#ngx.req.init_body|ngx.req.init_body]] and [[#ngx.req.append_body|ngx.req.append_body]] calls.

This function can be used with [[#ngx.req.init_body|ngx.req.init_body]], [[#ngx.req.append_body|ngx.req.append_body]], and [[#ngx.req.socket|ngx.req.socket]] to implement efficient input filters in pure Lua (in the context of [[#rewrite_by_lua|rewrite_by_lua*]] or [[#access_by_lua|access_by_lua*]]), which can be used with other Nginx content handler or upstream modules like [[HttpProxyModule]] and [[HttpFastcgiModule]].

This function was first introduced in the <code>v0.5.11</code> release.

See also [[#ngx.req.init_body|ngx.req.init_body]].

== ngx.req.socket ==

'''syntax:''' ''tcpsock, err = ngx.req.socket()''

'''syntax:''' ''tcpsock, err = ngx.req.socket(raw)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Returns a read-only cosocket object that wraps the downstream connection. Only [[#tcpsock:receive|receive]], [[#tcpsock:receiveany|receiveany]] and [[#tcpsock:receiveuntil|receiveuntil]] methods are supported on this object.

In case of error, <code>nil</code> will be returned as well as a string describing the error.

The socket object returned by this method is usually used to read the current request's body in a streaming fashion. Do not turn on the [[#lua_need_request_body|lua_need_request_body]] directive, and do not mix this call with [[#ngx.req.read_body|ngx.req.read_body]] and [[#ngx.req.discard_body|ngx.req.discard_body]].

If any request body data has been pre-read into the Nginx core request header buffer, the resulting cosocket object will take care of this to avoid potential data loss resulting from such pre-reading.
Chunked request bodies are not yet supported in this API.

Since the <code>v0.9.0</code> release, this function accepts an optional boolean <code>raw</code> argument. When this argument is <code>true</code>, this function returns a full-duplex cosocket object wrapping around the raw downstream connection socket, upon which you can call the [[#tcpsock:receive|receive]], [[#tcpsock:receiveany|receiveany]], [[#tcpsock:receiveuntil|receiveuntil]], and [[#tcpsock:send|send]] methods.

When the <code>raw</code> argument is <code>true</code>, it is required that no pending data from any previous [[#ngx.say|ngx.say]], [[#ngx.print|ngx.print]], or [[#ngx.send_headers|ngx.send_headers]] calls exists. So if you have these downstream output calls previously, you should call [[#ngx.flush|ngx.flush(true)]] before calling <code>ngx.req.socket(true)</code> to ensure that there is no pending output data. If the request body has not been read yet, then this "raw socket" can also be used to read the request body.

You can use the "raw request socket" returned by <code>ngx.req.socket(true)</code> to implement fancy protocols like [https://en.wikipedia.org/wiki/WebSocket WebSocket], or just emit your own raw HTTP response header or body data. You can refer to the [https://github.com/openresty/lua-resty-websocket lua-resty-websocket library] for a real world example.

This function was first introduced in the <code>v0.5.0rc1</code> release.

== ngx.exec ==

'''syntax:''' ''ngx.exec(uri, args?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Does an internal redirect to <code>uri</code> with <code>args</code> and is similar to the [[HttpEchoModule#echo_exec|echo_exec]] directive of the [[HttpEchoModule]].

<geshi lang="lua">
    ngx.exec('/some-location')
    ngx.exec('/some-location', 'a=3&b=5&c=6')
    ngx.exec('/some-location?a=3&b=5', 'c=6')
</geshi>

The optional second <code>args</code> can be used to specify extra URI query arguments, for example:

<geshi lang="lua">
    ngx.exec("/foo", "a=3&b=hello%20world")
</geshi>

Alternatively, a Lua table can be passed for the <code>args</code> argument for ngx_lua to carry out URI escaping and string concatenation.

<geshi lang="lua">
    ngx.exec("/foo", { a = 3, b = "hello world" })
</geshi>

The result is exactly the same as the previous example.

The format for the Lua table passed as the <code>args</code> argument is identical to the format used in the [[#ngx.encode_args|ngx.encode_args]] method.

Named locations are also supported but the second <code>args</code> argument will be ignored if present and the querystring for the new target is inherited from the referring location (if any).

<code>GET /foo/file.php?a=hello</code> will return "hello" and not "goodbye" in the example below

<geshi lang="nginx">
    location /foo {
        content_by_lua_block {
            ngx.exec("@bar", "a=goodbye")
        }
    }

    location @bar {
        content_by_lua_block {
            local args = ngx.req.get_uri_args()
            for key, val in pairs(args) do
                if key == "a" then
                    ngx.say(val)
                end
            end
        }
    }
</geshi>

Note that the <code>ngx.exec</code> method is different from [[#ngx.redirect|ngx.redirect]] in that
it is purely an internal redirect and that no new external HTTP traffic is involved.

Also note that this method call terminates the processing of the current request and that it ''must'' be called before [[#ngx.send_headers|ngx.send_headers]] or explicit response body
outputs by either [[#ngx.print|ngx.print]] or [[#ngx.say|ngx.say]].

It is recommended that a coding style that combines this method call with the <code>return</code> statement, i.e., <code>return ngx.exec(...)</code> be adopted when this method call is used in contexts other than [[#header_filter_by_lua|header_filter_by_lua*]] to reinforce the fact that the request processing is being terminated.

== ngx.redirect ==

'''syntax:''' ''ngx.redirect(uri, status?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Issue an <code>HTTP 301</code> or <code>302</code> redirection to <code>uri</code>.

Note: this function throws a Lua error if the <code>uri</code> argument
contains unsafe characters (control characters).

The optional <code>status</code> parameter specifies the HTTP status code to be used. The following status codes are supported right now:

* <code>301</code>
* <code>302</code> (default)
* <code>303</code>
* <code>307</code>
* <code>308</code>

It is <code>302</code> (<code>ngx.HTTP_MOVED_TEMPORARILY</code>) by default.

Here is an example assuming the current server name is <code>localhost</code> and that it is listening on port 1984:

<geshi lang="lua">
    return ngx.redirect("/foo")
</geshi>

which is equivalent to

<geshi lang="lua">
    return ngx.redirect("/foo", ngx.HTTP_MOVED_TEMPORARILY)
</geshi>

Redirecting arbitrary external URLs is also supported, for example:

<geshi lang="lua">
    return ngx.redirect("http://www.google.com")
</geshi>

We can also use the numerical code directly as the second <code>status</code> argument:

<geshi lang="lua">
    return ngx.redirect("/foo", 301)
</geshi>

This method is similar to the [[HttpRewriteModule#rewrite|rewrite]] directive with the <code>redirect</code> modifier in the standard
[[HttpRewriteModule]], for example, this <code>nginx.conf</code> snippet

<geshi lang="nginx">
    rewrite ^ /foo? redirect;  # nginx config
</geshi>

is equivalent to the following Lua code

<geshi lang="lua">
    return ngx.redirect('/foo')  -- Lua code
</geshi>

while

<geshi lang="nginx">
    rewrite ^ /foo? permanent;  # nginx config
</geshi>

is equivalent to

<geshi lang="lua">
    return ngx.redirect('/foo', ngx.HTTP_MOVED_PERMANENTLY)  -- Lua code
</geshi>

URI arguments can be specified as well, for example:

<geshi lang="lua">
    return ngx.redirect('/foo?a=3&b=4')
</geshi>

Note that this method call terminates the processing of the current request and that it ''must'' be called before [[#ngx.send_headers|ngx.send_headers]] or explicit response body
outputs by either [[#ngx.print|ngx.print]] or [[#ngx.say|ngx.say]].

It is recommended that a coding style that combines this method call with the <code>return</code> statement, i.e., <code>return ngx.redirect(...)</code> be adopted when this method call is used in contexts other than [[#header_filter_by_lua|header_filter_by_lua*]] to reinforce the fact that the request processing is being terminated.

== ngx.send_headers ==

'''syntax:''' ''ok, err = ngx.send_headers()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Explicitly send out the response headers.

Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.

Note that there is normally no need to manually send out response headers as ngx_lua will automatically send headers out
before content is output with [[#ngx.say|ngx.say]] or [[#ngx.print|ngx.print]] or when [[#content_by_lua|content_by_lua*]] exits normally.

== ngx.headers_sent ==

'''syntax:''' ''value = ngx.headers_sent''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*''

Returns <code>true</code> if the response headers have been sent (by ngx_lua), and <code>false</code> otherwise.

This API was first introduced in ngx_lua v0.3.1rc6.

== ngx.print ==

'''syntax:''' ''ok, err = ngx.print(...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Emits arguments concatenated to the HTTP client (as response body). If response headers have not been sent, this function will send headers out first and then output body data.

Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.

Lua <code>nil</code> values will output <code>"nil"</code> strings and Lua boolean values will output <code>"true"</code> and <code>"false"</code> literal strings respectively.

Nested arrays of strings are permitted and the elements in the arrays will be sent one by one:

<geshi lang="lua">
    local table = {
        "hello, ",
        {"world: ", true, " or ", false,
            {": ", nil}}
    }
    ngx.print(table)
</geshi>

will yield the output

<geshi lang="bash">
    hello, world: true or false: nil
</geshi>

Non-array table arguments will cause a Lua exception to be thrown.

The <code>ngx.null</code> constant will yield the <code>"null"</code> string output.

This is an asynchronous call and will return immediately without waiting for all the data to be written into the system send buffer. To run in synchronous mode, call <code>ngx.flush(true)</code> after calling <code>ngx.print</code>. This can be particularly useful for streaming output. See [[#ngx.flush|ngx.flush]] for more details.

Please note that both <code>ngx.print</code> and [[#ngx.say|ngx.say]] will always invoke the whole Nginx output body filter chain, which is an expensive operation. So be careful when calling either of these two in a tight loop; buffer the data yourself in Lua and save the calls.

== ngx.say ==

'''syntax:''' ''ok, err = ngx.say(...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Just as [[#ngx.print|ngx.print]] but also emit a trailing newline.

== ngx.log ==

'''syntax:''' ''ngx.log(log_level, ...)''

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Log arguments concatenated to error.log with the given logging level.

Lua <code>nil</code> arguments are accepted and result in literal <code>"nil"</code> string while Lua booleans result in literal <code>"true"</code> or <code>"false"</code> string outputs. And the <code>ngx.null</code> constant will yield the <code>"null"</code> string output.

The <code>log_level</code> argument can take constants like <code>ngx.ERR</code> and <code>ngx.WARN</code>. Check out [[#Nginx log level constants|Nginx log level constants]] for details.

There is a hard coded <code>2048</code> byte limitation on error message lengths in the Nginx core. This limit includes trailing newlines and leading time stamps. If the message size exceeds this limit, Nginx will truncate the message text accordingly. This limit can be manually modified by editing the <code>NGX_MAX_ERROR_STR</code> macro definition in the <code>src/core/ngx_log.h</code> file in the Nginx source tree.

== ngx.flush ==

'''syntax:''' ''ok, err = ngx.flush(wait?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Flushes response output to the client.

<code>ngx.flush</code> accepts an optional boolean <code>wait</code> argument (Default: <code>false</code>) first introduced in the <code>v0.3.1rc34</code> release. When called with the default argument, it issues an asynchronous call (Returns immediately without waiting for output data to be written into the system send buffer). Calling the function with the <code>wait</code> argument set to <code>true</code> switches to synchronous mode.

In synchronous mode, the function will not return until all output data has been written into the system send buffer or until the [[HttpCoreModule#send_timeout|send_timeout]] setting has expired. Note that using the Lua coroutine mechanism means that this function does not block the Nginx event loop even in the synchronous mode.

When <code>ngx.flush(true)</code> is called immediately after [[#ngx.print|ngx.print]] or [[#ngx.say|ngx.say]], it causes the latter functions to run in synchronous mode. This can be particularly useful for streaming output.

Note that <code>ngx.flush</code> is not functional when in the HTTP 1.0 output buffering mode. See [[#HTTP 1.0 support|HTTP 1.0 support]].

Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.

== ngx.exit ==

'''syntax:''' ''ngx.exit(status)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

When <code>status >= 200</code> (i.e., <code>ngx.HTTP_OK</code> and above), it will interrupt the execution of the current request and return status code to Nginx.

When <code>status == 0</code> (i.e., <code>ngx.OK</code>), it will only quit the current phase handler (or the content handler if the [[#content_by_lua|content_by_lua*]] directive is used) and continue to run later phases (if any) for the current request.

The <code>status</code> argument can be <code>ngx.OK</code>, <code>ngx.ERROR</code>, <code>ngx.HTTP_NOT_FOUND</code>,
<code>ngx.HTTP_MOVED_TEMPORARILY</code>, or other [[#HTTP status constants|HTTP status constants]].

To return an error page with custom contents, use code snippets like this:

<geshi lang="lua">
    ngx.status = ngx.HTTP_GONE
    ngx.say("This is our own content")
    -- to cause quit the whole request rather than the current phase handler
    ngx.exit(ngx.HTTP_OK)
</geshi>

The effect in action:

<geshi lang="bash">
    $ curl -i http://localhost/test
    HTTP/1.1 410 Gone
    Server: nginx/1.0.6
    Date: Thu, 15 Sep 2011 00:51:48 GMT
    Content-Type: text/plain
    Transfer-Encoding: chunked
    Connection: keep-alive

    This is our own content
</geshi>

Number literals can be used directly as the argument, for instance,

<geshi lang="lua">
    ngx.exit(501)
</geshi>

Note that while this method accepts all [[#HTTP status constants|HTTP status constants]] as input, it only accepts <code>ngx.OK</code> and <code>ngx.ERROR</code> of the [[#core constants|core constants]].

Also note that this method call terminates the processing of the current request and that it is recommended that a coding style that combines this method call with the <code>return</code> statement, i.e., <code>return ngx.exit(...)</code> be used to reinforce the fact that the request processing is being terminated.

When being used in the contexts of [[#header_filter_by_lua|header_filter_by_lua*]], [[#balancer_by_lua_block|balancer_by_lua*]], and
[[#ssl_session_store_by_lua_block|ssl_session_store_by_lua*]], <code>ngx.exit()</code> is
an asynchronous operation and will return immediately. This behavior may change in future and it is recommended that users always use <code>return</code> in combination as suggested above.

== ngx.eof ==

'''syntax:''' ''ok, err = ngx.eof()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Explicitly specify the end of the response output stream. In the case of HTTP 1.1 chunked encoded output, it will just trigger the Nginx core to send out the "last chunk".

When you disable the HTTP 1.1 keep-alive feature for your downstream connections, you can rely on well written HTTP clients to close the connection actively for you when you call this method. This trick can be used do back-ground jobs without letting the HTTP clients to wait on the connection, as in the following example:

<geshi lang="nginx">
    location = /async {
        keepalive_timeout 0;
        content_by_lua_block {
            ngx.say("got the task!")
            ngx.eof()  -- well written HTTP clients will close the connection at this point
            -- access MySQL, PostgreSQL, Redis, Memcached, and etc here...
        }
    }
</geshi>

But if you create subrequests to access other locations configured by Nginx upstream modules, then you should configure those upstream modules to ignore client connection abortions if they are not by default. For example, by default the standard [[HttpProxyModule]] will terminate both the subrequest and the main request as soon as the client closes the connection, so it is important to turn on the [[HttpProxyModule#proxy_ignore_client_abort|proxy_ignore_client_abort]] directive in your location block configured by [[HttpProxyModule]]:

<geshi lang="nginx">
    proxy_ignore_client_abort on;
</geshi>

A better way to do background jobs is to use the [[#ngx.timer.at|ngx.timer.at]] API.

Since <code>v0.8.3</code> this function returns <code>1</code> on success, or returns <code>nil</code> and a string describing the error otherwise.

== ngx.sleep ==

'''syntax:''' ''ngx.sleep(seconds)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Sleeps for the specified seconds without blocking. One can specify time resolution up to 0.001 seconds (i.e., one millisecond).

Behind the scene, this method makes use of the Nginx timers.

Since the <code>0.7.20</code> release, The <code>0</code> time argument can also be specified.

This method was introduced in the <code>0.5.0rc30</code> release.

== ngx.escape_uri ==

'''syntax:''' ''newstr = ngx.escape_uri(str, type?)''

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Since `v0.10.16`, this function accepts an optional <code>type</code> argument.
It accepts the following values (defaults to `2`):

* `0`: escapes <code>str</code> as a full URI. And the characters
<code> </code> (space), <code>#</code>, <code>%</code>,
`?`, 0x00 ~ 0x1F, 0x7F ~ 0xFF will be escaped.
* `2`: escape <code>str</code> as a URI component. All characters except
alphabetic characters, digits, <code>-</code>, <code>.</code>, <code>_</code>,
<code>~</code> will be encoded as `%XX`.

== ngx.unescape_uri ==

'''syntax:''' ''newstr = ngx.unescape_uri(str)''

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Unescape <code>str</code> as an escaped URI component.

For example,

<geshi lang="lua">
    ngx.say(ngx.unescape_uri("b%20r56+7"))
</geshi>

gives the output

<geshi lang="text">
    b r56 7
</geshi>

Invalid escaping sequences are handled in a conventional way: `%`s are left unchanged. Also, characters that should not appear in escaped string are simply left unchanged.

For example,

<geshi lang="lua">
    ngx.say(ngx.unescape_uri("try %search%%20%again%"))
</geshi>

gives the output

<geshi lang="text">
    try %search% %again%
</geshi>

(Note that `%20` following `%` got unescaped, even it can be considered a part of invalid sequence.)

== ngx.encode_args ==

'''syntax:''' ''str = ngx.encode_args(table)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_client_hello_by_lua*''

Encode the Lua table to a query args string according to the URI encoded rules.

For example,

<geshi lang="lua">
    ngx.encode_args({foo = 3, ["b r"] = "hello world"})
</geshi>

yields

<geshi lang="text">
    foo=3&b%20r=hello%20world
</geshi>

The table keys must be Lua strings.

Multi-value query args are also supported. Just use a Lua table for the argument's value, for example:

<geshi lang="lua">
    ngx.encode_args({baz = {32, "hello"}})
</geshi>

gives

<geshi lang="text">
    baz=32&baz=hello
</geshi>

If the value table is empty and the effect is equivalent to the <code>nil</code> value.

Boolean argument values are also supported, for instance,

<geshi lang="lua">
    ngx.encode_args({a = true, b = 1})
</geshi>

yields

<geshi lang="text">
    a&b=1
</geshi>

If the argument value is <code>false</code>, then the effect is equivalent to the <code>nil</code> value.

This method was first introduced in the <code>v0.3.1rc27</code> release.

== ngx.decode_args ==

'''syntax:''' ''table, err = ngx.decode_args(str, max_args?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Decodes a URI encoded query-string into a Lua table. This is the inverse function of [[#ngx.encode_args|ngx.encode_args]].

The optional <code>max_args</code> argument can be used to specify the maximum number of arguments parsed from the <code>str</code> argument. By default, a maximum of 100 request arguments are parsed (including those with the same name) and that additional URI arguments are silently discarded to guard against potential denial of service attacks. Since <code>v0.10.13</code>, when the limit is exceeded, it will return a second value which is the string `"truncated"`.

This argument can be set to zero to remove the limit and to process all request arguments received:

<geshi lang="lua">
    local args = ngx.decode_args(str, 0)
</geshi>

Removing the <code>max_args</code> cap is strongly discouraged.

This method was introduced in the <code>v0.5.0rc29</code>.

== ngx.encode_base64 ==

'''syntax:''' ''newstr = ngx.encode_base64(str, no_padding?)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Encodes <code>str</code> to a base64 digest.

Since the <code>0.9.16</code> release, an optional boolean-typed <code>no_padding</code> argument can be specified to control whether the base64 padding should be appended to the resulting digest (default to <code>false</code>, i.e., with padding enabled).

== ngx.decode_base64 ==

'''syntax:''' ''newstr = ngx.decode_base64(str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Decodes the <code>str</code> argument as a base64 digest to the raw form. Returns <code>nil</code> if <code>str</code> is not well formed.

== ngx.crc32_short ==

'''syntax:''' ''intval = ngx.crc32_short(str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Calculates the CRC-32 (Cyclic Redundancy Code) digest for the <code>str</code> argument.

This method performs better on relatively short <code>str</code> inputs (i.e., less than 30 ~ 60 bytes), as compared to [[#ngx.crc32_long|ngx.crc32_long]]. The result is exactly the same as [[#ngx.crc32_long|ngx.crc32_long]].

Behind the scene, it is just a thin wrapper around the <code>ngx_crc32_short</code> function defined in the Nginx core.

This API was first introduced in the <code>v0.3.1rc8</code> release.

== ngx.crc32_long ==

'''syntax:''' ''intval = ngx.crc32_long(str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Calculates the CRC-32 (Cyclic Redundancy Code) digest for the <code>str</code> argument.

This method performs better on relatively long <code>str</code> inputs (i.e., longer than 30 ~ 60 bytes), as compared to [[#ngx.crc32_short|ngx.crc32_short]].  The result is exactly the same as [[#ngx.crc32_short|ngx.crc32_short]].

Behind the scene, it is just a thin wrapper around the <code>ngx_crc32_long</code> function defined in the Nginx core.

This API was first introduced in the <code>v0.3.1rc8</code> release.

== ngx.hmac_sha1 ==

'''syntax:''' ''digest = ngx.hmac_sha1(secret_key, str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Computes the [https://en.wikipedia.org/wiki/HMAC HMAC-SHA1] digest of the argument <code>str</code> and turns the result using the secret key <code><secret_key></code>.

The raw binary form of the <code>HMAC-SHA1</code> digest will be generated, use [[#ngx.encode_base64|ngx.encode_base64]], for example, to encode the result to a textual representation if desired.

For example,

<geshi lang="lua">
    local key = "thisisverysecretstuff"
    local src = "some string we want to sign"
    local digest = ngx.hmac_sha1(key, src)
    ngx.say(ngx.encode_base64(digest))
</geshi>

yields the output

<geshi lang="text">
    R/pvxzHC4NLtj7S+kXFg/NePTmk=
</geshi>

This API requires the OpenSSL library enabled in the Nginx build (usually by passing the <code>--with-http_ssl_module</code> option to the <code>./configure</code> script).

This function was first introduced in the <code>v0.3.1rc29</code> release.

== ngx.md5 ==

'''syntax:''' ''digest = ngx.md5(str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Returns the hexadecimal representation of the MD5 digest of the <code>str</code> argument.

For example,

<geshi lang="nginx">
    location = /md5 {
        content_by_lua_block {
            ngx.say(ngx.md5("hello"))
        }
    }
</geshi>

yields the output

<geshi lang="text">
    5d41402abc4b2a76b9719d911017c592
</geshi>

See [[#ngx.md5_bin|ngx.md5_bin]] if the raw binary MD5 digest is required.

== ngx.md5_bin ==

'''syntax:''' ''digest = ngx.md5_bin(str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Returns the binary form of the MD5 digest of the <code>str</code> argument.

See [[#ngx.md5|ngx.md5]] if the hexadecimal form of the MD5 digest is required.

== ngx.sha1_bin ==

'''syntax:''' ''digest = ngx.sha1_bin(str)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Returns the binary form of the SHA-1 digest of the <code>str</code> argument.

This function requires SHA-1 support in the Nginx build. (This usually just means OpenSSL should be installed while building Nginx).

This function was first introduced in the <code>v0.5.0rc6</code>.

== ngx.quote_sql_str ==

'''syntax:''' ''quoted_value = ngx.quote_sql_str(raw_value)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Returns a quoted SQL string literal according to the MySQL quoting rules.

== ngx.today ==

'''syntax:''' ''str = ngx.today()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns current date (in the format <code>yyyy-mm-dd</code>) from the Nginx cached time (no syscall involved unlike Lua's date library).

This is the local time.

== ngx.time ==

'''syntax:''' ''secs = ngx.time()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns the elapsed seconds from the epoch for the current time stamp from the Nginx cached time (no syscall involved unlike Lua's date library).

Updates of the Nginx time cache can be forced by calling [[#ngx.update_time|ngx.update_time]] first.

== ngx.now ==

'''syntax:''' ''secs = ngx.now()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns a floating-point number for the elapsed time in seconds (including milliseconds as the decimal part) from the epoch for the current time stamp from the Nginx cached time (no syscall involved unlike Lua's date library).

You can forcibly update the Nginx time cache by calling [[#ngx.update_time|ngx.update_time]] first.

This API was first introduced in <code>v0.3.1rc32</code>.

== ngx.update_time ==

'''syntax:''' ''ngx.update_time()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Forcibly updates the Nginx current time cache. This call involves a syscall and thus has some overhead, so do not abuse it.

This API was first introduced in <code>v0.3.1rc32</code>.

== ngx.localtime ==

'''syntax:''' ''str = ngx.localtime()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns the current time stamp (in the format <code>yyyy-mm-dd hh:mm:ss</code>) of the Nginx cached time (no syscall involved unlike Lua's [https://www.lua.org/manual/5.1/manual.html#pdf-os.date os.date] function).

This is the local time.

== ngx.utctime ==

'''syntax:''' ''str = ngx.utctime()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns the current time stamp (in the format <code>yyyy-mm-dd hh:mm:ss</code>) of the Nginx cached time (no syscall involved unlike Lua's [https://www.lua.org/manual/5.1/manual.html#pdf-os.date os.date] function).

This is the UTC time.

== ngx.cookie_time ==

'''syntax:''' ''str = ngx.cookie_time(sec)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns a formatted string can be used as the cookie expiration time. The parameter <code>sec</code> is the time stamp in seconds (like those returned from [[#ngx.time|ngx.time]]).

<geshi lang="nginx">
    ngx.say(ngx.cookie_time(1290079655))
        -- yields "Thu, 18-Nov-10 11:27:35 GMT"
</geshi>

== ngx.http_time ==

'''syntax:''' ''str = ngx.http_time(sec)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns a formated string can be used as the http header time (for example, being used in <code>Last-Modified</code> header). The parameter <code>sec</code> is the time stamp in seconds (like those returned from [[#ngx.time|ngx.time]]).

<geshi lang="nginx">
    ngx.say(ngx.http_time(1290079655))
        -- yields "Thu, 18 Nov 2010 11:27:35 GMT"
</geshi>

== ngx.parse_http_time ==

'''syntax:''' ''sec = ngx.parse_http_time(str)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Parse the http time string (as returned by [[#ngx.http_time|ngx.http_time]]) into seconds. Returns the seconds or <code>nil</code> if the input string is in bad forms.

<geshi lang="nginx">
    local time = ngx.parse_http_time("Thu, 18 Nov 2010 11:27:35 GMT")
    if time == nil then
        ...
    end
</geshi>

== ngx.is_subrequest ==

'''syntax:''' ''value = ngx.is_subrequest''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*''

Returns <code>true</code> if the current request is an Nginx subrequest, or <code>false</code> otherwise.

== ngx.re.match ==

'''syntax:''' ''captures, err = ngx.re.match(subject, regex, options?, ctx?, res_table?)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Matches the <code>subject</code> string using the Perl compatible regular expression <code>regex</code> with the optional <code>options</code>.

Only the first occurrence of the match is returned, or <code>nil</code> if no match is found. In case of errors, like seeing a bad regular expression or exceeding the PCRE stack limit, <code>nil</code> and a string describing the error will be returned.

When a match is found, a Lua table <code>captures</code> is returned, where <code>captures[0]</code> holds the whole substring being matched, and <code>captures[1]</code> holds the first parenthesized sub-pattern's capturing, <code>captures[2]</code> the second, and so on.

<geshi lang="lua">
    local m, err = ngx.re.match("hello, 1234", "[0-9]+")
    if m then
        -- m[0] == "1234"

    else
        if err then
            ngx.log(ngx.ERR, "error: ", err)
            return
        end

        ngx.say("match not found")
    end
</geshi>

<geshi lang="lua">
    local m, err = ngx.re.match("hello, 1234", "([0-9])[0-9]+")
    -- m[0] == "1234"
    -- m[1] == "1"
</geshi>

Named captures are also supported since the <code>v0.7.14</code> release
and are returned in the same Lua table as key-value pairs as the numbered captures.

<geshi lang="lua">
    local m, err = ngx.re.match("hello, 1234", "([0-9])(?<remaining>[0-9]+)")
    -- m[0] == "1234"
    -- m[1] == "1"
    -- m[2] == "234"
    -- m["remaining"] == "234"
</geshi>

Unmatched subpatterns will have <code>false</code> values in their <code>captures</code> table fields.

<geshi lang="lua">
    local m, err = ngx.re.match("hello, world", "(world)|(hello)|(?<named>howdy)")
    -- m[0] == "hello"
    -- m[1] == false
    -- m[2] == "hello"
    -- m[3] == false
    -- m["named"] == false
</geshi>

Specify <code>options</code> to control how the match operation will be performed. The following option characters are supported:

<geshi lang="text">
    a             anchored mode (only match from the beginning)

    d             enable the DFA mode (or the longest token match semantics).
                  this requires PCRE 6.0+ or else a Lua exception will be thrown.
                  first introduced in ngx_lua v0.3.1rc30.

    D             enable duplicate named pattern support. This allows named
                  subpattern names to be repeated, returning the captures in
                  an array-like Lua table. for example,
                    local m = ngx.re.match("hello, world",
                                           "(?<named>\w+), (?<named>\w+)",
                                           "D")
                    -- m["named"] == {"hello", "world"}
                  this option was first introduced in the v0.7.14 release.
                  this option requires at least PCRE 8.12.

    i             case insensitive mode (similar to Perl's /i modifier)

    j             enable PCRE JIT compilation, this requires PCRE 8.21+ which
                  must be built with the --enable-jit option. for optimum performance,
                  this option should always be used together with the 'o' option.
                  first introduced in ngx_lua v0.3.1rc30.

    J             enable the PCRE Javascript compatible mode. this option was
                  first introduced in the v0.7.14 release. this option requires
                  at least PCRE 8.12.

    m             multi-line mode (similar to Perl's /m modifier)

    o             compile-once mode (similar to Perl's /o modifier),
                  to enable the worker-process-level compiled-regex cache

    s             single-line mode (similar to Perl's /s modifier)

    u             UTF-8 mode. this requires PCRE to be built with
                  the --enable-utf8 option or else a Lua exception will be thrown.

    U             similar to "u" but disables PCRE's UTF-8 validity check on
                  the subject string. first introduced in ngx_lua v0.8.1.

    x             extended mode (similar to Perl's /x modifier)
</geshi>

These options can be combined:

<geshi lang="nginx">
    local m, err = ngx.re.match("hello, world", "HEL LO", "ix")
    -- m[0] == "hello"
</geshi>

<geshi lang="nginx">
    local m, err = ngx.re.match("hello, 美好生活", "HELLO, (.{2})", "iu")
    -- m[0] == "hello, 美好"
    -- m[1] == "美好"
</geshi>

The <code>o</code> option is useful for performance tuning, because the regex pattern in question will only be compiled once, cached in the worker-process level, and shared among all requests in the current Nginx worker process. The upper limit of the regex cache can be tuned via the [[#lua_regex_cache_max_entries|lua_regex_cache_max_entries]] directive.

The optional fourth argument, <code>ctx</code>, can be a Lua table holding an optional <code>pos</code> field. When the <code>pos</code> field in the <code>ctx</code> table argument is specified, <code>ngx.re.match</code> will start matching from that offset (starting from 1). Regardless of the presence of the <code>pos</code> field in the <code>ctx</code> table, <code>ngx.re.match</code> will always set this <code>pos</code> field to the position ''after'' the substring matched by the whole pattern in case of a successful match. When match fails, the <code>ctx</code> table will be left intact.

<geshi lang="lua">
    local ctx = {}
    local m, err = ngx.re.match("1234, hello", "[0-9]+", "", ctx)
         -- m[0] = "1234"
         -- ctx.pos == 5
</geshi>

<geshi lang="lua">
    local ctx = { pos = 2 }
    local m, err = ngx.re.match("1234, hello", "[0-9]+", "", ctx)
         -- m[0] = "234"
         -- ctx.pos == 5
</geshi>

The <code>ctx</code> table argument combined with the <code>a</code> regex modifier can be used to construct a lexer atop <code>ngx.re.match</code>.

Note that, the <code>options</code> argument is not optional when the <code>ctx</code> argument is specified and that the empty Lua string (<code>""</code>) must be used as placeholder for <code>options</code> if no meaningful regex options are required.

This method requires the PCRE library enabled in Nginx ([[#Special Escaping Sequences|Known Issue With Special Escaping Sequences]]).

To confirm that PCRE JIT is enabled, activate the Nginx debug log by adding the <code>--with-debug</code> option to Nginx or OpenResty's <code>./configure</code> script. Then, enable the "debug" error log level in <code>error_log</code> directive. The following message will be generated if PCRE JIT is enabled:

<geshi lang="text">
    pcre JIT compiling result: 1
</geshi>

Starting from the <code>0.9.4</code> release, this function also accepts a 5th argument, <code>res_table</code>, for letting the caller supply the Lua table used to hold all the capturing results. Starting from <code>0.9.6</code>, it is the caller's responsibility to ensure this table is empty. This is very useful for recycling Lua tables and saving GC and table allocation overhead.

This feature was introduced in the <code>v0.2.1rc11</code> release.

== ngx.re.find ==

'''syntax:''' ''from, to, err = ngx.re.find(subject, regex, options?, ctx?, nth?)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Similar to [[#ngx.re.match|ngx.re.match]] but only returns the beginning index (<code>from</code>) and end index (<code>to</code>) of the matched substring. The returned indexes are 1-based and can be fed directly into the [https://www.lua.org/manual/5.1/manual.html#pdf-string.sub string.sub] API function to obtain the matched substring.

In case of errors (like bad regexes or any PCRE runtime errors), this API function returns two <code>nil</code> values followed by a string describing the error.

If no match is found, this function just returns a <code>nil</code> value.

Below is an example:

<geshi lang="lua">
    local s = "hello, 1234"
    local from, to, err = ngx.re.find(s, "([0-9]+)", "jo")
    if from then
        ngx.say("from: ", from)
        ngx.say("to: ", to)
        ngx.say("matched: ", string.sub(s, from, to))
    else
        if err then
            ngx.say("error: ", err)
            return
        end
        ngx.say("not matched!")
    end
</geshi>

This example produces the output

    from: 8
    to: 11
    matched: 1234

Because this API function does not create new Lua strings nor new Lua tables, it is much faster than [[#ngx.re.match|ngx.re.match]]. It should be used wherever possible.

Since the <code>0.9.3</code> release, an optional 5th argument, <code>nth</code>, is supported to specify which (submatch) capture's indexes to return. When <code>nth</code> is 0 (which is the default), the indexes for the whole matched substring is returned; when <code>nth</code> is 1, then the 1st submatch capture's indexes are returned; when <code>nth</code> is 2, then the 2nd submatch capture is returned, and so on. When the specified submatch does not have a match, then two <code>nil</code> values will be returned. Below is an example for this:

<geshi lang="lua">
    local str = "hello, 1234"
    local from, to = ngx.re.find(str, "([0-9])([0-9]+)", "jo", nil, 2)
    if from then
        ngx.say("matched 2nd submatch: ", string.sub(str, from, to))  -- yields "234"
    end
</geshi>

This API function was first introduced in the <code>v0.9.2</code> release.

== ngx.re.gmatch ==

'''syntax:''' ''iterator, err = ngx.re.gmatch(subject, regex, options?)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Similar to [[#ngx.re.match|ngx.re.match]], but returns a Lua iterator instead, so as to let the user programmer iterate all the matches over the <code><subject></code> string argument with the PCRE <code>regex</code>.

In case of errors, like seeing an ill-formed regular expression, <code>nil</code> and a string describing the error will be returned.

Here is a small example to demonstrate its basic usage:

<geshi lang="lua">
    local iterator, err = ngx.re.gmatch("hello, world!", "([a-z]+)", "i")
    if not iterator then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end

    local m
    m, err = iterator()    -- m[0] == m[1] == "hello"
    if err then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end

    m, err = iterator()    -- m[0] == m[1] == "world"
    if err then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end

    m, err = iterator()    -- m == nil
    if err then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end
</geshi>

More often we just put it into a Lua loop:

<geshi lang="lua">
    local it, err = ngx.re.gmatch("hello, world!", "([a-z]+)", "i")
    if not it then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end

    while true do
        local m, err = it()
        if err then
            ngx.log(ngx.ERR, "error: ", err)
            return
        end

        if not m then
            -- no match found (any more)
            break
        end

        -- found a match
        ngx.say(m[0])
        ngx.say(m[1])
    end
</geshi>

The optional <code>options</code> argument takes exactly the same semantics as the [[#ngx.re.match|ngx.re.match]] method.

The current implementation requires that the iterator returned should only be used in a single request. That is, one should ''not'' assign it to a variable belonging to persistent namespace like a Lua package.

This method requires the PCRE library enabled in Nginx ([[#Special Escaping Sequences|Known Issue With Special Escaping Sequences]]).

This feature was first introduced in the <code>v0.2.1rc12</code> release.

== ngx.re.sub ==

'''syntax:''' ''newstr, n, err = ngx.re.sub(subject, regex, replace, options?)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Substitutes the first match of the Perl compatible regular expression <code>regex</code> on the <code>subject</code> argument string with the string or function argument <code>replace</code>. The optional <code>options</code> argument has exactly the same meaning as in [[#ngx.re.match|ngx.re.match]].

This method returns the resulting new string as well as the number of successful substitutions. In case of failures, like syntax errors in the regular expressions or the <code><replace></code> string argument, it will return <code>nil</code> and a string describing the error.

When the <code>replace</code> is a string, then it is treated as a special template for string replacement. For example,

<geshi lang="lua">
    local newstr, n, err = ngx.re.sub("hello, 1234", "([0-9])[0-9]", "[$0][$1]")
    if not newstr then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end

    -- newstr == "hello, [12][1]34"
    -- n == 1
</geshi>

where <code>$0</code> referring to the whole substring matched by the pattern and <code>$1</code> referring to the first parenthesized capturing substring.

Curly braces can also be used to disambiguate variable names from the background string literals:

<geshi lang="lua">
    local newstr, n, err = ngx.re.sub("hello, 1234", "[0-9]", "${0}00")
    -- newstr == "hello, 100234"
    -- n == 1
</geshi>

Literal dollar sign characters (<code>$</code>) in the <code>replace</code> string argument can be escaped by another dollar sign, for instance,

<geshi lang="lua">
    local newstr, n, err = ngx.re.sub("hello, 1234", "[0-9]", "$$")
    -- newstr == "hello, $234"
    -- n == 1
</geshi>

Do not use backlashes to escape dollar signs; it will not work as expected.

When the <code>replace</code> argument is of type "function", then it will be invoked with the "match table" as the argument to generate the replace string literal for substitution. The "match table" fed into the <code>replace</code> function is exactly the same as the return value of [[#ngx.re.match|ngx.re.match]]. Here is an example:

<geshi lang="lua">
    local func = function (m)
        return "[" .. m[0] .. "][" .. m[1] .. "]"
    end

    local newstr, n, err = ngx.re.sub("hello, 1234", "( [0-9] ) [0-9]", func, "x")
    -- newstr == "hello, [12][1]34"
    -- n == 1
</geshi>

The dollar sign characters in the return value of the <code>replace</code> function argument are not special at all.

This method requires the PCRE library enabled in Nginx ([[#Special Escaping Sequences|Known Issue With Special Escaping Sequences]]).

This feature was first introduced in the <code>v0.2.1rc13</code> release.

== ngx.re.gsub ==

'''syntax:''' ''newstr, n, err = ngx.re.gsub(subject, regex, replace, options?)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Just like [[#ngx.re.sub|ngx.re.sub]], but does global substitution.

Here is some examples:

<geshi lang="lua">
    local newstr, n, err = ngx.re.gsub("hello, world", "([a-z])[a-z]+", "[$0,$1]", "i")
    if not newstr then
        ngx.log(ngx.ERR, "error: ", err)
        return
    end

    -- newstr == "[hello,h], [world,w]"
    -- n == 2
</geshi>

<geshi lang="lua">
    local func = function (m)
        return "[" .. m[0] .. "," .. m[1] .. "]"
    end
    local newstr, n, err = ngx.re.gsub("hello, world", "([a-z])[a-z]+", func, "i")
    -- newstr == "[hello,h], [world,w]"
    -- n == 2
</geshi>

This method requires the PCRE library enabled in Nginx ([[#Special Escaping Sequences|Known Issue With Special Escaping Sequences]]).

This feature was first introduced in the <code>v0.2.1rc15</code> release.

== ngx.shared.DICT ==

'''syntax:''' ''dict = ngx.shared.DICT''

'''syntax:''' ''dict = ngx.shared[name_var]''

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Fetching the shm-based Lua dictionary object for the shared memory zone named <code>DICT</code> defined by the [[#lua_shared_dict|lua_shared_dict]] directive.

Shared memory zones are always shared by all the Nginx worker processes in the current Nginx server instance.

The resulting object <code>dict</code> has the following methods:

* [[#ngx.shared.DICT.get|get]]
* [[#ngx.shared.DICT.get_stale|get_stale]]
* [[#ngx.shared.DICT.set|set]]
* [[#ngx.shared.DICT.safe_set|safe_set]]
* [[#ngx.shared.DICT.add|add]]
* [[#ngx.shared.DICT.safe_add|safe_add]]
* [[#ngx.shared.DICT.replace|replace]]
* [[#ngx.shared.DICT.delete|delete]]
* [[#ngx.shared.DICT.incr|incr]]
* [[#ngx.shared.DICT.lpush|lpush]]
* [[#ngx.shared.DICT.rpush|rpush]]
* [[#ngx.shared.DICT.lpop|lpop]]
* [[#ngx.shared.DICT.rpop|rpop]]
* [[#ngx.shared.DICT.llen|llen]]
* [[#ngx.shared.DICT.ttl|ttl]]
* [[#ngx.shared.DICT.expire|expire]]
* [[#ngx.shared.DICT.flush_all|flush_all]]
* [[#ngx.shared.DICT.flush_expired|flush_expired]]
* [[#ngx.shared.DICT.get_keys|get_keys]]
* [[#ngx.shared.DICT.capacity|capacity]]
* [[#ngx.shared.DICT.free_space|free_space]]

All these methods are ''atomic'' operations, that is, safe from concurrent accesses from multiple Nginx worker processes for the same <code>lua_shared_dict</code> zone.

Here is an example:

<geshi lang="nginx">
    http {
        lua_shared_dict dogs 10m;
        server {
            location /set {
                content_by_lua_block {
                    local dogs = ngx.shared.dogs
                    dogs:set("Jim", 8)
                    ngx.say("STORED")
                }
            }
            location /get {
                content_by_lua_block {
                    local dogs = ngx.shared.dogs
                    ngx.say(dogs:get("Jim"))
                }
            }
        }
    }
</geshi>

Let us test it:

<geshi lang="bash">
    $ curl localhost/set
    STORED

    $ curl localhost/get
    8

    $ curl localhost/get
    8
</geshi>

The number <code>8</code> will be consistently output when accessing <code>/get</code> regardless of how many Nginx workers there are because the <code>dogs</code> dictionary resides in the shared memory and visible to ''all'' of the worker processes.

The shared dictionary will retain its contents through a server config reload (either by sending the <code>HUP</code> signal to the Nginx process or by using the <code>-s reload</code> command-line option).

The contents in the dictionary storage will be lost, however, when the Nginx server quits.

This feature was first introduced in the <code>v0.3.1rc22</code> release.

== ngx.shared.DICT.get ==

'''syntax:''' ''value, flags = ngx.shared.DICT:get(key)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Retrieving the value in the dictionary [[#ngx.shared.DICT|ngx.shared.DICT]] for the key <code>key</code>. If the key does not exist or has expired, then <code>nil</code> will be returned.

In case of errors, <code>nil</code> and a string describing the error will be returned.

The value returned will have the original data type when they were inserted into the dictionary, for example, Lua booleans, numbers, or strings.

The first argument to this method must be the dictionary object itself, for example,

<geshi lang="lua">
    local cats = ngx.shared.cats
    local value, flags = cats.get(cats, "Marry")
</geshi>

or use Lua's syntactic sugar for method calls:

<geshi lang="lua">
    local cats = ngx.shared.cats
    local value, flags = cats:get("Marry")
</geshi>

These two forms are fundamentally equivalent.

If the user flags is <code>0</code> (the default), then no flags value will be returned.

This feature was first introduced in the <code>v0.3.1rc22</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.get_stale ==

'''syntax:''' ''value, flags, stale = ngx.shared.DICT:get_stale(key)''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Similar to the [[#ngx.shared.DICT.get|get]] method but returns the value even if the key has already expired.

Returns a 3rd value, <code>stale</code>, indicating whether the key has expired or not.

Note that the value of an expired key is not guaranteed to be available so one should never rely on the availability of expired items.

This method was first introduced in the <code>0.8.6</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.set ==

'''syntax:''' ''success, err, forcible = ngx.shared.DICT:set(key, value, exptime?, flags?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Unconditionally sets a key-value pair into the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]]. Returns three values:

* <code>success</code>: boolean value to indicate whether the key-value pair is stored or not.
* <code>err</code>: textual error message, can be <code>"no memory"</code>.
* <code>forcible</code>: a boolean value to indicate whether other valid items have been removed forcibly when out of storage in the shared memory zone.

The <code>value</code> argument inserted can be Lua booleans, numbers, strings, or <code>nil</code>. Their value type will also be stored into the dictionary and the same data type can be retrieved later via the [[#ngx.shared.DICT.get|get]] method.

The optional <code>exptime</code> argument specifies expiration time (in seconds) for the inserted key-value pair. The time resolution is <code>0.001</code> seconds. If the <code>exptime</code> takes the value <code>0</code> (which is the default), then the item will never expire.

The optional <code>flags</code> argument specifies a user flags value associated with the entry to be stored. It can also be retrieved later with the value. The user flags is stored as an unsigned 32-bit integer internally. Defaults to <code>0</code>. The user flags argument was first introduced in the <code>v0.5.0rc2</code> release.

When it fails to allocate memory for the current key-value item, then <code>set</code> will try removing existing items in the storage according to the Least-Recently Used (LRU) algorithm. Note that, LRU takes priority over expiration time here. If up to tens of existing items have been removed and the storage left is still insufficient (either due to the total capacity limit specified by [[#lua_shared_dict|lua_shared_dict]] or memory segmentation), then the <code>err</code> return value will be <code>no memory</code> and <code>success</code> will be <code>false</code>.

If the sizes of items in the dictionary are not multiples or even powers of a certain value (like 2), it is easier to encounter <code>no memory</code> error because of memory fragmentation. It is recommended to use different dictionaries for different sizes of items.

When you encounter <code>no memory</code> error, you can also evict more least-recently-used items by retrying this method call more times to to make room for the current item.

If this method succeeds in storing the current item by forcibly removing other not-yet-expired items in the dictionary via LRU, the <code>forcible</code> return value will be <code>true</code>. If it stores the item without forcibly removing other valid items, then the return value <code>forcible</code> will be <code>false</code>.

The first argument to this method must be the dictionary object itself, for example,

<geshi lang="lua">
    local cats = ngx.shared.cats
    local succ, err, forcible = cats.set(cats, "Marry", "it is a nice cat!")
</geshi>

or use Lua's syntactic sugar for method calls:

<geshi lang="lua">
    local cats = ngx.shared.cats
    local succ, err, forcible = cats:set("Marry", "it is a nice cat!")
</geshi>

These two forms are fundamentally equivalent.

This feature was first introduced in the <code>v0.3.1rc22</code> release.

Please note that while internally the key-value pair is set atomically, the atomicity does not go across the method call boundary.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.safe_set ==

'''syntax:''' ''ok, err = ngx.shared.DICT:safe_set(key, value, exptime?, flags?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Similar to the [[#ngx.shared.DICT.set|set]] method, but never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return <code>nil</code> and the string "no memory".

This feature was first introduced in the <code>v0.7.18</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.add ==

'''syntax:''' ''success, err, forcible = ngx.shared.DICT:add(key, value, exptime?, flags?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Just like the [[#ngx.shared.DICT.set|set]] method, but only stores the key-value pair into the dictionary [[#ngx.shared.DICT|ngx.shared.DICT]] if the key does ''not'' exist.

If the <code>key</code> argument already exists in the dictionary (and not expired for sure), the <code>success</code> return value will be <code>false</code> and the <code>err</code> return value will be <code>"exists"</code>.

This feature was first introduced in the <code>v0.3.1rc22</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.safe_add ==

'''syntax:''' ''ok, err = ngx.shared.DICT:safe_add(key, value, exptime?, flags?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Similar to the [[#ngx.shared.DICT.add|add]] method, but never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return <code>nil</code> and the string "no memory".

This feature was first introduced in the <code>v0.7.18</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.replace ==

'''syntax:''' ''success, err, forcible = ngx.shared.DICT:replace(key, value, exptime?, flags?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Just like the [[#ngx.shared.DICT.set|set]] method, but only stores the key-value pair into the dictionary [[#ngx.shared.DICT|ngx.shared.DICT]] if the key ''does'' exist.

If the <code>key</code> argument does ''not'' exist in the dictionary (or expired already), the <code>success</code> return value will be <code>false</code> and the <code>err</code> return value will be <code>"not found"</code>.

This feature was first introduced in the <code>v0.3.1rc22</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.delete ==

'''syntax:''' ''ngx.shared.DICT:delete(key)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Unconditionally removes the key-value pair from the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]].

It is equivalent to <code>ngx.shared.DICT:set(key, nil)</code>.

This feature was first introduced in the <code>v0.3.1rc22</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.incr ==

'''syntax:''' ''newval, err, forcible? = ngx.shared.DICT:incr(key, value, init?, init_ttl?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

'''optional requirement:''' <code>resty.core.shdict</code> or <code>resty.core</code>

Increments the (numerical) value for <code>key</code> in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]] by the step value <code>value</code>. Returns the new resulting number if the operation is successfully completed or <code>nil</code> and an error message otherwise.

When the key does not exist or has already expired in the shared dictionary,

# if the <code>init</code> argument is not specified or takes the value <code>nil</code>, this method will return <code>nil</code> and the error string <code>"not found"</code>, or
# if the <code>init</code> argument takes a number value, this method will create a new <code>key</code> with the value <code>init + value</code>.

Like the [[#ngx.shared.DICT.add|add]] method, it also overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone.

The optional <code>init_ttl</code> argument specifies expiration time (in seconds) of the value when it is initialized via the <code>init</code> argument. The time resolution is <code>0.001</code> seconds. If <code>init_ttl</code> takes the value <code>0</code> (which is the default), then the item will never expire. This argument cannot be provided without providing the <code>init</code> argument as well, and has no effect if the value already exists (e.g., if it was previously inserted via [[#ngx.shared.DICT.set|set]] or the likes).

'''Note:''' Usage of the <code>init_ttl</code> argument requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the [https://github.com/openresty/lua-resty-core lua-resty-core] library. Example:

<geshi lang="lua">
    require "resty.core"

    local cats = ngx.shared.cats
    local newval, err = cats:incr("black_cats", 1, 0, 0.1)

    print(newval) -- 1

    ngx.sleep(0.2)

    local val, err = cats:get("black_cats")
    print(val) -- nil
</geshi>

The <code>forcible</code> return value will always be <code>nil</code> when the <code>init</code> argument is not specified.

If this method succeeds in storing the current item by forcibly removing other not-yet-expired items in the dictionary via LRU, the <code>forcible</code> return value will be <code>true</code>. If it stores the item without forcibly removing other valid items, then the return value <code>forcible</code> will be <code>false</code>.

If the original value is not a valid Lua number in the dictionary, it will return <code>nil</code> and <code>"not a number"</code>.

The <code>value</code> argument and <code>init</code> argument can be any valid Lua numbers, like negative numbers or floating-point numbers.

This method was first introduced in the <code>v0.3.1rc22</code> release.

The optional <code>init</code> parameter was first added in the <code>v0.10.6</code> release.

The optional <code>init_ttl</code> parameter was introduced in the <code>v0.10.12rc2</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.lpush ==

'''syntax:''' ''length, err = ngx.shared.DICT:lpush(key, value)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Inserts the specified (numerical or string) <code>value</code> at the head of the list named <code>key</code> in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]]. Returns the number of elements in the list after the push operation.

If <code>key</code> does not exist, it is created as an empty list before performing the push operation. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>"value not a list"</code>.

It never overrides the (least recently used) unexpired items in the store when running out of storage in the shared memory zone. In this case, it will immediately return <code>nil</code> and the string "no memory".

This feature was first introduced in the <code>v0.10.6</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.rpush ==

'''syntax:''' ''length, err = ngx.shared.DICT:rpush(key, value)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Similar to the [[#ngx.shared.DICT.lpush|lpush]] method, but inserts the specified (numerical or string) <code>value</code> at the tail of the list named <code>key</code>.

This feature was first introduced in the <code>v0.10.6</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.lpop ==

'''syntax:''' ''val, err = ngx.shared.DICT:lpop(key)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Removes and returns the first element of the list named <code>key</code> in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]].

If <code>key</code> does not exist, it will return <code>nil</code>. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>"value not a list"</code>.

This feature was first introduced in the <code>v0.10.6</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.rpop ==

'''syntax:''' ''val, err = ngx.shared.DICT:rpop(key)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Removes and returns the last element of the list named <code>key</code> in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]].

If <code>key</code> does not exist, it will return <code>nil</code>. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>"value not a list"</code>.

This feature was first introduced in the <code>v0.10.6</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.llen ==

'''syntax:''' ''len, err = ngx.shared.DICT:llen(key)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Returns the number of elements in the list named <code>key</code> in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]].

If key does not exist, it is interpreted as an empty list and 0 is returned. When the <code>key</code> already takes a value that is not a list, it will return <code>nil</code> and <code>"value not a list"</code>.

This feature was first introduced in the <code>v0.10.6</code> release.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.ttl ==

'''syntax:''' ''ttl, err = ngx.shared.DICT:ttl(key)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

'''requires:''' <code>resty.core.shdict</code> or <code>resty.core</code>

Retrieves the remaining TTL (time-to-live in seconds) of a key-value pair in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]]. Returns the TTL as a number if the operation is successfully completed or <code>nil</code> and an error message otherwise.

If the key does not exist (or has already expired), this method will return <code>nil</code> and the error string <code>"not found"</code>.

The TTL is originally determined by the <code>exptime</code> argument of the [[#ngx.shared.DICT.set|set]], [[#ngx.shared.DICT.add|add]], [[#ngx.shared.DICT.replace|replace]] (and the likes) methods. It has a time resolution of <code>0.001</code> seconds. A value of <code>0</code> means that the item will never expire.

Example:

<geshi lang="lua">
    require "resty.core"

    local cats = ngx.shared.cats
    local succ, err = cats:set("Marry", "a nice cat", 0.5)

    ngx.sleep(0.2)

    local ttl, err = cats:ttl("Marry")
    ngx.say(ttl) -- 0.3
</geshi>

This feature was first introduced in the <code>v0.10.11</code> release.

'''Note:''' This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the [https://github.com/openresty/lua-resty-core lua-resty-core] library.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.expire ==

'''syntax:''' ''success, err = ngx.shared.DICT:expire(key, exptime)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

'''requires:''' <code>resty.core.shdict</code> or <code>resty.core</code>

Updates the <code>exptime</code> (in second) of a key-value pair in the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]]. Returns a boolean indicating success if the operation completes or <code>nil</code> and an error message otherwise.

If the key does not exist, this method will return <code>nil</code> and the error string <code>"not found"</code>.

The <code>exptime</code> argument has a resolution of <code>0.001</code> seconds. If <code>exptime</code> is <code>0</code>, then the item will never expire.

Example:

<geshi lang="lua">
    require "resty.core"

    local cats = ngx.shared.cats
    local succ, err = cats:set("Marry", "a nice cat", 0.1)

    succ, err = cats:expire("Marry", 0.5)

    ngx.sleep(0.2)

    local val, err = cats:get("Marry")
    ngx.say(val) -- "a nice cat"
</geshi>

This feature was first introduced in the <code>v0.10.11</code> release.

'''Note:''' This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the [https://github.com/openresty/lua-resty-core lua-resty-core] library.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.flush_all ==

'''syntax:''' ''ngx.shared.DICT:flush_all()''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Flushes out all the items in the dictionary. This method does not actually free up all the memory blocks in the dictionary but just marks all the existing items as expired.

This feature was first introduced in the <code>v0.5.0rc17</code> release.

See also [[#ngx.shared.DICT.flush_expired|ngx.shared.DICT.flush_expired]] and [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.flush_expired ==

'''syntax:''' ''flushed = ngx.shared.DICT:flush_expired(max_count?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Flushes out the expired items in the dictionary, up to the maximal number specified by the optional <code>max_count</code> argument. When the <code>max_count</code> argument is given <code>0</code> or not given at all, then it means unlimited. Returns the number of items that have actually been flushed.

Unlike the [[#ngx.shared.DICT.flush_all|flush_all]] method, this method actually frees up the memory used by the expired items.

This feature was first introduced in the <code>v0.6.3</code> release.

See also [[#ngx.shared.DICT.flush_all|ngx.shared.DICT.flush_all]] and [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.get_keys ==

'''syntax:''' ''keys = ngx.shared.DICT:get_keys(max_count?)''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Fetch a list of the keys from the dictionary, up to <code><max_count></code>.

By default, only the first 1024 keys (if any) are returned. When the <code><max_count></code> argument is given the value <code>0</code>, then all the keys will be returned even there is more than 1024 keys in the dictionary.

'''CAUTION''' Avoid calling this method on dictionaries with a very large number of keys as it may lock the dictionary for significant amount of time and block Nginx worker processes trying to access the dictionary.

This feature was first introduced in the <code>v0.7.3</code> release.

== ngx.shared.DICT.capacity ==

'''syntax:''' ''capacity_bytes = ngx.shared.DICT:capacity()''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

'''requires:''' <code>resty.core.shdict</code> or <code>resty.core</code>

Retrieves the capacity in bytes for the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]] declared with
the [[#lua_shared_dict|lua_shared_dict]] directive.

Example:

<geshi lang="lua">
    require "resty.core.shdict"

    local cats = ngx.shared.cats
    local capacity_bytes = cats:capacity()
</geshi>

This feature was first introduced in the <code>v0.10.11</code> release.

'''Note:''' This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the [https://github.com/openresty/lua-resty-core lua-resty-core] library.

This feature requires at least Nginx core version <code>0.7.3</code>.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.shared.DICT.free_space ==

'''syntax:''' ''free_page_bytes = ngx.shared.DICT:free_space()''

'''context:''' ''init_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

'''requires:''' <code>resty.core.shdict</code> or <code>resty.core</code>

Retrieves the free page size in bytes for the shm-based dictionary [[#ngx.shared.DICT|ngx.shared.DICT]].

'''Note:''' The memory for ngx.shared.DICT is allocated via the Nginx slab allocator which has each slot for
data size ranges like \~8, 9\~16, 17\~32, ..., 1025\~2048, 2048\~ bytes. And pages are assigned to a slot if there
is no room in already assigned pages for the slot.

So even if the return value of the <code>free_space</code> method is zero, there may be room in already assigned pages, so
you may successfully set a new key value pair to the shared dict without getting <code>true</code> for <code>forcible</code> or
non nil <code>err</code> from the <code>ngx.shared.DICT.set</code>.

On the other hand, if already assigned pages for a slot are full and a new key value pair is added to the
slot and there is no free page, you may get <code>true</code> for <code>forcible</code> or non nil <code>err</code> from the
<code>ngx.shared.DICT.set</code> method.

Example:

<geshi lang="lua">
    require "resty.core.shdict"

    local cats = ngx.shared.cats
    local free_page_bytes = cats:free_space()
</geshi>

This feature was first introduced in the <code>v0.10.11</code> release.

'''Note:''' This method requires the <code>resty.core.shdict</code> or <code>resty.core</code> modules from the [https://github.com/openresty/lua-resty-core lua-resty-core] library.

This feature requires at least Nginx core version <code>1.11.7</code>.

See also [[#ngx.shared.DICT|ngx.shared.DICT]].

== ngx.socket.udp ==

'''syntax:''' ''udpsock = ngx.socket.udp()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Creates and returns a UDP or datagram-oriented unix domain socket object (also known as one type of the "cosocket" objects). The following methods are supported on this object:

* [[#udpsock:setpeername|setpeername]]
* [[#udpsock:send|send]]
* [[#udpsock:receive|receive]]
* [[#udpsock:close|close]]
* [[#udpsock:settimeout|settimeout]]

It is intended to be compatible with the UDP API of the [http://w3.impa.br/~diego/software/luasocket/udp.html LuaSocket] library but is 100% nonblocking out of the box.

This feature was first introduced in the <code>v0.5.7</code> release.

See also [[#ngx.socket.tcp|ngx.socket.tcp]].

== udpsock:setpeername ==

'''syntax:''' ''ok, err = udpsock:setpeername(host, port)''

'''syntax:''' ''ok, err = udpsock:setpeername("unix:/path/to/unix-domain.socket")''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Attempts to connect a UDP socket object to a remote server or to a datagram unix domain socket file. Because the datagram protocol is actually connection-less, this method does not really establish a "connection", but only just set the name of the remote peer for subsequent read/write operations.

Both IP addresses and domain names can be specified as the <code>host</code> argument. In case of domain names, this method will use Nginx core's dynamic resolver to parse the domain name without blocking and it is required to configure the [[HttpCoreModule#resolver|resolver]] directive in the <code>nginx.conf</code> file like this:

<geshi lang="nginx">
    resolver 8.8.8.8;  # use Google's public DNS nameserver
</geshi>

If the nameserver returns multiple IP addresses for the host name, this method will pick up one randomly.

In case of error, the method returns <code>nil</code> followed by a string describing the error. In case of success, the method returns <code>1</code>.

Here is an example for connecting to a UDP (memcached) server:

<geshi lang="nginx">
    location /test {
        resolver 8.8.8.8;

        content_by_lua_block {
            local sock = ngx.socket.udp()
            local ok, err = sock:setpeername("my.memcached.server.domain", 11211)
            if not ok then
                ngx.say("failed to connect to memcached: ", err)
                return
            end
            ngx.say("successfully connected to memcached!")
            sock:close()
        }
    }
</geshi>

Since the <code>v0.7.18</code> release, connecting to a datagram unix domain socket file is also possible on Linux:

<geshi lang="lua">
    local sock = ngx.socket.udp()
    local ok, err = sock:setpeername("unix:/tmp/some-datagram-service.sock")
    if not ok then
        ngx.say("failed to connect to the datagram unix domain socket: ", err)
        return
    end

    -- do something after connect
    -- such as sock:send or sock:receive
</geshi>

assuming the datagram service is listening on the unix domain socket file <code>/tmp/some-datagram-service.sock</code> and the client socket will use the "autobind" feature on Linux.

Calling this method on an already connected socket object will cause the original connection to be closed first.

This method was first introduced in the <code>v0.5.7</code> release.

== udpsock:send ==

'''syntax:''' ''ok, err = udpsock:send(data)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Sends data on the current UDP or datagram unix domain socket object.

In case of success, it returns <code>1</code>. Otherwise, it returns <code>nil</code> and a string describing the error.

The input argument <code>data</code> can either be a Lua string or a (nested) Lua table holding string fragments. In case of table arguments, this method will copy all the string elements piece by piece to the underlying Nginx socket send buffers, which is usually optimal than doing string concatenation operations on the Lua land.

This feature was first introduced in the <code>v0.5.7</code> release.

== udpsock:receive ==

'''syntax:''' ''data, err = udpsock:receive(size?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Receives data from the UDP or datagram unix domain socket object with an optional receive buffer size argument, <code>size</code>.

This method is a synchronous operation and is 100% nonblocking.

In case of success, it returns the data received; in case of error, it returns <code>nil</code> with a string describing the error.

If the <code>size</code> argument is specified, then this method will use this size as the receive buffer size. But when this size is greater than <code>8192</code>, then <code>8192</code> will be used instead.

If no argument is specified, then the maximal buffer size, <code>8192</code> is assumed.

Timeout for the reading operation is controlled by the [[#lua_socket_read_timeout|lua_socket_read_timeout]] config directive and the [[#udpsock:settimeout|settimeout]] method. And the latter takes priority. For example:

<geshi lang="lua">
    sock:settimeout(1000)  -- one second timeout
    local data, err = sock:receive()
    if not data then
        ngx.say("failed to read a packet: ", err)
        return
    end
    ngx.say("successfully read a packet: ", data)
</geshi>

It is important here to call the [[#udpsock:settimeout|settimeout]] method ''before'' calling this method.

This feature was first introduced in the <code>v0.5.7</code> release.

== udpsock:close ==

'''syntax:''' ''ok, err = udpsock:close()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Closes the current UDP or datagram unix domain socket. It returns the <code>1</code> in case of success and returns <code>nil</code> with a string describing the error otherwise.

Socket objects that have not invoked this method (and associated connections) will be closed when the socket object is released by the Lua GC (Garbage Collector) or the current client HTTP request finishes processing.

This feature was first introduced in the <code>v0.5.7</code> release.

== udpsock:settimeout ==

'''syntax:''' ''udpsock:settimeout(time)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Set the timeout value in milliseconds for subsequent socket operations (like [[#udpsock:receive|receive]]).

Settings done by this method takes priority over those config directives, like [[#lua_socket_read_timeout|lua_socket_read_timeout]].

This feature was first introduced in the <code>v0.5.7</code> release.

== ngx.socket.stream ==

Just an alias to [[#ngx.socket.tcp|ngx.socket.tcp]]. If the stream-typed cosocket may also connect to a unix domain
socket, then this API name is preferred.

This API function was first added to the <code>v0.10.1</code> release.

== ngx.socket.tcp ==

'''syntax:''' ''tcpsock = ngx.socket.tcp()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Creates and returns a TCP or stream-oriented unix domain socket object (also known as one type of the "cosocket" objects). The following methods are supported on this object:

* [[#tcpsock:bind|bind]]
* [[#tcpsock:connect|connect]]
* [[#tcpsock:setclientcert|setclientcert]]
* [[#tcpsock:sslhandshake|sslhandshake]]
* [[#tcpsock:send|send]]
* [[#tcpsock:receive|receive]]
* [[#tcpsock:close|close]]
* [[#tcpsock:settimeout|settimeout]]
* [[#tcpsock:settimeouts|settimeouts]]
* [[#tcpsock:setoption|setoption]]
* [[#tcpsock:receiveany|receiveany]]
* [[#tcpsock:receiveuntil|receiveuntil]]
* [[#tcpsock:setkeepalive|setkeepalive]]
* [[#tcpsock:getreusedtimes|getreusedtimes]]

It is intended to be compatible with the TCP API of the [http://w3.impa.br/~diego/software/luasocket/tcp.html LuaSocket] library but is 100% nonblocking out of the box. Also, we introduce some new APIs to provide more functionalities.

The cosocket object created by this API function has exactly the same lifetime as the Lua handler creating it. So never pass the cosocket object to any other Lua handler (including ngx.timer callback functions) and never share the cosocket object between different Nginx requests.

For every cosocket object's underlying connection, if you do not
explicitly close it (via [[#tcpsock:close|close]]) or put it back to the connection
pool (via [[#tcpsock:setkeepalive|setkeepalive]]), then it is automatically closed when one of
the following two events happens:

* the current request handler completes, or
* the Lua cosocket object value gets collected by the Lua GC.

Fatal errors in cosocket operations always automatically close the current
connection (note that, read timeout error is the only error that is
not fatal), and if you call [[#tcpsock:close|close]] on a closed connection, you will get
the "closed" error.

Starting from the <code>0.9.9</code> release, the cosocket object here is full-duplex, that is, a reader "light thread" and a writer "light thread" can operate on a single cosocket object simultaneously (both "light threads" must belong to the same Lua handler though, see reasons above). But you cannot have two "light threads" both reading (or writing or connecting) the same cosocket, otherwise you might get an error like "socket busy reading" when calling the methods of the cosocket object.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

See also [[#ngx.socket.udp|ngx.socket.udp]].

== tcpsock:bind ==
'''syntax:''' ''ok, err = tcpsock:bind(address)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*''

Just like the standard [[HttpProxyModule#proxy_bind|proxy_bind]] directive, this api makes the outgoing connection to a upstream server originate from the specified local IP address.

Only IP addresses can be specified as the <code>address</code> argument.

Here is an example for connecting to a TCP server from the specified local IP address:

<geshi lang="nginx">
    location /test {
        content_by_lua_block {
            local sock = ngx.socket.tcp()
            -- assume "192.168.1.10" is the local ip address
            local ok, err = sock:bind("192.168.1.10")
            if not ok then
                ngx.say("failed to bind")
                return
            end
            local ok, err = sock:connect("192.168.1.67", 80)
            if not ok then
                ngx.say("failed to connect server: ", err)
                return
            end
            ngx.say("successfully connected!")
            sock:close()
        }
    }
</geshi>

== tcpsock:connect ==

'''syntax:''' ''ok, err = tcpsock:connect(host, port, options_table?)''

'''syntax:''' ''ok, err = tcpsock:connect("unix:/path/to/unix-domain.socket", options_table?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Attempts to connect a TCP socket object to a remote server or to a stream unix domain socket file without blocking.

Before actually resolving the host name and connecting to the remote backend, this method will always look up the connection pool for matched idle connections created by previous calls of this method (or the [[#ngx.socket.connect|ngx.socket.connect]] function).

Both IP addresses and domain names can be specified as the <code>host</code> argument. In case of domain names, this method will use Nginx core's dynamic resolver to parse the domain name without blocking and it is required to configure the [[HttpCoreModule#resolver|resolver]] directive in the <code>nginx.conf</code> file like this:

<geshi lang="nginx">
    resolver 8.8.8.8;  # use Google's public DNS nameserver
</geshi>

If the nameserver returns multiple IP addresses for the host name, this method will pick up one randomly.

In case of error, the method returns <code>nil</code> followed by a string describing the error. In case of success, the method returns <code>1</code>.

Here is an example for connecting to a TCP server:

<geshi lang="nginx">
    location /test {
        resolver 8.8.8.8;

        content_by_lua_block {
            local sock = ngx.socket.tcp()
            local ok, err = sock:connect("www.google.com", 80)
            if not ok then
                ngx.say("failed to connect to google: ", err)
                return
            end
            ngx.say("successfully connected to google!")
            sock:close()
        }
    }
</geshi>

Connecting to a Unix Domain Socket file is also possible:

<geshi lang="lua">
    local sock = ngx.socket.tcp()
    local ok, err = sock:connect("unix:/tmp/memcached.sock")
    if not ok then
        ngx.say("failed to connect to the memcached unix domain socket: ", err)
        return
    end

    -- do something after connect
    -- such as sock:send or sock:receive
</geshi>

assuming memcached (or something else) is listening on the unix domain socket file <code>/tmp/memcached.sock</code>.

Timeout for the connecting operation is controlled by the [[#lua_socket_connect_timeout|lua_socket_connect_timeout]] config directive and the [[#tcpsock:settimeout|settimeout]] method. And the latter takes priority. For example:

<geshi lang="lua">
    local sock = ngx.socket.tcp()
    sock:settimeout(1000)  -- one second timeout
    local ok, err = sock:connect(host, port)
</geshi>

It is important here to call the [[#tcpsock:settimeout|settimeout]] method ''before'' calling this method.

Calling this method on an already connected socket object will cause the original connection to be closed first.

An optional Lua table can be specified as the last argument to this method to specify various connect options:

* <code>pool</code>
: specify a custom name for the connection pool being used. If omitted, then the connection pool name will be generated from the string template <code>"<host>:<port>"</code> or <code>"<unix-socket-path>"</code>.

* <code>pool_size</code>
: specify the size of the connection pool. If omitted and no
: <code>backlog</code> option was provided, no pool will be created. If omitted
: but <code>backlog</code> was provided, the pool will be created with a default
: size equal to the value of the [[#lua_socket_pool_size|lua_socket_pool_size]]
: directive.
: The connection pool holds up to <code>pool_size</code> alive connections
: ready to be reused by subsequent calls to [[#tcpsock:connect|connect]], but
: note that there is no upper limit to the total number of opened connections
: outside of the pool. If you need to restrict the total number of opened
: connections, specify the <code>backlog</code> option.
: When the connection pool would exceed its size limit, the least recently used
: (kept-alive) connection already in the pool will be closed to make room for
: the current connection.
: Note that the cosocket connection pool is per Nginx worker process rather
: than per Nginx server instance, so the size limit specified here also applies
: to every single Nginx worker process. Also note that the size of the connection
: pool cannot be changed once it has been created.
: This option was first introduced in the <code>v0.10.14</code> release.

* <code>backlog</code>
: if specified, this module will limit the total number of opened connections
: for this pool. No more connections than <code>pool_size</code> can be opened
: for this pool at any time. If the connection pool is full, subsequent
: connect operations will be queued into a queue equal to this option's
: value (the "backlog" queue).
: If the number of queued connect operations is equal to <code>backlog</code>,
: subsequent connect operations will fail and return <code>nil</code> plus the
: error string <code>"too many waiting connect operations"</code>.
: The queued connect operations will be resumed once the number of connections
: in the pool is less than <code>pool_size</code>.
: The queued connect operation will abort once they have been queued for more
: than <code>connect_timeout</code>, controlled by
: [[#tcpsock:settimeouts|settimeouts]], and will return <code>nil</code> plus
: the error string <code>"timeout"</code>.
: This option was first introduced in the <code>v0.10.14</code> release.

The support for the options table argument was first introduced in the <code>v0.5.7</code> release.

This method was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:setclientcert ==

'''syntax:''' ''ok, err = tcpsock:setclientcert(cert, pkey)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Set client certificate chain and corresponding private key to the TCP socket object.
The certificate chain and private key provided will be used later by the [tcpsock:sslhandshake](#tcpsocksslhandshake) method.

* <code>cert</code> specify a client certificate chain cdata object that will be used while handshaking with
remote server. These objects can be created using [ngx.ssl.parse\_pem\_cert](https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md#parse_pem_cert)
function provided by lua-resty-core. Note that specifying the <code>cert</code> option requires
corresponding <code>pkey</code> be provided too. See below.
* <code>pkey</code> specify a private key corresponds to the <code>cert</code> option above.
These objects can be created using [ngx.ssl.parse\_pem\_priv\_key](https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md#parse_pem_priv_key)
function provided by lua-resty-core.

If both of <code>cert</code> and <code>pkey</code> are <code>nil</code>, this method will clear any existing client certificate and private key
that was previously set on the cosocket object.

This method was first introduced in the `v0.10.22` release.

== tcpsock:sslhandshake ==

'''syntax:''' ''session, err = tcpsock:sslhandshake(reused_session?, server_name?, ssl_verify?, send_status_req?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Does SSL/TLS handshake on the currently established connection.

The optional <code>reused_session</code> argument can take a former SSL
session userdata returned by a previous <code>sslhandshake</code>
call for exactly the same target. For short-lived connections, reusing SSL
sessions can usually speed up the handshake by one order by magnitude but it
is not so useful if the connection pool is enabled. This argument defaults to
<code>nil</code>. If this argument takes the boolean <code>false</code> value, no SSL session
userdata would return by this call and only a Lua boolean will be returned as
the first return value; otherwise the current SSL session will
always be returned as the first argument in case of successes.

The optional <code>server_name</code> argument is used to specify the server
name for the new TLS extension Server Name Indication (SNI). Use of SNI can
make different servers share the same IP address on the server side. Also,
when SSL verification is enabled, this <code>server_name</code> argument is
also used to validate the server name specified in the server certificate sent from
the remote.

The optional <code>ssl_verify</code> argument takes a Lua boolean value to
control whether to perform SSL verification. When set to <code>true</code>, the server
certificate will be verified according to the CA certificates specified by
the [[#lua_ssl_trusted_certificate|lua_ssl_trusted_certificate]] directive.
You may also need to adjust the [[#lua_ssl_verify_depth|lua_ssl_verify_depth]]
directive to control how deep we should follow along the certificate chain.
Also, when the <code>ssl_verify</code> argument is true and the
<code>server_name</code> argument is also specified, the latter will be used
to validate the server name in the server certificate.

The optional <code>send_status_req</code> argument takes a boolean that controls whether to send
the OCSP status request in the SSL handshake request (which is for requesting OCSP stapling).

For connections that have already done SSL/TLS handshake, this method returns
immediately.

This method was first introduced in the <code>v0.9.11</code> release.

== tcpsock:send ==

'''syntax:''' ''bytes, err = tcpsock:send(data)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Sends data without blocking on the current TCP or Unix Domain Socket connection.

This method is a synchronous operation that will not return until ''all'' the data has been flushed into the system socket send buffer or an error occurs.

In case of success, it returns the total number of bytes that have been sent. Otherwise, it returns <code>nil</code> and a string describing the error.

The input argument <code>data</code> can either be a Lua string or a (nested) Lua table holding string fragments. In case of table arguments, this method will copy all the string elements piece by piece to the underlying Nginx socket send buffers, which is usually optimal than doing string concatenation operations on the Lua land.

Timeout for the sending operation is controlled by the [[#lua_socket_send_timeout|lua_socket_send_timeout]] config directive and the [[#tcpsock:settimeout|settimeout]] method. And the latter takes priority. For example:

<geshi lang="lua">
    sock:settimeout(1000)  -- one second timeout
    local bytes, err = sock:send(request)
</geshi>

It is important here to call the [[#tcpsock:settimeout|settimeout]] method ''before'' calling this method.

In case of any connection errors, this method always automatically closes the current connection.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:receive ==

'''syntax:''' ''data, err, partial = tcpsock:receive(size)''

'''syntax:''' ''data, err, partial = tcpsock:receive(pattern?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Receives data from the connected socket according to the reading pattern or size.

This method is a synchronous operation just like the [[#tcpsock:send|send]] method and is 100% nonblocking.

In case of success, it returns the data received; in case of error, it returns <code>nil</code> with a string describing the error and the partial data received so far.

If a number-like argument is specified (including strings that look like numbers), then it is interpreted as a size. This method will not return until it reads exactly this size of data or an error occurs.

If a non-number-like string argument is specified, then it is interpreted as a "pattern". The following patterns are supported:

* <code>'*a'</code>: reads from the socket until the connection is closed. No end-of-line translation is performed;
* <code>'*l'</code>: reads a line of text from the socket. The line is terminated by a <code>Line Feed</code> (LF) character (ASCII 10), optionally preceded by a <code>Carriage Return</code> (CR) character (ASCII 13). The CR and LF characters are not included in the returned line. In fact, all CR characters are ignored by the pattern.

If no argument is specified, then it is assumed to be the pattern <code>'*l'</code>, that is, the line reading pattern.

Timeout for the reading operation is controlled by the [[#lua_socket_read_timeout|lua_socket_read_timeout]] config directive and the [[#tcpsock:settimeout|settimeout]] method. And the latter takes priority. For example:

<geshi lang="lua">
    sock:settimeout(1000)  -- one second timeout
    local line, err, partial = sock:receive()
    if not line then
        ngx.say("failed to read a line: ", err)
        return
    end
    ngx.say("successfully read a line: ", line)
</geshi>

It is important here to call the [[#tcpsock:settimeout|settimeout]] method ''before'' calling this method.

Since the <code>v0.8.8</code> release, this method no longer automatically closes the current connection when the read timeout error happens. For other connection errors, this method always automatically closes the connection.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:receiveany ==

'''syntax:''' ''data, err = tcpsock:receiveany(max)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Returns any data received by the connected socket, at most <code>max</code> bytes.

This method is a synchronous operation just like the [[#tcpsock:send|send]] method and is 100% nonblocking.

In case of success, it returns the data received; in case of error, it returns <code>nil</code> with a string describing the error.

If the received data is more than this size, this method will return with exactly this size of data.
The remaining data in the underlying receive buffer could be returned in the next reading operation.

Timeout for the reading operation is controlled by the [[#lua_socket_read_timeout|lua_socket_read_timeout]] config directive and the [[#tcpsock:settimeouts|settimeouts]] method. And the latter takes priority. For example:

<geshi lang="lua">
    sock:settimeouts(1000, 1000, 1000)  -- one second timeout for connect/read/write
    local data, err = sock:receiveany(10 * 1024) -- read any data, at most 10K
    if not data then
        ngx.say("failed to read any data: ", err)
        return
    end
    ngx.say("successfully read: ", data)
</geshi>

This method doesn't automatically close the current connection when the read timeout error occurs. For other connection errors, this method always automatically closes the connection.

This feature was first introduced in the <code>v0.10.14</code> release.

== tcpsock:receiveuntil ==

'''syntax:''' ''iterator = tcpsock:receiveuntil(pattern, options?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

This method returns an iterator Lua function that can be called to read the data stream until it sees the specified pattern or an error occurs.

Here is an example for using this method to read a data stream with the boundary sequence <code>--abcedhb</code>:

<geshi lang="lua">
    local reader = sock:receiveuntil("\r\n--abcedhb")
    local data, err, partial = reader()
    if not data then
        ngx.say("failed to read the data stream: ", err)
    end
    ngx.say("read the data stream: ", data)
</geshi>

When called without any argument, the iterator function returns the received data right ''before'' the specified pattern string in the incoming data stream. So for the example above, if the incoming data stream is <code>'hello, world! -agentzh\r\n--abcedhb blah blah'</code>, then the string <code>'hello, world! -agentzh'</code> will be returned.

In case of error, the iterator function will return <code>nil</code> along with a string describing the error and the partial data bytes that have been read so far.

The iterator function can be called multiple times and can be mixed safely with other cosocket method calls or other iterator function calls.

The iterator function behaves differently (i.e., like a real iterator) when it is called with a <code>size</code> argument. That is, it will read that <code>size</code> of data on each invocation and will return <code>nil</code> at the last invocation (either sees the boundary pattern or meets an error). For the last successful invocation of the iterator function, the <code>err</code> return value will be <code>nil</code> too. The iterator function will be reset after the last successful invocation that returns <code>nil</code> data and <code>nil</code> error. Consider the following example:

<geshi lang="lua">
    local reader = sock:receiveuntil("\r\n--abcedhb")

    while true do
        local data, err, partial = reader(4)
        if not data then
            if err then
                ngx.say("failed to read the data stream: ", err)
                break
            end

            ngx.say("read done")
            break
        end
        ngx.say("read chunk: [", data, "]")
    end
</geshi>

Then for the incoming data stream <code>'hello, world! -agentzh\r\n--abcedhb blah blah'</code>, we shall get the following output from the sample code above:

<geshi lang="text">
    read chunk: [hell]
    read chunk: [o, w]
    read chunk: [orld]
    read chunk: [! -a]
    read chunk: [gent]
    read chunk: [zh]
    read done
</geshi>

Note that, the actual data returned ''might'' be a little longer than the size limit specified by the <code>size</code> argument when the boundary pattern has ambiguity for streaming parsing. Near the boundary of the data stream, the data string actually returned could also be shorter than the size limit.

Timeout for the iterator function's reading operation is controlled by the [[#lua_socket_read_timeout|lua_socket_read_timeout]] config directive and the [[#tcpsock:settimeout|settimeout]] method. And the latter takes priority. For example:

<geshi lang="lua">
    local readline = sock:receiveuntil("\r\n")

    sock:settimeout(1000)  -- one second timeout
    line, err, partial = readline()
    if not line then
        ngx.say("failed to read a line: ", err)
        return
    end
    ngx.say("successfully read a line: ", line)
</geshi>

It is important here to call the [[#tcpsock:settimeout|settimeout]] method ''before'' calling the iterator function (note that the <code>receiveuntil</code> call is irrelevant here).

As from the <code>v0.5.1</code> release, this method also takes an optional <code>options</code> table argument to control the behavior. The following options are supported:

* <code>inclusive</code>

The <code>inclusive</code> takes a boolean value to control whether to include the pattern string in the returned data string. Default to <code>false</code>. For example,

<geshi lang="lua">
    local reader = tcpsock:receiveuntil("_END_", { inclusive = true })
    local data = reader()
    ngx.say(data)
</geshi>

Then for the input data stream <code>"hello world _END_ blah blah blah"</code>, then the example above will output <code>hello world _END_</code>, including the pattern string <code>_END_</code> itself.

Since the <code>v0.8.8</code> release, this method no longer automatically closes the current connection when the read timeout error happens. For other connection errors, this method always automatically closes the connection.

This method was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:close ==

'''syntax:''' ''ok, err = tcpsock:close()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Closes the current TCP or stream unix domain socket. It returns the <code>1</code> in case of success and returns <code>nil</code> with a string describing the error otherwise.

Note that there is no need to call this method on socket objects that have invoked the [[#tcpsock:setkeepalive|setkeepalive]] method because the socket object is already closed (and the current connection is saved into the built-in connection pool).

Socket objects that have not invoked this method (and associated connections) will be closed when the socket object is released by the Lua GC (Garbage Collector) or the current client HTTP request finishes processing.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:settimeout ==

'''syntax:''' ''tcpsock:settimeout(time)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Set the timeout value in milliseconds for subsequent socket operations ([[#tcpsock:connect|connect]], [[#tcpsock:receive|receive]], and iterators returned from [[#tcpsock:receiveuntil|receiveuntil]]).

Settings done by this method take priority over those specified via config directives (i.e. [[#lua_socket_connect_timeout|lua_socket_connect_timeout]], [[#lua_socket_send_timeout|lua_socket_send_timeout]], and [[#lua_socket_read_timeout|lua_socket_read_timeout]]).

Note that this method does ''not'' affect the [[#lua_socket_keepalive_timeout|lua_socket_keepalive_timeout]] setting; the <code>timeout</code> argument to the [[#tcpsock:setkeepalive|setkeepalive]] method should be used for this purpose instead.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:settimeouts ==

'''syntax:''' ''tcpsock:settimeouts(connect_timeout, send_timeout, read_timeout)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Respectively sets the connect, send, and read timeout thresholds (in milliseconds) for subsequent socket
operations ([[#tcpsock:connect|connect]], [[#tcpsock:send|send]], [[#tcpsock:receive|receive]], and iterators returned from [[#tcpsock:receiveuntil|receiveuntil]]).

Settings done by this method take priority over those specified via config directives (i.e. [[#lua_socket_connect_timeout|lua_socket_connect_timeout]], [[#lua_socket_send_timeout|lua_socket_send_timeout]], and [[#lua_socket_read_timeout|lua_socket_read_timeout]]).

It is recommended to use [[#tcpsock:settimeouts|settimeouts]] instead of [[#tcpsock:settimeout|settimeout]].

Note that this method does ''not'' affect the [[#lua_socket_keepalive_timeout|lua_socket_keepalive_timeout]] setting; the <code>timeout</code> argument to the [[#tcpsock:setkeepalive|setkeepalive]] method should be used for this purpose instead.

This feature was first introduced in the <code>v0.10.7</code> release.

== tcpsock:setoption ==

'''syntax:''' ''ok, err = tcpsock:setoption(option, value?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

This function is added for [http://w3.impa.br/~diego/software/luasocket/tcp.html LuaSocket] API compatibility and does nothing for now. Its functionality is implemented <code>v0.10.18</code>.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

In case of success, it returns <code>true</code>. Otherwise, it returns nil and a string describing the error.

The <code>option</code> is a string with the option name, and the value depends on the option being set:

* <code>keepalive</code>

: Setting this option to true enables sending of keep-alive messages on
: connection-oriented sockets. Make sure the <code>connect</code> function
: had been called before, for example,

    <geshi lang="lua">
    local ok, err = tcpsock:setoption("keepalive", true)
    if not ok then
        ngx.say("setoption keepalive failed: ", err)
    end
    </geshi>
* <code>reuseaddr</code>

: Enabling this option indicates that the rules used in validating addresses
: supplied in a call to bind should allow reuse of local addresses. Make sure
: the <code>connect</code> function had been called before, for example,

    <geshi lang="lua">
    local ok, err = tcpsock:setoption("reuseaddr", 0)
    if not ok then
        ngx.say("setoption reuseaddr failed: ", err)
    end
    </geshi>
* <code>tcp-nodelay</code>

: Setting this option to true disables the Nagle's algorithm for the connection.
: Make sure the <code>connect</code> function had been called before, for example,

    <geshi lang="lua">
    local ok, err = tcpsock:setoption("tcp-nodelay", true)
    if not ok then
        ngx.say("setoption tcp-nodelay failed: ", err)
    end
    </geshi>
* <code>sndbuf</code>

: Sets the maximum socket send buffer in bytes. The kernel doubles this value
: (to allow space for bookkeeping overhead) when it is set using setsockopt().
: Make sure the <code>connect</code> function had been called before, for example,

    <geshi lang="lua">
    local ok, err = tcpsock:setoption("sndbuf", 1024 * 10)
    if not ok then
        ngx.say("setoption sndbuf failed: ", err)
    end
    </geshi>
* <code>rcvbuf</code>

: Sets the maximum socket receive buffer in bytes. The kernel doubles this value
: (to allow space for bookkeeping overhead) when it is set using setsockopt. Make
: sure the <code>connect</code> function had been called before, for example,

    <geshi lang="lua">
    local ok, err = tcpsock:setoption("rcvbuf", 1024 * 10)
    if not ok then
        ngx.say("setoption rcvbuf failed: ", err)
    end
    </geshi>

NOTE: Once the option is set, it will become effective until the connection is closed. If you know the connection is from the connection pool and all the in-pool connections already have called the setoption() method with the desired socket option state, then you can just skip calling setoption() again to avoid the overhead of repeated calls, for example,

<geshi lang="lua">
    local count, err = tcpsock:getreusedtimes()
    if not count then
        ngx.say("getreusedtimes failed: ", err)
        return
    end

    if count == 0 then
        local ok, err = tcpsock:setoption("rcvbuf", 1024 * 10)
        if not ok then
            ngx.say("setoption rcvbuf failed: ", err)
            return
        end
    end
</geshi>

These options described above are supported in <code>v0.10.18</code>, and more options will be implemented in future.

== tcpsock:setkeepalive ==

'''syntax:''' ''ok, err = tcpsock:setkeepalive(timeout?, size?)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Puts the current socket's connection immediately into the cosocket built-in connection pool and keep it alive until other [[#tcpsock:connect|connect]] method calls request it or the associated maximal idle timeout is expired.

The first optional argument, <code>timeout</code>, can be used to specify the maximal idle timeout (in milliseconds) for the current connection. If omitted, the default setting in the [[#lua_socket_keepalive_timeout|lua_socket_keepalive_timeout]] config directive will be used. If the <code>0</code> value is given, then the timeout interval is unlimited.

The second optional argument <code>size</code> is considered deprecated since
the <code>v0.10.14</code> release of this module, in favor of the
<code>pool_size</code> option of the [[#tcpsock:connect|connect]] method.
Since the <code>v0.10.14</code> release, this option will only take effect if
the call to [[#tcpsock:connect|connect]] did not already create a connection
pool.
When this option takes effect (no connection pool was previously created by
[[#tcpsock:connect|connect]]), it will specify the size of the connection pool,
and create it.
If omitted (and no pool was previously created), the default size is the value
of the [[#lua_socket_pool_size|lua_socket_pool_size]] directive.
The connection pool holds up to <code>size</code> alive connections ready to be
reused by subsequent calls to [[#tcpsock:connect|connect]], but note that there
is no upper limit to the total number of opened connections outside of the
pool.
When the connection pool would exceed its size limit, the least recently used
(kept-alive) connection already in the pool will be closed to make room for
the current connection.
Note that the cosocket connection pool is per Nginx worker process rather
than per Nginx server instance, so the size limit specified here also applies
to every single Nginx worker process. Also note that the size of the connection
pool cannot be changed once it has been created.
If you need to restrict the total number of opened connections, specify both
the <code>pool_size</code> and <code>backlog</code> option in the call to
[[#tcpsock:connect|connect]].

In case of success, this method returns <code>1</code>; otherwise, it returns <code>nil</code> and a string describing the error.

When the system receive buffer for the current connection has unread data, then this method will return the "connection in dubious state" error message (as the second return value) because the previous session has unread data left behind for the next session and the connection is not safe to be reused.

This method also makes the current cosocket object enter the "closed" state, so there is no need to manually call the [[#tcpsock:close|close]] method on it afterwards.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== tcpsock:getreusedtimes ==

'''syntax:''' ''count, err = tcpsock:getreusedtimes()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

This method returns the (successfully) reused times for the current connection. In case of error, it returns <code>nil</code> and a string describing the error.

If the current connection does not come from the built-in connection pool, then this method always returns <code>0</code>, that is, the connection has never been reused (yet). If the connection comes from the connection pool, then the return value is always non-zero. So this method can also be used to determine if the current connection comes from the pool.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== ngx.socket.connect ==

'''syntax:''' ''tcpsock, err = ngx.socket.connect(host, port)''

'''syntax:''' ''tcpsock, err = ngx.socket.connect("unix:/path/to/unix-domain.socket")''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*''

This function is a shortcut for combining [[#ngx.socket.tcp|ngx.socket.tcp()]] and the [[#tcpsock:connect|connect()]] method call in a single operation. It is actually implemented like this:

<geshi lang="lua">
    local sock = ngx.socket.tcp()
    local ok, err = sock:connect(...)
    if not ok then
        return nil, err
    end
    return sock
</geshi>

There is no way to use the [[#tcpsock:settimeout|settimeout]] method to specify connecting timeout for this method and the [[#lua_socket_connect_timeout|lua_socket_connect_timeout]] directive must be set at configure time instead.

This feature was first introduced in the <code>v0.5.0rc1</code> release.

== ngx.get_phase ==

'''syntax:''' ''str = ngx.get_phase()''

'''context:''' ''init_by_lua*, init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Retrieves the current running phase name. Possible return values are

* <code>init</code>
: for the context of [[#init_by_lua|init_by_lua*]].
* <code>init_worker</code>
: for the context of [[#init_worker_by_lua|init_worker_by_lua*]].
* <code>ssl_cert</code>
: for the context of [[#ssl_certificate_by_lua_block|ssl_certificate_by_lua*]].
* <code>ssl_session_fetch</code>
: for the context of [[#ssl_session_fetch_by_lua_block|ssl_session_fetch_by_lua*]].
* <code>ssl_session_store</code>
: for the context of [[#ssl_session_store_by_lua_block|ssl_session_store_by_lua*]].
* <code>ssl_client_hello</code>
: for the context of [[#ssl_client_hello_by_lua_block|ssl_client_hello_by_lua*]].
* <code>set</code>
: for the context of [[#set_by_lua|set_by_lua*]].
* <code>rewrite</code>
: for the context of [[#rewrite_by_lua|rewrite_by_lua*]].
* <code>balancer</code>
: for the context of [[#balancer_by_lua_block|balancer_by_lua*]].
* <code>access</code>
: for the context of [[#access_by_lua|access_by_lua*]].
* <code>content</code>
: for the context of [[#content_by_lua|content_by_lua*]].
* <code>header_filter</code>
: for the context of [[#header_filter_by_lua|header_filter_by_lua*]].
* <code>body_filter</code>
: for the context of [[#body_filter_by_lua|body_filter_by_lua*]].
* <code>log</code>
: for the context of [[#log_by_lua|log_by_lua*]].
* <code>timer</code>
: for the context of user callback functions for [[#ngx.timer.at|ngx.timer.*]].
* <code>exit_worker</code>
: for the context of [[#exit_worker_by_lua|exit_worker_by_lua*]].

This API was first introduced in the <code>v0.5.10</code> release.

== ngx.thread.spawn ==

'''syntax:''' ''co = ngx.thread.spawn(func, arg1, arg2, ...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Spawns a new user "light thread" with the Lua function <code>func</code> as well as those optional arguments <code>arg1</code>, <code>arg2</code>, and etc. Returns a Lua thread (or Lua coroutine) object represents this "light thread".

"Light threads" are just a special kind of Lua coroutines that are scheduled by the ngx_lua module.

Before <code>ngx.thread.spawn</code> returns, the <code>func</code> will be called with those optional arguments until it returns, aborts with an error, or gets yielded due to I/O operations via the [[#Nginx API for Lua|Nginx API for Lua]] (like [[#tcpsock:receive|tcpsock:receive]]).

After <code>ngx.thread.spawn</code> returns, the newly-created "light thread" will keep running asynchronously usually at various I/O events.

All the Lua code chunks running by [[#rewrite_by_lua|rewrite_by_lua]], [[#access_by_lua|access_by_lua]], and [[#content_by_lua|content_by_lua]] are in a boilerplate "light thread" created automatically by ngx_lua. Such boilerplate "light thread" are also called "entry threads".

By default, the corresponding Nginx handler (e.g., [[#rewrite_by_lua|rewrite_by_lua]] handler) will not terminate until

# both the "entry thread" and all the user "light threads" terminates,
# a "light thread" (either the "entry thread" or a user "light thread") aborts by calling [[#ngx.exit|ngx.exit]], [[#ngx.exec|ngx.exec]], [[#ngx.redirect|ngx.redirect]], or [[#ngx.req.set_uri|ngx.req.set_uri(uri, true)]], or
# the "entry thread" terminates with a Lua error.

When the user "light thread" terminates with a Lua error, however, it will not abort other running "light threads" like the "entry thread" does.

Due to the limitation in the Nginx subrequest model, it is not allowed to abort a running Nginx subrequest in general. So it is also prohibited to abort a running "light thread" that is pending on one ore more Nginx subrequests. You must call [[#ngx.thread.wait|ngx.thread.wait]] to wait for those "light thread" to terminate before quitting the "world". A notable exception here is that you can abort pending subrequests by calling [[#ngx.exit|ngx.exit]] with and only with the status code <code>ngx.ERROR</code> (-1), <code>408</code>, <code>444</code>, or <code>499</code>.

The "light threads" are not scheduled in a pre-emptive way. In other words, no time-slicing is performed automatically. A "light thread" will keep running exclusively on the CPU until

# a (nonblocking) I/O operation cannot be completed in a single run,
# it calls [[#coroutine.yield|coroutine.yield]] to actively give up execution, or
# it is aborted by a Lua error or an invocation of [[#ngx.exit|ngx.exit]], [[#ngx.exec|ngx.exec]], [[#ngx.redirect|ngx.redirect]], or [[#ngx.req.set_uri|ngx.req.set_uri(uri, true)]].

For the first two cases, the "light thread" will usually be resumed later by the ngx_lua scheduler unless a "stop-the-world" event happens.

User "light threads" can create "light threads" themselves. And normal user coroutines created by [[#coroutine.create|coroutine.create]] can also create "light threads". The coroutine (be it a normal Lua coroutine or a "light thread") that directly spawns the "light thread" is called the "parent coroutine" for the "light thread" newly spawned.

The "parent coroutine" can call [[#ngx.thread.wait|ngx.thread.wait]] to wait on the termination of its child "light thread".

You can call coroutine.status() and coroutine.yield() on the "light thread" coroutines.

The status of the "light thread" coroutine can be "zombie" if

# the current "light thread" already terminates (either successfully or with an error),
# its parent coroutine is still alive, and
# its parent coroutine is not waiting on it with [[#ngx.thread.wait|ngx.thread.wait]].

The following example demonstrates the use of coroutine.yield() in the "light thread" coroutines
to do manual time-slicing:

<geshi lang="lua">
    local yield = coroutine.yield

    function f()
        local self = coroutine.running()
        ngx.say("f 1")
        yield(self)
        ngx.say("f 2")
        yield(self)
        ngx.say("f 3")
    end

    local self = coroutine.running()
    ngx.say("0")
    yield(self)

    ngx.say("1")
    ngx.thread.spawn(f)

    ngx.say("2")
    yield(self)

    ngx.say("3")
    yield(self)

    ngx.say("4")
</geshi>

Then it will generate the output

<geshi lang="text">
    0
    1
    f 1
    2
    f 2
    3
    f 3
    4
</geshi>

"Light threads" are mostly useful for making concurrent upstream requests in a single Nginx request handler, much like a generalized version of [[#ngx.location.capture_multi|ngx.location.capture_multi]] that can work with all the [[#Nginx API for Lua|Nginx API for Lua]]. The following example demonstrates parallel requests to MySQL, Memcached, and upstream HTTP services in a single Lua handler, and outputting the results in the order that they actually return (similar to Facebook's BigPipe model):

<geshi lang="lua">
    -- query mysql, memcached, and a remote http service at the same time,
    -- output the results in the order that they
    -- actually return the results.

    local mysql = require "resty.mysql"
    local memcached = require "resty.memcached"

    local function query_mysql()
        local db = mysql:new()
        db:connect{
                    host = "127.0.0.1",
                    port = 3306,
                    database = "test",
                    user = "monty",
                    password = "mypass"
                  }
        local res, err, errno, sqlstate =
                db:query("select * from cats order by id asc")
        db:set_keepalive(0, 100)
        ngx.say("mysql done: ", cjson.encode(res))
    end

    local function query_memcached()
        local memc = memcached:new()
        memc:connect("127.0.0.1", 11211)
        local res, err = memc:get("some_key")
        ngx.say("memcached done: ", res)
    end

    local function query_http()
        local res = ngx.location.capture("/my-http-proxy")
        ngx.say("http done: ", res.body)
    end

    ngx.thread.spawn(query_mysql)      -- create thread 1
    ngx.thread.spawn(query_memcached)  -- create thread 2
    ngx.thread.spawn(query_http)       -- create thread 3
</geshi>

This API was first enabled in the <code>v0.7.0</code> release.

== ngx.thread.wait ==

'''syntax:''' ''ok, res1, res2, ... = ngx.thread.wait(thread1, thread2, ...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Waits on one or more child "light threads" and returns the results of the first "light thread" that terminates (either successfully or with an error).

The arguments <code>thread1</code>, <code>thread2</code>, and etc are the Lua thread objects returned by earlier calls of [[#ngx.thread.spawn|ngx.thread.spawn]].

The return values have exactly the same meaning as [[#coroutine.resume|coroutine.resume]], that is, the first value returned is a boolean value indicating whether the "light thread" terminates successfully or not, and subsequent values returned are the return values of the user Lua function that was used to spawn the "light thread" (in case of success) or the error object (in case of failure).

Only the direct "parent coroutine" can wait on its child "light thread", otherwise a Lua exception will be raised.

The following example demonstrates the use of <code>ngx.thread.wait</code> and [[#ngx.location.capture|ngx.location.capture]] to emulate [[#ngx.location.capture_multi|ngx.location.capture_multi]]:

<geshi lang="lua">
    local capture = ngx.location.capture
    local spawn = ngx.thread.spawn
    local wait = ngx.thread.wait
    local say = ngx.say

    local function fetch(uri)
        return capture(uri)
    end

    local threads = {
        spawn(fetch, "/foo"),
        spawn(fetch, "/bar"),
        spawn(fetch, "/baz")
    }

    for i = 1, #threads do
        local ok, res = wait(threads[i])
        if not ok then
            say(i, ": failed to run: ", res)
        else
            say(i, ": status: ", res.status)
            say(i, ": body: ", res.body)
        end
    end
</geshi>

Here it essentially implements the "wait all" model.

And below is an example demonstrating the "wait any" model:

<geshi lang="lua">
    function f()
        ngx.sleep(0.2)
        ngx.say("f: hello")
        return "f done"
    end

    function g()
        ngx.sleep(0.1)
        ngx.say("g: hello")
        return "g done"
    end

    local tf, err = ngx.thread.spawn(f)
    if not tf then
        ngx.say("failed to spawn thread f: ", err)
        return
    end

    ngx.say("f thread created: ", coroutine.status(tf))

    local tg, err = ngx.thread.spawn(g)
    if not tg then
        ngx.say("failed to spawn thread g: ", err)
        return
    end

    ngx.say("g thread created: ", coroutine.status(tg))

    ok, res = ngx.thread.wait(tf, tg)
    if not ok then
        ngx.say("failed to wait: ", res)
        return
    end

    ngx.say("res: ", res)

    -- stop the "world", aborting other running threads
    ngx.exit(ngx.OK)
</geshi>

And it will generate the following output:

<geshi lang="text">
    f thread created: running
    g thread created: running
    g: hello
    res: g done
</geshi>

This API was first enabled in the <code>v0.7.0</code> release.

== ngx.thread.kill ==

'''syntax:''' ''ok, err = ngx.thread.kill(thread)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_client_hello_by_lua*''

Kills a running "light thread" created by [[#ngx.thread.spawn|ngx.thread.spawn]]. Returns a true value when successful or <code>nil</code> and a string describing the error otherwise.

According to the current implementation, only the parent coroutine (or "light thread") can kill a thread. Also, a running "light thread" with pending Nginx subrequests (initiated by [[#ngx.location.capture|ngx.location.capture]] for example) cannot be killed due to a limitation in the Nginx core.

This API was first enabled in the <code>v0.9.9</code> release.

== ngx.on_abort ==

'''syntax:''' ''ok, err = ngx.on_abort(callback)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

Registers a user Lua function as the callback which gets called automatically when the client closes the (downstream) connection prematurely.

Returns <code>1</code> if the callback is registered successfully or returns <code>nil</code> and a string describing the error otherwise.

All the [[#Nginx API for Lua|Nginx API for Lua]] can be used in the callback function because the function is run in a special "light thread", just as those "light threads" created by [[#ngx.thread.spawn|ngx.thread.spawn]].

The callback function can decide what to do with the client abortion event all by itself. For example, it can simply ignore the event by doing nothing and the current Lua request handler will continue executing without interruptions. And the callback function can also decide to terminate everything by calling [[#ngx.exit|ngx.exit]], for example,

<geshi lang="lua">
    local function my_cleanup()
        -- custom cleanup work goes here, like cancelling a pending DB transaction

        -- now abort all the "light threads" running in the current request handler
        ngx.exit(499)
    end

    local ok, err = ngx.on_abort(my_cleanup)
    if not ok then
        ngx.log(ngx.ERR, "failed to register the on_abort callback: ", err)
        ngx.exit(500)
    end
</geshi>

When [[#lua_check_client_abort|lua_check_client_abort]] is set to <code>off</code> (which is the default), then this function call will always return the error message "lua_check_client_abort is off".

According to the current implementation, this function can only be called once in a single request handler; subsequent calls will return the error message "duplicate call".

This API was first introduced in the <code>v0.7.4</code> release.

See also [[#lua_check_client_abort|lua_check_client_abort]].

== ngx.timer.at ==

'''syntax:''' ''hdl, err = ngx.timer.at(delay, callback, user_arg1, user_arg2, ...)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Creates an Nginx timer with a user callback function as well as optional user arguments.

The first argument, <code>delay</code>, specifies the delay for the timer,
in seconds. One can specify fractional seconds like <code>0.001</code> to mean 1
millisecond here. <code>0</code> delay can also be specified, in which case the
timer will immediately expire when the current handler yields
execution.

The second argument, <code>callback</code>, can
be any Lua function, which will be invoked later in a background
"light thread" after the delay specified. The user callback will be
called automatically by the Nginx core with the arguments <code>premature</code>,
<code>user_arg1</code>, <code>user_arg2</code>, and etc, where the <code>premature</code>
argument takes a boolean value indicating whether it is a premature timer
expiration or not, and <code>user_arg1</code>, <code>user_arg2</code>, and etc, are
those (extra) user arguments specified when calling <code>ngx.timer.at</code>
as the remaining arguments.

Premature timer expiration happens when the Nginx worker process is
trying to shut down, as in an Nginx configuration reload triggered by
the <code>HUP</code> signal or in an Nginx server shutdown. When the Nginx worker
is trying to shut down, one can no longer call <code>ngx.timer.at</code> to
create new timers with nonzero delays and in that case <code>ngx.timer.at</code> will return a "conditional false" value and
a string describing the error, that is, "process exiting".

Starting from the <code>v0.9.3</code> release, it is allowed to create zero-delay timers even when the Nginx worker process starts shutting down.

When a timer expires, the user Lua code in the timer callback is
running in a "light thread" detached completely from the original
request creating the timer. So objects with the same lifetime as the
request creating them, like [[#ngx.socket.tcp|cosockets]], cannot be shared between the
original request and the timer user callback function.

Here is a simple example:

<geshi lang="nginx">
    location / {
        ...
        log_by_lua_block {
            local function push_data(premature, uri, args, status)
                -- push the data uri, args, and status to the remote
                -- via ngx.socket.tcp or ngx.socket.udp
                -- (one may want to buffer the data in Lua a bit to
                -- save I/O operations)
            end
            local ok, err = ngx.timer.at(0, push_data,
                                         ngx.var.uri, ngx.var.args, ngx.header.status)
            if not ok then
                ngx.log(ngx.ERR, "failed to create timer: ", err)
                return
            end

            -- other job in log_by_lua_block
        }
    }
</geshi>

One can also create infinite re-occurring timers, for instance, a timer getting triggered every <code>5</code> seconds, by calling <code>ngx.timer.at</code> recursively in the timer callback function. Here is such an example,

<geshi lang="lua">
    local delay = 5
    local handler
    handler = function (premature)
        -- do some routine job in Lua just like a cron job
        if premature then
            return
        end
        local ok, err = ngx.timer.at(delay, handler)
        if not ok then
            ngx.log(ngx.ERR, "failed to create the timer: ", err)
            return
        end

        -- do something in timer
    end

    local ok, err = ngx.timer.at(delay, handler)
    if not ok then
        ngx.log(ngx.ERR, "failed to create the timer: ", err)
        return
    end

    -- do other jobs
</geshi>

It is recommended, however, to use the [[#ngx.timer.every|ngx.timer.every]] API function
instead for creating recurring timers since it is more robust.

Because timer callbacks run in the background and their running time
will not add to any client request's response time, they can easily
accumulate in the server and exhaust system resources due to either
Lua programming mistakes or just too much client traffic. To prevent
extreme consequences like crashing the Nginx server, there are
built-in limitations on both the number of "pending timers" and the
number of "running timers" in an Nginx worker process. The "pending
timers" here mean timers that have not yet been expired and "running
timers" are those whose user callbacks are currently running.

The maximal number of pending timers allowed in an Nginx
worker is controlled by the [[#lua_max_pending_timers|lua_max_pending_timers]]
directive. The maximal number of running timers is controlled by the
[[#lua_max_running_timers|lua_max_running_timers]] directive.

According to the current implementation, each "running timer" will
take one (fake) connection record from the global connection record
list configured by the standard [[EventsModule#worker_connections|worker_connections]] directive in
<code>nginx.conf</code>. So ensure that the
[[EventsModule#worker_connections|worker_connections]] directive is set to
a large enough value that takes into account both the real connections
and fake connections required by timer callbacks (as limited by the
[[#lua_max_running_timers|lua_max_running_timers]] directive).

A lot of the Lua APIs for Nginx are enabled in the context of the timer
callbacks, like stream/datagram cosockets ([[#ngx.socket.tcp|ngx.socket.tcp]] and [[#ngx.socket.udp|ngx.socket.udp]]), shared
memory dictionaries ([[#ngx.shared.DICT|ngx.shared.DICT]]), user coroutines ([[#coroutine.create|coroutine.*]]),
user "light threads" ([[#ngx.thread.spawn|ngx.thread.*]]), [[#ngx.exit|ngx.exit]], [[#ngx.now|ngx.now]]/[[#ngx.time|ngx.time]],
[[#ngx.md5|ngx.md5]]/[[#ngx.sha1_bin|ngx.sha1_bin]], are all allowed. But the subrequest API (like
[[#ngx.location.capture|ngx.location.capture]]), the [[#ngx.req.start_time|ngx.req.*]] API, the downstream output API
(like [[#ngx.say|ngx.say]], [[#ngx.print|ngx.print]], and [[#ngx.flush|ngx.flush]]) are explicitly disabled in
this context.

You must notice that each timer will be based on a fake request (this fake request is also based on a fake connection). Because Nginx's memory release is based on the connection closure, if you run a lot of APIs that apply for memory resources in a timer, such as [[#tcpsock:connect|tcpsock:connect]], will cause the accumulation of memory resources. So it is recommended to create a new timer after running several times to release memory resources.

You can pass most of the standard Lua values (nils, booleans, numbers, strings, tables, closures, file handles, and etc) into the timer callback, either explicitly as user arguments or implicitly as upvalues for the callback closure. There are several exceptions, however: you ''cannot'' pass any thread objects returned by [[#coroutine.create|coroutine.create]] and [[#ngx.thread.spawn|ngx.thread.spawn]] or any cosocket objects returned by [[#ngx.socket.tcp|ngx.socket.tcp]], [[#ngx.socket.udp|ngx.socket.udp]], and [[#ngx.req.socket|ngx.req.socket]] because these objects' lifetime is bound to the request context creating them while the timer callback is detached from the creating request's context (by design) and runs in its own (fake) request context. If you try to share the thread or cosocket objects across the boundary of the creating request, then you will get the "no co ctx found" error (for threads) or "bad request" (for cosockets). It is fine, however, to create all these objects inside your timer callback.

Please note that the timer Lua handler has its own copy of the `ngx.ctx` magic
table. It won't share the same `ngx.ctx` with the Lua handler creating the timer.
If you need to pass data from the timer creator to the timer handler, please
use the extra parameters of `ngx.timer.at()`.

This API was first introduced in the <code>v0.8.0</code> release.

== ngx.timer.every ==

'''syntax:''' ''hdl, err = ngx.timer.every(delay, callback, user_arg1, user_arg2, ...)''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Similar to the [[#ngx.timer.at|ngx.timer.at]] API function, but

# <code>delay</code> ''cannot'' be zero,
# timer will be created every <code>delay</code> seconds until the current Nginx worker process starts exiting.

Like [[#ngx.timer.at|ngx.timer.at]], the <code>callback</code> argument will be called
automatically with the arguments <code>premature</code>, <code>user_arg1</code>, <code>user_arg2</code>, etc.

When success, returns a "conditional true" value (but not a <code>true</code>). Otherwise, returns a "conditional false" value and a string describing the error.

This API also respect the [[#lua_max_pending_timers|lua_max_pending_timers]] and [[#lua_max_running_timers|lua_max_running_timers]].

This API was first introduced in the <code>v0.10.9</code> release.

== ngx.timer.running_count ==

'''syntax:''' ''count = ngx.timer.running_count()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns the number of timers currently running.

This directive was first introduced in the <code>v0.9.20</code> release.

== ngx.timer.pending_count ==

'''syntax:''' ''count = ngx.timer.pending_count()''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

Returns the number of pending timers.

This directive was first introduced in the <code>v0.9.20</code> release.

== ngx.config.subsystem ==

'''syntax:''' ''subsystem = ngx.config.subsystem''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

This string field indicates the Nginx subsystem the current Lua environment is based on. For this module, this field always takes the string value <code>"http"</code>. For
[https://github.com/openresty/stream-lua-nginx-module#readme ngx_stream_lua_module], however, this field takes the value <code>"stream"</code>.

This field was first introduced in the <code>0.10.1</code>.

== ngx.config.debug ==

'''syntax:''' ''debug = ngx.config.debug''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

This boolean field indicates whether the current Nginx is a debug build, i.e., being built by the <code>./configure</code> option <code>--with-debug</code>.

This field was first introduced in the <code>0.8.7</code>.

== ngx.config.prefix ==

'''syntax:''' ''prefix = ngx.config.prefix()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

Returns the Nginx server "prefix" path, as determined by the <code>-p</code> command-line option when running the Nginx executable, or the path specified by the <code>--prefix</code> command-line option when building Nginx with the <code>./configure</code> script.

This function was first introduced in the <code>0.9.2</code>.

== ngx.config.nginx_version ==

'''syntax:''' ''ver = ngx.config.nginx_version''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

This field take an integral value indicating the version number of the current Nginx core being used. For example, the version number <code>1.4.3</code> results in the Lua number 1004003.

This API was first introduced in the <code>0.9.3</code> release.

== ngx.config.nginx_configure ==

'''syntax:''' ''str = ngx.config.nginx_configure()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*''

This function returns a string for the Nginx <code>./configure</code> command's arguments string.

This API was first introduced in the <code>0.9.5</code> release.

== ngx.config.ngx_lua_version ==

'''syntax:''' ''ver = ngx.config.ngx_lua_version''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*''

This field take an integral value indicating the version number of the current <code>ngx_lua</code> module being used. For example, the version number <code>0.9.3</code> results in the Lua number 9003.

This API was first introduced in the <code>0.9.3</code> release.

== ngx.worker.exiting ==

'''syntax:''' ''exiting = ngx.worker.exiting()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

This function returns a boolean value indicating whether the current Nginx worker process already starts exiting. Nginx worker process exiting happens on Nginx server quit or configuration reload (aka HUP reload).

This API was first introduced in the <code>0.9.3</code> release.

== ngx.worker.pid ==

'''syntax:''' ''pid = ngx.worker.pid()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

This function returns a Lua number for the process ID (PID) of the current Nginx worker process. This API is more efficient than <code>ngx.var.pid</code> and can be used in contexts where the [[#ngx.var.VARIABLE|ngx.var.VARIABLE]] API cannot be used (like [[#init_worker_by_lua|init_worker_by_lua]]).

This API was first introduced in the <code>0.9.5</code> release.

== ngx.worker.pids ==

'''syntax:''' ''pid = ngx.worker.pids()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, exit_worker_by_lua*''

This function returns a Lua table for all Nginx worker process ID (PID). Nginx uses channel to send the current worker PID to another worker in the worker process start or restart. So this API can get all current worker PID.
== ngx.worker.count ==

'''syntax:''' ''count = ngx.worker.count()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_by_lua*, init_worker_by_lua*, exit_worker_by_lua*''

Returns the total number of the Nginx worker processes (i.e., the value configured
by the [https://nginx.org/en/docs/ngx_core_module.html#worker_processes worker_processes]
directive in <code>nginx.conf</code>).

This API was first introduced in the <code>0.9.20</code> release.

== ngx.worker.id ==

'''syntax:''' ''id = ngx.worker.id()''

'''context:''' ''set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, init_worker_by_lua*, exit_worker_by_lua*''

Returns the ordinal number of the current Nginx worker processes (starting from number 0).

So if the total number of workers is <code>N</code>, then this method may return a number between 0
and <code>N - 1</code> (inclusive).

This function returns meaningful values only for Nginx 1.9.1+. With earlier versions of Nginx, it
always returns <code>nil</code>.

See also [[#ngx.worker.count|ngx.worker.count]].

This API was first introduced in the <code>0.9.20</code> release.

== ngx.semaphore ==

'''syntax:''' ''local semaphore = require "ngx.semaphore"''

This is a Lua module that implements a classic-style semaphore API for efficient synchronizations among
different "light threads". Sharing the same semaphore among different "light threads" created in different (request)
contexts are also supported as long as the "light threads" reside in the same Nginx worker process
and the [[#lua_code_cache|lua_code_cache]] directive is turned on (which is the default).

This Lua module does not ship with this ngx_lua module itself rather it is shipped with
the
[https://github.com/openresty/lua-resty-core lua-resty-core] library.

Please refer to the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/semaphore.md documentation]
for this <code>ngx.semaphore</code> Lua module in [https://github.com/openresty/lua-resty-core lua-resty-core]
for more details.

This feature requires at least ngx_lua <code>v0.10.0</code>.

== ngx.balancer ==

'''syntax:''' ''local balancer = require "ngx.balancer"''

This is a Lua module that provides a Lua API to allow defining completely dynamic load balancers
in pure Lua.

This Lua module does not ship with this ngx_lua module itself rather it is shipped with
the
[https://github.com/openresty/lua-resty-core lua-resty-core] library.

Please refer to the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/balancer.md documentation]
for this <code>ngx.balancer</code> Lua module in [https://github.com/openresty/lua-resty-core lua-resty-core]
for more details.

This feature requires at least ngx_lua <code>v0.10.0</code>.

== ngx.ssl ==

'''syntax:''' ''local ssl = require "ngx.ssl"''

This Lua module provides API functions to control the SSL handshake process in contexts like
[ssl_certificate_by_lua*](#ssl_certificate_by_lua_block).

This Lua module does not ship with this ngx_lua module itself rather it is shipped with
the
[https://github.com/openresty/lua-resty-core lua-resty-core] library.

Please refer to the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md documentation]
for this <code>ngx.ssl</code> Lua module for more details.

This feature requires at least ngx_lua <code>v0.10.0</code>.

== ngx.ocsp ==

'''syntax:''' ''local ocsp = require "ngx.ocsp"''

This Lua module provides API to perform OCSP queries, OCSP response validations, and
OCSP stapling planting.

Usually, this module is used together with the [ngx.ssl](https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ssl.md)
module in the
context of [ssl_certificate_by_lua*](#ssl_certificate_by_lua_block).

This Lua module does not ship with this ngx_lua module itself rather it is shipped with
the
[https://github.com/openresty/lua-resty-core lua-resty-core] library.

Please refer to the [https://github.com/openresty/lua-resty-core/blob/master/lib/ngx/ocsp.md documentation]
for this <code>ngx.ocsp</code> Lua module for more details.

This feature requires at least ngx_lua <code>v0.10.0</code>.

== ndk.set_var.DIRECTIVE ==

'''syntax:''' ''res = ndk.set_var.DIRECTIVE_NAME''

'''context:''' ''init_worker_by_lua*, set_by_lua*, rewrite_by_lua*, access_by_lua*, content_by_lua*, header_filter_by_lua*, body_filter_by_lua*, log_by_lua*, ngx.timer.*, balancer_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, exit_worker_by_lua*, ssl_client_hello_by_lua*''

This mechanism allows calling other Nginx C modules' directives that are implemented by [https://github.com/simplresty/ngx_devel_kit Nginx Devel Kit] (NDK)'s set_var submodule's <code>ndk_set_var_value</code>.

For example, the following [[HttpSetMiscModule]] directives can be invoked this way:

* [[HttpSetMiscModule#set_quote_sql_str|set_quote_sql_str]]
* [[HttpSetMiscModule#set_quote_pgsql_str|set_quote_pgsql_str]]
* [[HttpSetMiscModule#set_quote_json_str|set_quote_json_str]]
* [[HttpSetMiscModule#set_unescape_uri|set_unescape_uri]]
* [[HttpSetMiscModule#set_escape_uri|set_escape_uri]]
* [[HttpSetMiscModule#set_encode_base32|set_encode_base32]]
* [[HttpSetMiscModule#set_decode_base32|set_decode_base32]]
* [[HttpSetMiscModule#set_encode_base64|set_encode_base64]]
* [[HttpSetMiscModule#set_decode_base64|set_decode_base64]]
* [[HttpSetMiscModule#set_encode_base64|set_encode_hex]]
* [[HttpSetMiscModule#set_decode_base64|set_decode_hex]]
* [[HttpSetMiscModule#set_encode_base64|set_sha1]]
* [[HttpSetMiscModule#set_decode_base64|set_md5]]

For instance,

<geshi lang="lua">
    local res = ndk.set_var.set_escape_uri('a/b')
    -- now res == 'a%2fb'
</geshi>

Similarly, the following directives provided by [[HttpEncryptedSessionModule]] can be invoked from within Lua too:

* [[HttpEncryptedSessionModule#set_encrypt_session|set_encrypt_session]]
* [[HttpEncryptedSessionModule#set_decrypt_session|set_decrypt_session]]

This feature requires the [https://github.com/simplresty/ngx_devel_kit ngx_devel_kit] module.

== coroutine.create ==

'''syntax:''' ''co = coroutine.create(f)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Creates a user Lua coroutines with a Lua function, and returns a coroutine object.

Similar to the standard Lua [https://www.lua.org/manual/5.1/manual.html#pdf-coroutine.create coroutine.create] API, but works in the context of the Lua coroutines created by ngx_lua.

This API was first usable in the context of [[#init_by_lua|init_by_lua*]] since the <code>0.9.2</code>.

This API was first introduced in the <code>v0.6.0</code> release.

== coroutine.resume ==

'''syntax:''' ''ok, ... = coroutine.resume(co, ...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Resumes the execution of a user Lua coroutine object previously yielded or just created.

Similar to the standard Lua [https://www.lua.org/manual/5.1/manual.html#pdf-coroutine.resume coroutine.resume] API, but works in the context of the Lua coroutines created by ngx_lua.

This API was first usable in the context of [[#init_by_lua|init_by_lua*]] since the <code>0.9.2</code>.

This API was first introduced in the <code>v0.6.0</code> release.

== coroutine.yield ==

'''syntax:''' ''... = coroutine.yield(...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Yields the execution of the current user Lua coroutine.

Similar to the standard Lua [https://www.lua.org/manual/5.1/manual.html#pdf-coroutine.yield coroutine.yield] API, but works in the context of the Lua coroutines created by ngx_lua.

This API was first usable in the context of [[#init_by_lua|init_by_lua*]] since the <code>0.9.2</code>.

This API was first introduced in the <code>v0.6.0</code> release.

== coroutine.wrap ==

'''syntax:''' ''co = coroutine.wrap(f)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Similar to the standard Lua [https://www.lua.org/manual/5.1/manual.html#pdf-coroutine.wrap coroutine.wrap] API, but works in the context of the Lua coroutines created by ngx_lua.

This API was first usable in the context of [[#init_by_lua|init_by_lua*]] since the <code>0.9.2</code>.

This API was first introduced in the <code>v0.6.0</code> release.

== coroutine.running ==

'''syntax:''' ''co = coroutine.running()''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Identical to the standard Lua [https://www.lua.org/manual/5.1/manual.html#pdf-coroutine.running coroutine.running] API.

This API was first usable in the context of [[#init_by_lua|init_by_lua*]] since the <code>0.9.2</code>.

This API was first enabled in the <code>v0.6.0</code> release.

== coroutine.status ==

'''syntax:''' ''status = coroutine.status(co)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*, init_by_lua*, ngx.timer.*, header_filter_by_lua*, body_filter_by_lua*, ssl_certificate_by_lua*, ssl_session_fetch_by_lua*, ssl_session_store_by_lua*, ssl_client_hello_by_lua*''

Identical to the standard Lua [https://www.lua.org/manual/5.1/manual.html#pdf-coroutine.status coroutine.status] API.

This API was first usable in the context of [[#init_by_lua|init_by_lua*]] since the <code>0.9.2</code>.

This API was first enabled in the <code>v0.6.0</code> release.

== ngx.run_worker_thread ==

'''syntax:''' ''ok, res1, res2, ... = ngx.run_worker_thread(threadpool, module_name, func_name, arg1, arg2, ...)''

'''context:''' ''rewrite_by_lua*, access_by_lua*, content_by_lua*''

'''This API is still experimental and may change in the future without notice.'''

'''This API is available only for Linux.'''

Wrap the [http://nginx.org/en/docs/dev/development_guide.html#threads nginx worker thread] to execute lua function. The caller coroutine would yield until the function returns.

Only the following ngx_lua APIs could be used in `function_name` function of the `module` module:

* `ngx.encode_base64`
* `ngx.decode_base64`

* `ngx.hmac_sha1`
* `ngx.encode_args`
* `ngx.decode_args`
* `ngx.quote_sql_str`

* `ngx.re.match`
* `ngx.re.find`
* `ngx.re.gmatch`
* `ngx.re.sub`
* `ngx.re.gsub`

* `ngx.crc32_short`
* `ngx.crc32_long`
* `ngx.hmac_sha1`
* `ngx.md5_bin`
* `ngx.md5`

* `ngx.config.subsystem`
* `ngx.config.debug`
* `ngx.config.prefix`
* `ngx.config.nginx_version`
* `ngx.config.nginx_configure`
* `ngx.config.ngx_lua_version`


The first argument `threadpool` specifies the Nginx thread pool name defined by [thread_pool](https://nginx.org/en/docs/ngx_core_module.html#thread_pool).

The second argument <code>module_name</code> specifies the lua module name to execute in the worker thread, which would return a lua table. The module must be inside the package path, e.g.

<geshi lang="nginx">
lua_package_path '/opt/openresty/?.lua;;';
</geshi>

The third argument <code>func_name</code> specifies the function field in the module table as the second argument.

The type of <code>arg</code>s must be one of type below:

* boolean
* number
* string
* nil
* table (the table may be recursive, and contains members of types above.)

The <code>ok</code> is in boolean type, which indicate the C land error (failed to get thread from thread pool, pcall the module function failed, .etc). If <code>ok</code> is <code>false</code>, the <code>res1</code> is the error string.

The return values (res1, ...) are returned by invocation of the module function. Normally, the <code>res1</code> should be in boolean type, so that the caller could inspect the error.

This API is useful when you need to execute the below types of tasks:

* CPU bound task, e.g. do md5 calculation
* File I/O task
* Call <code>os.execute()</code> or blocking C API via <code>ffi</code>
* Call external Lua library not based on cosocket or nginx

Example1: do md5 calculation.

<geshi lang="nginx">
location /calc_md5 {
    default_type 'text/plain';

    content_by_lua_block {
        local ok, md5_or_err = ngx.run_worker_thread("testpool", "md5", "md5")
        ngx.say(ok, " : ", md5_or_err)
    }
}

</geshi>

<code>md5.lua</code>

<geshi lang="lua">
local function md5()
    return ngx.md5("hello")
end
return {md5=md5}
</geshi>

Example2: write logs into the log file.

<geshi lang="nginx">
location /write_log_file {
    default_type 'text/plain';

    content_by_lua_block {
        local ok, err = ngx.run_worker_thread("testpool", "write_log_file", "log", ngx.var.arg_str)
        if not ok then
            ngx.say(ok, " : ", err)
            return
        end
        ngx.say(ok)
    }
}
</geshi>

<code>write_log_file.lua</code>

<geshi lang="lua">
local function log(str)
    local file, err = io.open("/tmp/tmp.log", "a")
    if not file then
        return false, err
    end
    file:write(str)
    file:flush()
    file:close()
    return true
end
return {log=log}
</geshi>

= Obsolete Sections =

This section is just holding obsolete documentation sections that have been either renamed or removed so that existing links over the web are still valid.

== Special PCRE Sequences ==

This section has been renamed to [[#Special Escaping Sequences|Special Escaping Sequences]].

== Lua/LuaJIT bytecode support ==

This section has been renamed to
[[#LuaJIT bytecode support|LuaJIT bytecode support]]. As of version
<code>v0.10.16</code> of this module, the standard Lua interpreter (also known
as "PUC-Rio Lua") is not supported anymore.
